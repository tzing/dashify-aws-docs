<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="fr-FR"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Création de tables externes pour Redshift Spectrum - Amazon Redshift</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="c-spectrum-external-tables" /><meta name="default_state" content="c-spectrum-external-tables" /><link rel="icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="canonical" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="description" content="Vous créez une table externe dans un schéma externe. Pour créer des tables externes, vous devez être le propriétaire du schéma externe ou un superutilisateur. Pour transférer la propriété d’un schéma externe, utilisez pour modifier le propriétaire. L’exemple suivant remplace le propriétaire du schéma" /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon Redshift" /><meta name="guide" content="Guide du développeur de base de données" /><meta name="abstract" content="Créez et gérez un entrepôt de données avec Amazon Redshift, service d’entrepôt de données au niveau de l’entreprise, pouvant atteindre plusieurs Po et entièrement géré." /><meta name="guide-locale" content="fr_fr" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="de" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="en-us" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="zh-tw" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="x-default" /><meta name="feedback-item" content="Redshift" /><meta name="this_doc_product" content="Amazon Redshift" /><meta name="this_doc_guide" content="Guide du développeur de base de données" /><script defer="" src="/assets/r/vendor4.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor3.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor1.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-common.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-doc-page.js?version=2021.12.02"></script><link href="/assets/r/vendor4.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-common.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-doc-page.css?version=2021.12.02" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'redshift'}"></script><meta id="panorama-serviceSubSection" value="Guide du développeur de base de données" /><meta id="panorama-serviceConsolePage" value="Création de tables externes pour Redshift Spectrum" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Création de tables externes pour Redshift Spectrum - Amazon Redshift</title><meta name="pdf" content="redshift-dg.pdf#c-spectrum-external-tables" /><meta name="rss" content="Dochistory.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=155" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="keywords" content="Amazon Redshift,AWS Redshift,Redshift,Redshift Spectrum,cluster,entrepôt de données,développeur,exemples de données,database,développeur de base de données,HLL" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon Redshift",
        "item" : "https://docs.aws.amazon.com/redshift/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Guide du développeur de base de données",
        "item" : "https://docs.aws.amazon.com/fr_fr/redshift/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Interroger des données externes avec Amazon Redshift Spectrum",
        "item" : "https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-using-spectrum.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Création de tables externes pour Redshift Spectrum",
        "item" : "https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-using-spectrum.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="redshift-dg.pdf#c-spectrum-external-tables" target="_blank" rel="noopener noreferrer" title="Ouvrir le PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="/index.html">Documentation</a><a href="/redshift/index.html">Amazon Redshift</a><a href="welcome.html">Guide du développeur de base de données</a></div><div id="page-toc-src"><a href="#c-spectrum-external-tables-pseudocolumns">Pseudocolonnes</a><a href="#c-spectrum-external-tables-partitioning">Partitionnement des tables externes Redshift Spectrum</a><a href="#c-spectrum-column-mapping-orc">Mappage des colonnes ORC</a><a href="#c-spectrum-column-mapping-hudi">Créer des tables externes pour les données gérées par Hudi</a><a href="#c-spectrum-column-mapping-delta">Créer des tables externes pour les données Delta Lake</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><awsui-alert class="awsdocs-page-banner awsui-util-mb-l"><p>Les traductions sont fournies par des outils de traduction automatique. En cas de conflit entre le contenu d'une traduction et celui de la version originale en anglais, la version anglaise prévaudra.</p></awsui-alert><h1 class="topictitle" id="c-spectrum-external-tables">Création de tables externes pour Redshift Spectrum</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p></p><p>Vous créez une table externe dans un schéma externe. Pour créer des tables externes, vous devez être le propriétaire du schéma externe ou un superutilisateur. Pour transférer la propriété d’un schéma externe, utilisez <a href="./r_ALTER_SCHEMA.html">ALTER SCHEMA</a> pour modifier le propriétaire. L’exemple suivant remplace le propriétaire du schéma <code class="code">spectrum_schema</code> par <code class="code">newowner</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter schema spectrum_schema owner to newowner;</code></pre><p>Pour exécuter une requête Redshift Spectrum, vous devez avoir les autorisations suivantes :</p><div class="itemizedlist">
          
          
      <ul class="itemizedlist"><li class="listitem">
            <p>Autorisations d’utilisation du schéma </p>
         </li><li class="listitem">
            <p>Autorisation de créer des tables temporaires dans la base de données actuelle </p>
         </li></ul></div><p>L’exemple suivant accorde l’autorisation d’utiliser le schéma <code class="code">spectrum_schema</code> au groupe d’utilisateurs <code class="code">spectrumusers</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">grant usage on schema spectrum_schema to group spectrumusers;</code></pre><p>L’exemple suivant accorde une autorisation temporaire concernant la base de données <code class="code">spectrumdb</code> au groupe d’utilisateurs <code class="code">spectrumusers</code>. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">grant temp on database spectrumdb to group spectrumusers;</code></pre><p>Vous pouvez créer une table externe dans Amazon Redshift, AWS Glue, Amazon Athena ou un métastore Apache Hive. Pour plus d’informations, consultez <a href="https://docs.aws.amazon.com/glue/latest/dg/getting-started.html">Premiers pas avec AWS Glue</a> dans le <em>guide du développeur AWS Glue</em>, <a href="https://docs.aws.amazon.com/athena/latest/ug/getting-started.html">Démarrez</a> dans le <em>guide de l’utilisateur d’Amazon Athena</em>, ou <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html">Apache Hive</a> dans le <em>guide du développeur Amazon EMR</em>. </p><p>Si votre table externe est définie dans AWS Glue, Athena ou un métastore Hive, vous devez d’abord créer un schéma externe qui fait référence à la base de données externe. Vous pouvez alors faire référence à la table externe dans votre instruction SELECT en faisant précéder le nom de la table du nom du schéma, sans avoir à créer la table dans Amazon Redshift. Pour de plus amples informations, consultez <a href="./c-spectrum-external-schemas.html">Création de schémas externes pour Amazon Redshift Spectrum</a>. </p><p>Pour autoriser Amazon Redshift à afficher les tables dans le AWS Glue Data Catalog, ajoutez <code class="code">glue:GetTable</code> au rôle IAM Amazon Redshift. Sinon, vous risquez de recevoir une erreur similaire à ce qui suit.</p><pre class="programlisting"><div class="code-btn-container"></div><code class="nohighlight">RedshiftIamRoleSession is not authorized to perform: glue:GetTable on resource: *;</code></pre><p>Par exemple, supposons que vous ayez une table externe nommée <code class="code">lineitem_athena</code> définie dans un catalogue externe Athena. Vous pouvez dans ce cas définir un schéma externe nommé <code class="code">athena_schema</code>, puis interroger la table à l’aide de l’instruction SELECT suivante.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select count(*) from athena_schema.lineitem_athena;</code></pre><p>Pour définir une table externe dans Amazon Redshift, utilisez la commande <a href="./r_CREATE_EXTERNAL_TABLE.html">CREATE EXTERNAL TABLE</a>. L’instruction de la table externe définit les colonnes de la table, le format des fichiers de données ainsi que l’emplacement des données dans Amazon S3. Redshift Spectrum analyse les fichiers dans le dossier spécifié, mais pas dans les sous-dossiers. Redshift Spectrum ignore les fichiers masqués ainsi que les fichiers dont le nom commence par un point, un trait de soulignement ou une marque de hachage ( . , _ ou #) ou se termine par un tilde (~). </p><p>L’exemple suivant crée une table nommée SALES dans le schéma externe Amazon Redshift nommé <code class="code">spectrum</code>. Les données figurent dans des fichiers texte délimités par des tabulations.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
row format delimited
fields terminated by '\t'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/sales/'
table properties ('numRows'='172000');</code></pre><p>Pour afficher les tables externes, interrogez la vue système <a href="./r_SVV_EXTERNAL_TABLES.html">SVV_EXTERNAL_TABLES</a>. </p>
         <h2 id="c-spectrum-external-tables-pseudocolumns">Pseudocolonnes</h2>

         
         <p>Par défaut, Amazon Redshift crée des tables externes avec les pseudo-colonnes <code class="code">$path</code>, <code class="code">$size</code> et <code class="code">$spectrum_oid</code>. Sélectionnez la colonne <code class="code">$path</code> pour afficher le chemin d’accès aux fichiers de données sur Amazon S3 et sélectionnez la colonne <code class="code">$size</code> pour afficher la taille des données de chaque ligne renvoyée par une requête. La colonne <code class="code">$spectrum_oid</code> permet d’effectuer des requêtes corrélées avec Redshift Spectrum. Pour obtenir un exemple, consultez <a href="./c_performing-correlated-subqueries-spectrum.html">Exemple : exécution de sous-requêtes corrélées dans Redshift Spectrum</a>. Vous devez délimiter les noms de colonne <code class="code">$path</code>, <code class="code">$size</code> et <code class="code">$spectrum_oid</code> par des guillemets doubles. Une clause SELECT * ne renvoie pas les pseudo-colonnes. Vous devez inclure explicitement les noms de colonne <code class="code">$path</code>, <code class="code">$size</code> et <code class="code">$spectrum_oid</code> dans votre requête, comme l’illustre l’exemple suivant.</p>
         
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="SQL ">select "$path", "$size", "$spectrum_oid"
from spectrum.sales_part where saledate = '2008-12-01';</code></pre>
         
         <p>Vous pouvez désactiver la création de pseudo-colonnes d’une séance en définissant le paramètre de configuration <code class="code">spectrum_enable_pseudo_columns</code> avec la valeur <code class="code">false</code>. Pour plus d'informations, consultez <a href="./r_spectrum_enable_pseudo_columns.html">spectrum_enable_pseudo_columns</a>. Vous pouvez aussi désactiver uniquement la pseudo-colonne <code class="code">$spectrum_oid</code> en définissant <code class="code">enable_spectrum_oid</code> sur <code class="code">false</code>. Pour plus d'informations, consultez <a href="./r_spectrum_enable_spectrum_oid.html">enable_spectrum_oid</a>. Toutefois, la désactivation de la pseudo-colonne <code class="code">$spectrum_oid</code> désactive également la prise en charge des requêtes corrélées avec Redshift Spectrum.</p>
         <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>La sélection de <code class="code">$size</code>, <code class="code">$path</code> ou <code class="code">$spectrum_oid</code> entraîne des frais, car Redshift Spectrum analyse les fichiers de données sur Amazon S3 pour déterminer la taille de l’ensemble de résultats. Pour plus d'informations, veuillez consulter la rubrique <a href="https://aws.amazon.com/redshift/pricing/" rel="noopener noreferrer" target="_blank"><span>Tarification d'Amazon Redshift</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p></div></div>
          
            <h3 id="c-spectrum-external-tables-pseudocolumns-example">Exemple de pseudocolonnes</h3>

            <p>L’exemple suivant renvoie la taille totale des fichiers de données associés pour une table externe.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select distinct "$path", "$size"
from spectrum.sales_part;

 $path                                                                    | $size
--------------------------------------------------------------------------+-------
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/ |  1616
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-02/ |  1444
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/ |  1644</code></pre>
          
       
         <h2 id="c-spectrum-external-tables-partitioning">Partitionnement des tables externes Redshift Spectrum</h2>

         <p>Lorsque vous partitionnez vos données, vous pouvez restreindre la quantité de données analysées par Redshift Spectrum en les filtrant en fonction de n’importe quelle clé de partition. </p>
         <p>Il est courant de les partitionner selon des critères temporels. Par exemple, vous pouvez les partitionner en fonction de l’année, du mois, de la date et de l’heure. Si les données sont issues de plusieurs sources, vous pouvez les partitionner selon un identificateur de source de données et une date. </p>
         <p>La procédure suivante décrit comment partitionner les données.</p>
         <div class="procedure"><h6>Pour partitionner les données</h6><ol><li>
               <p>Stockez les données dans des dossiers d’Amazon S3 en fonction de la clé de partition. </p>
               <p>Créez pour chaque valeur de partition un dossier que vous nommerez à l’aide de la clé et de la valeur de partition. Par exemple, si vous partitionnez les données par date, vos dossiers peuvent être nommés <code class="code">saledate=2017-04-01</code>, <code class="code">saledate=2017-04-02</code>, etc. Redshift Spectrum analyse les fichiers dans le dossier de partition et tous les sous-dossiers. Redshift Spectrum ignore les fichiers masqués ainsi que les fichiers dont le nom commence par un point, un trait de soulignement ou une marque de hachage ( . , _ ou #) ou se termine par un tilde (~). </p>

            </li><li>
               <p>Créez une table externe, puis spécifiez la clé de partition dans la clause PARTITIONED BY. </p>
               <p>La clé de partition ne peut pas correspondre au nom d’une colonne de la table. Le type de données peut être SMALLINT, INTEGER, BIGINT, DECIMAL, REAL, DOUBLE PRECISION, BOOLEAN, CHAR, VARCHAR, DATE ou TIMESTAMP. </p>
            </li><li>
               <p>Ajoutez des partitions. </p>
               <p>En utilisant <a href="./r_ALTER_TABLE.html">ALTER TABLE</a> … ADD PARTITION, ajoutez chaque partition, en spécifiant la colonne de la partition et la valeur de la clé, ainsi que l’emplacement du dossier de partition dans Amazon S3. Vous pouvez ajouter plusieurs partitions en une seule instruction ALTER TABLE … ADD. L’exemple qui suit ajoute des partitions pour <code class="code">'2008-01'</code> et <code class="code">'2008-03'</code>.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_part add
partition(saledate='2008-01-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/'
partition(saledate='2008-03-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/';</code></pre>
               <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Si vous utilisez le catalogue AWS Glue, vous pouvez ajouter jusqu’à 100 partitions à l’aide d’une seule instruction ALTER TABLE.</p></div></div>
            </li></ol></div>

          
            <h3 id="c-spectrum-external-tables-partitioning-example">Exemples de partitionnement de données</h3>


            <p>Dans cet exemple, vous devez créer une table externe partitionnée par une seule clé de partition et une table externe partitionnée par deux clés de partition.</p>

            <p>Les données de cet exemple sont situées dans un compartiment Amazon S3 qui donne un accès en lecture à tous les utilisateurs AWS authentifiés. Votre cluster et vos fichiers de données externes doivent se trouver dans la même Région AWS. L’exemple de compartiment de données se trouve dans la région USA Est (Virginie du Nord) (us-east-1). Pour pouvoir accéder aux données à l’aide de Redshift Spectrum, votre cluster doit donc également se trouver dans la région us-east-1. Pour répertorier les dossiers dans Amazon S3, exécutez la commande suivante.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">aws s3 ls s3://redshift-downloads/tickit/spectrum/sales_partition/</code></pre>
            <pre class="screen">PRE saledate=2008-01/
PRE saledate=2008-03/
PRE saledate=2008-04/
PRE saledate=2008-05/
PRE saledate=2008-06/
PRE saledate=2008-12/</pre>
            <p>Si vous ne possédez pas encore de schéma externe, exécutez la commande ci-dessous. Remplacez l’Amazon Resource Name (ARN) pour votre rôle AWS Identity and Access Management (IAM).</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external schema spectrum
from data catalog
database 'spectrumdb'
iam_role 'arn:aws:iam::123456789012:role/myspectrumrole'
create external database if not exists;</code></pre>
             
               <h4 id="c-spectrum-external-tables-single-partition-example">Exemple 1 : Partitionnement avec une seule clé de partition</h4>
               <p>Dans l’exemple suivant, vous devez créer une table externe partitionnée par mois.</p>
               <p>Pour créer une table externe partitionnée par mois, exécutez la commande suivante.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales_part(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
partitioned by (saledate char(10))
row format delimited
fields terminated by '|'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/sales_partition/'
table properties ('numRows'='172000');</code></pre>
               <p>Exécutez la commande ALTER TABLE suivante pour ajouter les partitions.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_part add
partition(saledate='2008-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/'

partition(saledate='2008-03') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/'

partition(saledate='2008-04') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-04/';</code></pre>
               <p>Pour sélectionner les données de la table partitionnée, exécutez la requête suivante.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select top 5 spectrum.sales_part.eventid, sum(spectrum.sales_part.pricepaid) 
from spectrum.sales_part, event
where spectrum.sales_part.eventid = event.eventid
  and spectrum.sales_part.pricepaid &gt; 30
  and saledate = '2008-01'
group by spectrum.sales_part.eventid
order by 2 desc;</code></pre>

               <pre class="screen">eventid | sum     
--------+---------
   4124 | 21179.00
   1924 | 20569.00
   2294 | 18830.00
   2260 | 17669.00
   6032 | 17265.00</pre>
               <p>Pour afficher les partitions de la table externe, interrogez la vue système <a href="./r_SVV_EXTERNAL_PARTITIONS.html">SVV_EXTERNAL_PARTITIONS</a>.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select schemaname, tablename, values, location from svv_external_partitions
where tablename = 'sales_part';</code></pre>

               <pre class="screen">schemaname | tablename  | values      | location                                                                
-----------+------------+-------------+-------------------------------------------------------------------------
spectrum   | sales_part | ["2008-01"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01
spectrum   | sales_part | ["2008-03"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03
spectrum   | sales_part | ["2008-04"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-04</pre>
             
             
               <h4 id="c-spectrum-external-tables-multi-partition-example">Exemple 2 : Partitionnement avec plusieurs clés de partition</h4>

               <p>Pour créer une table externe partitionnée par <code class="code">date</code> et <code class="code">eventid</code>, exécutez la commande suivante.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales_event(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
partitioned by (salesmonth char(10), event integer)
row format delimited
fields terminated by '|'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/salesevent/'
table properties ('numRows'='172000');</code></pre>
               <p>Exécutez la commande ALTER TABLE suivante pour ajouter les partitions.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_event add
partition(salesmonth='2008-01', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=101/'

partition(salesmonth='2008-01', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=102/'

partition(salesmonth='2008-01', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=103/'

partition(salesmonth='2008-02', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=101/'

partition(salesmonth='2008-02', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=102/'

partition(salesmonth='2008-02', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=103/'

partition(salesmonth='2008-03', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=101/'

partition(salesmonth='2008-03', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=102/'

partition(salesmonth='2008-03', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=103/';</code></pre>
               <p>Exécutez la requête suivante pour sélectionner les données de la table partitionnée.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select spectrum.sales_event.salesmonth, event.eventname, sum(spectrum.sales_event.pricepaid) 
from spectrum.sales_event, event
where spectrum.sales_event.eventid = event.eventid
  and salesmonth = '2008-02'
	and (event = '101'
	or event = '102'
	or event = '103')
group by event.eventname, spectrum.sales_event.salesmonth
order by 3 desc;</code></pre>
               <pre class="screen">salesmonth | eventname       | sum    
-----------+-----------------+--------
2008-02    | The Magic Flute | 5062.00
2008-02    | La Sonnambula   | 3498.00
2008-02    | Die Walkure     |  534.00</pre>
             
          
       
         <h2 id="c-spectrum-column-mapping-orc">Mappage de colonnes de table externe à des colonnes ORC</h2>
         <p>Vous utilisez les tables externes Amazon Redshift Spectrum pour interroger les données des fichiers au format ORC. Le format Optimized Row Columnar (ORC) est un format de fichier de stockage en colonnes qui prend en charge les structures de données imbriquées. Pour plus d’informations sur l’interrogation de données imbriquées, consultez <a href="./tutorial-query-nested-data.html#tutorial-nested-data-overview">Interrogation de données imbriquées avec Amazon Redshift Spectrum</a>. </p>
         <p>Lorsque vous créez une table externe qui fait référence à des données dans un fichier ORC, vous mappez chaque colonne de la table externe à une colonne dans les données ORC. Pour ce faire, vous utilisez l’une des méthodes suivantes :</p>
         <div class="itemizedlist">
             
             
         <ul class="itemizedlist"><li class="listitem">
               <p><a href="#orc-mapping-by-position">Mappage par position</a></p>
            </li><li class="listitem">
               <p><a href="#orc-mapping-by-name">Mappage par nom de colonne</a> </p>
            </li></ul></div>
         <p>Le mappage par nom de colonne est l’option par défaut. </p>
          
            <h3 id="orc-mapping-by-position">Mappage par position</h3>
            <p>Avec le mappage par position, la première colonne définie dans la table externe est mappée à la première colonne du fichier de données ORC, la deuxième colonne à la deuxième colonne, et ainsi de suite. Pour le mappage par position, l’ordre des colonnes dans la table externe et dans le fichier ORC doivent correspondre. Si l’ordre des colonnes ne correspond pas, vous pouvez mapper les colonnes par nom. </p>
            <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>Dans des versions précédentes, Redshift Spectrum utilisait le mappage par position par défaut. Si vous avez besoin de continuer à utiliser le mappage par position pour des tables existantes, définissez la propriété de table <code class="code">orc.schema.resolution</code> sur <code class="code">position</code>, comme illustré dans l’exemple suivant. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.orc_example 
set table properties('orc.schema.resolution'='position'); </code></pre></div></div>
            <p>Par exemple, la table <code class="code">SPECTRUM.ORC_EXAMPLE</code> est définie comme suit. </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.orc_example(
int_col int,
float_col float,
nested_col struct&lt;
  "int_col" : int,
  "map_col" : map&lt;int, array&lt;float &gt;&gt;
   &gt;
) stored as orc
location 's3://example/orc/files/';</code></pre>
            <p>La structure de table peut être extraite comme suit. </p>
            <pre class="screen">• 'int_col' : int
• 'float_col' : float
• 'nested_col' : struct
   o 'int_col' : int
   o 'map_col' : map
      - key : int
      - value : array
         - value : float</pre>
            <p>Le fichier ORC sous-jacent a la structure de fichier suivante.</p>
            <pre class="screen">• ORC file root(id = 0)
   o 'int_col' : int (id = 1)
   o 'float_col' : float (id = 2)
   o 'nested_col' : struct (id = 3)
      - 'int_col' : int (id = 4)
      - 'map_col' : map (id = 5)
         - key : int (id = 6)
         - value : array (id = 7)
            - value : float (id = 8)</pre>
            <p>Dans cet exemple, vous pouvez mapper chaque colonne de la table externe à une colonne du fichier ORC strictement par position. Voici une illustration du mappage.</p>

            <div class="table-container"><div class="table-contents"><table id="w319aac29c19c45c11c21"><thead>
                     <tr>
                        <th>Nom de colonne de la table externe</th>
                        <th>ID de colonne ORC</th>
                        <th>Nom de colonne ORC</th>
                     </tr>
                  </thead>
                     <tr>
                        <td tabindex="-1">int_col</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">float_col</td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">float_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col</td>
                        <td tabindex="-1">3</td>
                        <td tabindex="-1">nested_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.int_col</td>
                        <td tabindex="-1">4</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col</td>
                        <td tabindex="-1">5</td>
                        <td tabindex="-1">map_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.key</td>
                        <td tabindex="-1">6</td>
                        <td tabindex="-1">NA</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.value</td>
                        <td tabindex="-1">7</td>
                        <td tabindex="-1">NA</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.value.item</td>
                        <td tabindex="-1">8</td>
                        <td tabindex="-1">NA</td>
                     </tr>
                  </table></div></div>
          
          
            <h3 id="orc-mapping-by-name">Mappage par nom de colonne</h3>
            <p>À l’aide du mappage par nom, vous mappez des colonnes d’une table externe à des colonnes nommées de fichiers ORC sur le même niveau avec le même nom. </p>
            <p>Par exemple, supposons que vous souhaitez mapper la table de l’exemple précédent, <code class="code">SPECTRUM.ORC_EXAMPLE</code>, avec un fichier ORC qui utilise la structure de fichier suivante.</p>
            <pre class="screen">• ORC file root(id = 0)
   o 'nested_col' : struct (id = 1)
      - 'map_col' : map (id = 2)
         - key : int (id = 3)
         - value : array (id = 4)
            - value : float (id = 5)
      - 'int_col' : int (id = 6)
   o 'int_col' : int (id = 7)
   o 'float_col' : float (id = 8)</pre>

            <p>À l’aide du mappage par position, Redshift Spectrum tente le mappage suivant. </p>
            <div class="table-container"><div class="table-contents"><table id="w319aac29c19c45c13c11"><thead>
                     <tr>
                        <th>Nom de colonne de la table externe</th>
                        <th>ID de colonne ORC</th>
                        <th>Nom de colonne ORC</th>
                     </tr>
                  </thead>
                     <tr>
                        <td tabindex="-1">int_col</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">struct</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">float_col</td>
                        <td tabindex="-1">7</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col</td>
                        <td tabindex="-1">8</td>
                        <td tabindex="-1">float_col</td>
                     </tr>
                  </table></div></div>
            <p>Lorsque vous interrogez une table avec le mappage par position précédent, la commande SELECT échoue pour la validation du type parce que les structures sont différentes. </p>
            <p>Vous pouvez mapper la même table externe aux deux structures de fichier illustrés dans les exemples précédents à l’aide du mappage par nom de colonne. Les colonnes de table <code class="code">int_col</code>, <code class="code">float_col</code> et <code class="code">nested_col</code> sont mappées par nom de colonne aux colonnes avec les mêmes noms dans le fichier ORC. La colonne de table nommée <code class="code">nested_col</code>dans la table externe est une colonne <code class="code">struct</code> avec des sous-colonnes nommées <code class="code">map_col</code> et <code class="code">int_col</code>. Les sous-colonnes sont mappées correctement aux colonnes correspondantes dans le fichier ORC par nom de colonne. </p>

          
       
      <h2 id="c-spectrum-column-mapping-hudi">Créer des tables externes pour les données gérées dans Apache Hudi</h2>
      <p>Pour interroger des données au format Apache Hudi Copy On Write (CoW), vous pouvez utiliser les tables externes Amazon Redshift Spectrum. Une table Hudi Copy On Write est une collection de fichiers Apache Parquet stockés dans Amazon S3. Vous pouvez lire les tables Copy On Write (Copie sur écriture, CoW) qui sont créées et modifiées avec les opérations d’écriture insert, delete et upsert dans Apache Hudi versions 0.5.2, 0.6.0, 0.7.0, 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0 et 0.11.1. Par exemple, les tables d’amorçage ne sont pas prises en charge. Pour de plus amples informations, consultez <a href="https://hudi.apache.org/docs/next/table_types#copy-on-write-table" rel="noopener noreferrer" target="_blank"><span>Table Copy On Write</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> dans la documentation open source Apache Hudi. </p>
      <p>Lorsque vous créez une table externe qui fait référence à des données au format CoW Hudi, vous mappez chaque colonne de la table externe à une colonne des données Hudi. Le mappage se fait par colonne. </p>

      <p>Les instructions DDL (Data Definition Language) pour les tables Hudi partitionnées et non partitionnées sont similaires à celles des autres formats de fichier Apache Parquet. Pour les tables Hudi, vous définissez <code class="code">INPUTFORMAT</code> sur <code class="code">org.apache.hudi.hadoop.HoodieParquetInputFormat</code>. Le paramètre <code class="code">LOCATION</code> doit être tourné vers le dossier de base de la table Hudi qui contient le dossier <code class="code">.hoodie</code>, qui est nécessaire pour établir la chronologie de validation Hudi. Dans certains cas, une opération SELECT sur une table Hudi peut échouer avec le message <strong class="errortext"><code>No valid Hudi commit timeline found (Aucune chronologie de validation Hudi valide n’a été trouvée)</code></strong>. Si c’est le cas, vérifiez si le dossier <code class="code">.hoodie</code> est à l’emplacement correct et contient une chronologie de validation Hudi valide. </p>
      <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Le format Apache Hudi n’est pris en charge que lorsque vous utilisez un AWS Glue Data Catalog. Il n’est pas pris en charge lorsque vous utilisez un métastore Apache Hive comme catalogue externe. </p></div></div>
      <p>Le format DDL pour définir une table non partitionnée est au format suivant. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>'</code></pre>
      <p>Le DDL pour définir une table partitionnée est au format suivant. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
PARTITIONED BY(<em>pcolumn1</em> <em>pcolumn1-type</em>[,...])
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>'</code></pre>
      <p>Pour ajouter des partitions à une table Hudi partitionnée, exécutez une commande ALTER TABLE ADD PARTITION dans laquelle le paramètre <code class="code">LOCATION</code> est tourné vers le sous-dossier Amazon S3 avec les fichiers qui appartiennent à la partition.</p>
      <p>Le DDL pour ajouter des partitions est au format suivant.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>/<em>partition-path</em>'</code></pre>
    
      <h2 id="c-spectrum-column-mapping-delta">Créer des tables externes pour les données gérées dans Delta Lake</h2>
      <p>Pour interroger des données dans des tables Delta Lake, vous pouvez utiliser des tables externes Amazon Redshift Spectrum. </p>
         <p>Pour accéder à une table Delta Lake à partir de Redshift Spectrum, générez un manifeste avant la requête. Un <em>manifeste</em> Delta Lake contient une liste des fichiers qui constituent un instantané cohérent de la table Delta Lake. Dans une table partitionnée, il y a un manifeste par partition. Une table Delta Lake est une collection de fichiers Apache Parquet stockés dans Amazon S3. Pour plus d’informations, consultez <a href="https://delta.io" rel="noopener noreferrer" target="_blank"><span>Delta Lake</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> dans la documentation open source de Delta Lake. </p>
      <p>Lorsque vous créez une table externe qui fait référence aux données des tables Delta Lake, vous mappez chaque colonne de la table externe à une colonne de la table Delta Lake. Le mappage se fait par nom de colonne. </p>
      
      <p>La DDL pour les tables Delta Lake partitionnées et non partitionnées est similaire à celle des autres formats de fichiers Apache Parquet. Pour les tables Delta Lake, vous définissez <code class="code">INPUTFORMAT</code> sur <code class="code">org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat</code> et <code class="code">OUTPUTFORMAT</code> sur <code class="code">org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</code>. Le paramètre <code class="code">LOCATION</code> doit être tourné vers le dossier manifeste dans le dossier de base de la table. Si une opération SELECT sur une table Delta Lake échoue, pour des raisons possibles, consultez <a href="#c-spectrum-column-mapping-delta-limitations">Limites et dépannage pour les tables Delta Lake</a>. </p>
      <p>Le format DDL pour définir une table non partitionnée est au format suivant. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest'</code></pre>
      <p>Le DDL pour définir une table partitionnée est au format suivant. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
PARTITIONED BY(<em>pcolumn1</em> <em>pcolumn1-type</em>[,...])
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION 's3://<em>s3-bucket</em>&gt;/<em>prefix</em>/_symlink_format_manifest'</code></pre>
      <p>Pour ajouter des partitions à une table Delta Lake partitionnée, exécutez une commande ALTER TABLE ADD PARTITION dans laquelle le paramètre <code class="code">LOCATION</code> est tourné vers le sous-dossier Amazon S3 qui contient le manifeste de la partition.</p>
      <p>Le DDL pour ajouter des partitions est au format suivant.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION
's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest/<em>partition-path</em>'</code></pre>
      <p>Sinon, exécutez DDL qui est tourné directement vers le fichier manifeste Delta Lake.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Texte"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION
's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest/<em>partition-path</em>/manifest'</code></pre>
      
       
         <h3 id="c-spectrum-column-mapping-delta-limitations">Limites et dépannage pour les tables Delta Lake</h3>
       
      <p>Tenez compte des éléments suivants lorsque vous interrogez des tables Delta Lake à partir de Redshift Spectrum :</p>
      <div class="itemizedlist">
          
          
      <ul class="itemizedlist"><li class="listitem"><p>Si un manifeste est tourné vers un instantané ou une partition qui n’existe plus, les requêtes échouent jusqu’à ce qu’un nouveau manifeste valide ait été généré. Par exemple, cela peut résulter d’une opération VACUUM sur la table sous-jacente,</p></li><li class="listitem"><p>Les manifestes Delta Lake fournissent uniquement une cohérence au niveau des partitions. </p></li></ul></div>
      <p>Le tableau suivant explique les raisons potentielles de certaines erreurs lorsque vous interrogez une table Delta Lake. </p>
      <div class="table-container"><div class="table-contents"><table id="w319aac29c19c49c37"><thead>
               <tr>
                  <th>Error message (Message d’erreur)</th>
                  <th>Raison possible</th>
               </tr>
            </thead>
               
               
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Le manifeste Delta Lake dans le compartiment <em>s3-bucket-1</em> ne peut pas contenir d’entrées dans le compartiment <em>s3-bucket-2</em>.</code></strong></p></td>
                  <td tabindex="-1"><p>Les entrées de manifeste sont tournées vers des fichiers dans un compartiment Amazon S3 différent de celui spécifié. </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Les fichiers Delta Lake doivent se trouver dans le même dossier.</code></strong></p></td>
                  <td tabindex="-1"><p>Les entrées de manifeste sont tournées vers des fichiers qui ont un préfixe Amazon S3 différent de celui spécifié.</p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Le fichier <em>filename</em> figurant dans le manifeste Delta Lake <em>manifest-path</em> n’a pas été trouvé.</code></strong></p></td>
                  <td tabindex="-1"><p>Un fichier répertorié dans le manifeste n’a pas été trouvé dans Amazon S3. </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Erreur lors de la récupération du manifeste Delta Lake.</code></strong></p></td>
                  <td tabindex="-1"><p>Le manifeste n’a pas été trouvé dans Amazon S3. </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Chemin d’accès S3 non valide.</code></strong></p></td>
                  <td tabindex="-1"><p>Une entrée dans le fichier manifeste n’est pas un chemin d’accès Amazon S3 valide ou le fichier manifeste a été corrompu. </p></td>
               </tr>

            </table></div></div>
      
   <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Avertissement" /> <strong>JavaScript est désactivé ou n'est pas disponible dans votre navigateur.</strong></p><p>Pour que vous puissiez utiliser la documentation AWS, Javascript doit être activé. Vous trouverez des instructions sur les pages d'aide de votre navigateur.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="/general/latest/gr/docconventions.html">Conventions de rédaction</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./c-spectrum-external-schemas.html">Création de schémas externes</div><div id="next" class="next-link" accesskey="n" href="./querying-iceberg.html">Utilisation des tables Apache Iceberg</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Cette page vous a-t-elle été utile ? - Oui</div><div class="content"><p>Merci de nous avoir fait part de votre satisfaction.</p><p>Si vous avez quelques minutes à nous consacrer, merci de nous indiquer ce qui vous a plu afin que nous puissions nous améliorer davantage.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Commentaire" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Cette page vous a-t-elle été utile ? - Non</div><div class="content"><p>Merci de nous avoir avertis que cette page avait besoin d'être retravaillée. Nous sommes désolés de ne pas avoir répondu à vos attentes.</p><p>Si vous avez quelques minutes à nous consacrer, merci de nous indiquer comment nous pourrions améliorer cette documentation.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Commentaire" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>