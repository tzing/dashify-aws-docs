<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="it-IT"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Creazione di tabelle esterne per Redshift Spectrum - Amazon Redshift</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="c-spectrum-external-tables" /><meta name="default_state" content="c-spectrum-external-tables" /><link rel="icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="canonical" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="description" content="Crei una tabella esterna in uno schema esterno. Per creare tabelle esterne, devi essere il proprietario dello schema esterno o un utente con privilegi avanzati. Per trasferire la proprietà di uno schema esterno, utilizza per cambiare il proprietario. L'esempio seguente cambia il proprietario dello schema" /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon Redshift" /><meta name="guide" content="Guida per sviluppatori di database" /><meta name="abstract" content="Creare e gestire un data warehouse con Amazon Redshift, un servizio di data warehouse completamente gestito di livello aziendale e con capacità nell'ordine di più petabyte." /><meta name="guide-locale" content="it_it" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="de" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="en-us" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="zh-tw" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="x-default" /><meta name="feedback-item" content="Redshift" /><meta name="this_doc_product" content="Amazon Redshift" /><meta name="this_doc_guide" content="Guida per sviluppatori di database" /><script defer="" src="/assets/r/vendor4.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor3.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor1.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-common.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-doc-page.js?version=2021.12.02"></script><link href="/assets/r/vendor4.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-common.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-doc-page.css?version=2021.12.02" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'redshift'}"></script><meta id="panorama-serviceSubSection" value="Guida per sviluppatori di database" /><meta id="panorama-serviceConsolePage" value="Creazione di tabelle esterne per Redshift Spectrum" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Creazione di tabelle esterne per Redshift Spectrum - Amazon Redshift</title><meta name="pdf" content="redshift-dg.pdf#c-spectrum-external-tables" /><meta name="rss" content="Dochistory.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=155" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="keywords" content="Amazon Redshift,AWS Redshift,Redshift,Redshift Spectrum,cluster,data warehouse,sviluppatore,dati campione,database,sviluppatore di database,HLL" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon Redshift",
        "item" : "https://docs.aws.amazon.com/redshift/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Guida per sviluppatori di database",
        "item" : "https://docs.aws.amazon.com/it_it/redshift/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Esecuzione di query sui dati esterni utilizzando Amazon Redshift Spectrum",
        "item" : "https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-using-spectrum.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Creazione di tabelle esterne per Redshift Spectrum",
        "item" : "https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-using-spectrum.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="redshift-dg.pdf#c-spectrum-external-tables" target="_blank" rel="noopener noreferrer" title="Apri PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="/index.html">Documentazione</a><a href="/redshift/index.html">Amazon Redshift</a><a href="welcome.html">Guida per sviluppatori di database</a></div><div id="page-toc-src"><a href="#c-spectrum-external-tables-pseudocolumns">Pseudocolonne</a><a href="#c-spectrum-external-tables-partitioning">Partizionamento delle tabelle esterne di Redshift Spectrum</a><a href="#c-spectrum-column-mapping-orc">Mappatura alle colonne ORC</a><a href="#c-spectrum-column-mapping-hudi">Creazione di tabelle esterne per i dati gestiti da Hudi</a><a href="#c-spectrum-column-mapping-delta">Creazione di tabelle esterne per i dati Delta Lake</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><awsui-alert class="awsdocs-page-banner awsui-util-mb-l"><p>Le traduzioni sono generate tramite traduzione automatica. In caso di conflitto tra il contenuto di una traduzione e la versione originale in Inglese, quest'ultima prevarrà.</p></awsui-alert><h1 class="topictitle" id="c-spectrum-external-tables">Creazione di tabelle esterne per Redshift Spectrum</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p></p><p>Crei una tabella esterna in uno schema esterno. Per creare tabelle esterne, devi essere il proprietario dello schema esterno o un utente con privilegi avanzati. Per trasferire la proprietà di uno schema esterno, utilizza <a href="./r_ALTER_SCHEMA.html">ALTER SCHEMA</a> per cambiare il proprietario. L'esempio seguente cambia il proprietario dello schema <code class="code">spectrum_schema</code> in <code class="code">newowner</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter schema spectrum_schema owner to newowner;</code></pre><p>Per eseguire una query di Redshift Spectrum, sono necessarie le seguenti autorizzazioni:</p><div class="itemizedlist">
          
          
      <ul class="itemizedlist"><li class="listitem">
            <p>Autorizzazione di utilizzare lo schema </p>
         </li><li class="listitem">
            <p>Autorizzazione di creare tabelle temporanee nel database corrente </p>
         </li></ul></div><p>L'esempio seguente concede l'autorizzazione all'utilizzo dello schema <code class="code">spectrum_schema</code> al gruppo di utenti <code class="code">spectrumusers</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">grant usage on schema spectrum_schema to group spectrumusers;</code></pre><p>L'esempio seguente concede l'autorizzazione temporanea per il database <code class="code">spectrumdb</code> al gruppo di utenti <code class="code">spectrumusers</code>. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">grant temp on database spectrumdb to group spectrumusers;</code></pre><p>È possibile creare una tabella esterna in Amazon Redshift, AWS Glue, Amazon Athena o in un metastore Apache Hive. Per ulteriori informazioni, consultare <a href="https://docs.aws.amazon.com/glue/latest/dg/getting-started.html">Nozioni di base sull'uso di AWS Glue</a> nella <em>Guida per gli sviluppatori di AWS Glue</em>, <a href="https://docs.aws.amazon.com/athena/latest/ug/getting-started.html">Nozioni di base</a> nella <em>Guida per l'utente di Amazon Athena</em> oppure <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html">Apache Hive</a> nella <em>Guida per gli sviluppatori di Amazon EMR</em>. </p><p>Se la tabella esterna è definita in AWS Glue, Athena o in un metastore Hive, creare prima uno schema esterno che faccia riferimento al database esterno. È quindi possibile fare riferimento alla tabella esterna nell'istruzione SELECT aggiungendo un prefisso al nome della tabella con il nome dello schema senza che sia necessario creare la tabella in Amazon Redshift. Per ulteriori informazioni, consultare <a href="./c-spectrum-external-schemas.html">Creazione di schemi esterni per Amazon Redshift Spectrum</a>. </p><p>Per consentire ad Amazon Redshift di visualizzare le tabelle nella AWS Glue Data Catalog, aggiungere <code class="code">glue:GetTable</code> al ruolo IAM di Amazon Redshift. In caso contrario, si potrebbe verificare un errore simile al seguente:</p><pre class="programlisting"><div class="code-btn-container"></div><code class="nohighlight">RedshiftIamRoleSession is not authorized to perform: glue:GetTable on resource: *;</code></pre><p>Ad esempio, si supponga di avere una tabella esterna denominata <code class="code">lineitem_athena</code> definita nel catalogo esterno di Athena. In tal caso, puoi definire uno schema esterno denominato <code class="code">athena_schema</code> e quindi eseguire una query sulla tabella utilizzando l'istruzione SELECT seguente.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select count(*) from athena_schema.lineitem_athena;</code></pre><p>Per definire una tabella esterna in Amazon Redshift, utilizzare il comando <a href="./r_CREATE_EXTERNAL_TABLE.html">CREATE EXTERNAL TABLE</a>. L'istruzione della tabella esterna definisce le colonne della tabella, il formato dei file di dati e la posizione dei dati in Amazon S3. Redshift Spectrum esegue la scansione dei file nella cartella specificata e in tutte le sottocartelle. Redshift Spectrum ignora i file nascosti e i file che iniziano con un punto, un carattere di sottolineatura o un marcatore hash ( . , _ o #) oppure che terminano con una tilde (~). </p><p>Nell'esempio seguente viene creata una tabella denominata SALES nello schema esterno Amazon Redshift denominato <code class="code">spectrum</code>. I dati sono in file di testo delimitati da tabulazioni.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
row format delimited
fields terminated by '\t'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/sales/'
table properties ('numRows'='172000');</code></pre><p>Per visualizzare le tabelle esterne, eseguire una query sulla vista di sistema <a href="./r_SVV_EXTERNAL_TABLES.html">SVV_EXTERNAL_TABLES</a>. </p>
         <h2 id="c-spectrum-external-tables-pseudocolumns">Pseudocolonne</h2>

         
         <p>Di default, Amazon Redshift crea tabelle esterne con le pseudocolonne <code class="code">$path</code>, <code class="code">$size</code> e <code class="code">$spectrum_oid</code>. Selezionare la colonna <code class="code">$path</code> per visualizzare il percorso ai file di dati su Simple Storage Service (Amazon S3) e selezionare la colonna <code class="code">$size</code> per visualizzare le dimensioni dei file di dati per ogni riga restituita da una query. La colonna <code class="code">$spectrum_oid</code> consente di eseguire query correlate con Redshift Spectrum. Per vedere un esempio, consulta <a href="./c_performing-correlated-subqueries-spectrum.html">Esempio: esecuzione di sottoquery correlate in Redshift Spectrum</a>. I nomi di colonna <code class="code">$path</code>, <code class="code">$size</code> e <code class="code">$spectrum_oid</code> devono essere delimitati da virgolette doppie. Una clausola SELECT * non restituisce le pseudocolonne. È necessario includere in modo esplicito i nomi delle colonne <code class="code">$path</code>, <code class="code">$size</code> e <code class="code">$spectrum_oid</code> nella query, come indicato nel seguente esempio.</p>
         
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="SQL ">select "$path", "$size", "$spectrum_oid"
from spectrum.sales_part where saledate = '2008-12-01';</code></pre>
         
         <p>Puoi disabilitare la creazione di pseudocolonne per una sessione impostando il parametro di configurazione <code class="code">spectrum_enable_pseudo_columns</code> su <code class="code">false</code>. Per ulteriori informazioni, consulta <a href="./r_spectrum_enable_pseudo_columns.html">spectrum_enable_pseudo_columns</a>. È anche possibile disabilitare solo la pseudocolonna <code class="code">$spectrum_oid</code> impostando il parametro di configurazione <code class="code">enable_spectrum_oid</code> su <code class="code">false</code>. Per ulteriori informazioni, consulta <a href="./r_spectrum_enable_spectrum_oid.html">enable_spectrum_oid</a>. Tuttavia, disabilitando la pseudocolonna <code class="code">$spectrum_oid</code> viene disabilitato anche il supporto per le query correlate con Redshift Spectrum.</p>
         <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Importante</h6></div><div class="awsdocs-note-text"><p>La selezione di <code class="code">$size</code>, <code class="code">$path</code> o <code class="code">$spectrum_oid</code> comporta dei costi perché Redshift Spectrum analizza i file di dati su Simple Storage Service (Amazon S3) per determinare la dimensione del set di risultati. Per ulteriori informazioni sui prezzi, consultare <a href="https://aws.amazon.com/redshift/pricing/" rel="noopener noreferrer" target="_blank"><span>Prezzi di Amazon Redshift</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p></div></div>
          
            <h3 id="c-spectrum-external-tables-pseudocolumns-example">Esempio di pseudocolonne</h3>

            <p>L'esempio seguente restituisce la dimensione totale dei file di dati correlati per una tabella esterna.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select distinct "$path", "$size"
from spectrum.sales_part;

 $path                                                                    | $size
--------------------------------------------------------------------------+-------
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/ |  1616
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-02/ |  1444
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/ |  1644</code></pre>
          
       
         <h2 id="c-spectrum-external-tables-partitioning">Partizionamento delle tabelle esterne di Redshift Spectrum</h2>

         <p>Quando esegui la partizione dei dati, puoi limitare la quantità di dati sottoposti a scansione da Redshift Spectrum filtrandoli in base a qualsiasi chiave di partizione. </p>
         <p>In genere, si partizionano i dati in base a criteri temporali. Ad esempio, puoi scegliere di eseguire il partizionamento per anno, mese, data e ora. Se hai dati da più origini, puoi eseguire il partizionamento in base a una data e a un identificatore di origine dati. </p>
         <p>La procedura seguente descrive come partizionare i dati.</p>
         <div class="procedure"><h6>Per partizionare i dati</h6><ol><li>
               <p>Archiviare i dati in cartelle di Amazon S3 in funzione della chiave di partizione. </p>
               <p>Creare una cartella per ogni valore di partizione e assegnare un nome alla cartella con la chiave e il valore di partizione. Ad esempio, se si esegue la partizione per data, le cartelle possono essere denominate <code class="code">saledate=2017-04-01</code>, <code class="code">saledate=2017-04-02</code> e così via. Redshift Spectrum esegue la scansione dei file nella cartella di partizione e in tutte le sottocartelle. Redshift Spectrum ignora i file nascosti e i file che iniziano con un punto, un carattere di sottolineatura o un marcatore hash ( . , _ o #) oppure che terminano con una tilde (~). </p>

            </li><li>
               <p>Creare una tabella esterna e specificare la chiave di partizione nella clausola PARTITIONED BY. </p>
               <p>La chiave di partizione non può essere Il nome di una colonna della tabella. Il tipo di dati può essere SMALLINT, INTEGER, BIGINT, DECIMAL, REAL, DOUBLE PRECISION, BOOLEAN, CHAR, VARCHAR, DATE o TIMESTAMP. </p>
            </li><li>
               <p>Aggiungere le partizioni. </p>
               <p>Utilizzando <a href="./r_ALTER_TABLE.html">ALTER TABLE</a> … ADD PARTITION, aggiungere ogni partizione, specificando la colonna della partizione e il valore della chiave nonché la posizione della cartella di partizione in Amazon S3. È possibile aggiungere più partizioni in una singola istruzione ALTER TABLE … ADD. L'esempio seguente aggiunge partizioni per <code class="code">'2008-01'</code> e <code class="code">'2008-03'</code>.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_part add
partition(saledate='2008-01-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/'
partition(saledate='2008-03-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/';</code></pre>
               <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Nota</h6></div><div class="awsdocs-note-text"><p>Se utilizzi il catalogo AWS Glue, puoi aggiungere fino a 100 partizioni utilizzando una singola istruzione ALTER TABLE.</p></div></div>
            </li></ol></div>

          
            <h3 id="c-spectrum-external-tables-partitioning-example">Partizionamento di esempi di dati</h3>


            <p>In questo esempio, crei una tabella esterna partizionata con una singola chiave di partizione e una tabella esterna partizionata con due chiavi di partizione.</p>

            <p>I dati per questo esempio si trovano in un bucket Amazon S3 che fornisce accesso in lettura a tutti gli utenti AWS autenticati. Il cluster e i file di dati esterni devono trovarsi nella stessa Regione AWS. Il bucket di dati di esempio si trova nella regione Stati Uniti orientali (Virginia settentrionale) (us-east-1). Per accedere ai dati mediante Redshift Spectrum, anche il cluster deve essere nella regione us-east-1. Per elencare le cartelle in Amazon S3, emettere il comando seguente.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">aws s3 ls s3://redshift-downloads/tickit/spectrum/sales_partition/</code></pre>
            <pre class="screen">PRE saledate=2008-01/
PRE saledate=2008-03/
PRE saledate=2008-04/
PRE saledate=2008-05/
PRE saledate=2008-06/
PRE saledate=2008-12/</pre>
            <p>Se non hai ancora uno schema esterno, esegui il comando seguente. Sostituisci l'Amazon Resource Name (ARN) del tuo ruolo AWS Identity and Access Management (IAM).</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external schema spectrum
from data catalog
database 'spectrumdb'
iam_role 'arn:aws:iam::123456789012:role/myspectrumrole'
create external database if not exists;</code></pre>
             
               <h4 id="c-spectrum-external-tables-single-partition-example">Esempio 1: partizionamento con una singola chiave di partizione</h4>
               <p>Nell'esempio seguente, crei una tabella esterna partizionata per mese.</p>
               <p>Per creare una tabella esterna partizionata per mese, esegui il comando seguente.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales_part(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
partitioned by (saledate char(10))
row format delimited
fields terminated by '|'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/sales_partition/'
table properties ('numRows'='172000');</code></pre>
               <p>Per aggiungere le partizioni, esegui il comando ALTER TABLE seguente.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_part add
partition(saledate='2008-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/'

partition(saledate='2008-03') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/'

partition(saledate='2008-04') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-04/';</code></pre>
               <p>Per selezionare i dati dalla tabella partizionata, esegui la seguente query.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select top 5 spectrum.sales_part.eventid, sum(spectrum.sales_part.pricepaid) 
from spectrum.sales_part, event
where spectrum.sales_part.eventid = event.eventid
  and spectrum.sales_part.pricepaid &gt; 30
  and saledate = '2008-01'
group by spectrum.sales_part.eventid
order by 2 desc;</code></pre>

               <pre class="screen">eventid | sum     
--------+---------
   4124 | 21179.00
   1924 | 20569.00
   2294 | 18830.00
   2260 | 17669.00
   6032 | 17265.00</pre>
               <p>Per visualizzare le partizioni delle tabelle, eseguire una query sulla vista di sistema <a href="./r_SVV_EXTERNAL_PARTITIONS.html">SVV_EXTERNAL_PARTITIONS</a>.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select schemaname, tablename, values, location from svv_external_partitions
where tablename = 'sales_part';</code></pre>

               <pre class="screen">schemaname | tablename  | values      | location                                                                
-----------+------------+-------------+-------------------------------------------------------------------------
spectrum   | sales_part | ["2008-01"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01
spectrum   | sales_part | ["2008-03"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03
spectrum   | sales_part | ["2008-04"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-04</pre>
             
             
               <h4 id="c-spectrum-external-tables-multi-partition-example">Esempio 2: partizionamento con più chiavi di partizione</h4>

               <p>Per creare una tabella esterna partizionata per <code class="code">date</code> e <code class="code">eventid</code>, esegui il comando seguente.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales_event(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
partitioned by (salesmonth char(10), event integer)
row format delimited
fields terminated by '|'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/salesevent/'
table properties ('numRows'='172000');</code></pre>
               <p>Per aggiungere le partizioni, esegui il comando ALTER TABLE seguente.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_event add
partition(salesmonth='2008-01', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=101/'

partition(salesmonth='2008-01', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=102/'

partition(salesmonth='2008-01', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=103/'

partition(salesmonth='2008-02', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=101/'

partition(salesmonth='2008-02', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=102/'

partition(salesmonth='2008-02', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=103/'

partition(salesmonth='2008-03', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=101/'

partition(salesmonth='2008-03', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=102/'

partition(salesmonth='2008-03', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=103/';</code></pre>
               <p>Esegui la query seguente per selezionare i dati dalla tabella partizionata.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select spectrum.sales_event.salesmonth, event.eventname, sum(spectrum.sales_event.pricepaid) 
from spectrum.sales_event, event
where spectrum.sales_event.eventid = event.eventid
  and salesmonth = '2008-02'
	and (event = '101'
	or event = '102'
	or event = '103')
group by event.eventname, spectrum.sales_event.salesmonth
order by 3 desc;</code></pre>
               <pre class="screen">salesmonth | eventname       | sum    
-----------+-----------------+--------
2008-02    | The Magic Flute | 5062.00
2008-02    | La Sonnambula   | 3498.00
2008-02    | Die Walkure     |  534.00</pre>
             
          
       
         <h2 id="c-spectrum-column-mapping-orc">Mappatura delle colonne di una tabella esterna alle colonne ORC</h2>
         <p>Utilizzare le tabelle esterne di Amazon Redshift Spectrum per eseguire query sui dati dai file nel formato ORC. Il formato Optimized Row Columnar (ORC) è un formato di file di storage a colonne che supporta le strutture di dati annidate. Per ulteriori informazioni sull'esecuzione di query su dati nidificati, consultare <a href="./tutorial-query-nested-data.html#tutorial-nested-data-overview">Esecuzione di query su dati nidificati con Amazon Redshift Spectrum</a>. </p>
         <p>Quando crei una tabella esterna che fa riferimento ai dati in un file ORC, devi mappare ogni colonna della tabella verso una colonna nei dati ORC. A tale scopo, utilizza uno dei seguenti metodi:</p>
         <div class="itemizedlist">
             
             
         <ul class="itemizedlist"><li class="listitem">
               <p><a href="#orc-mapping-by-position">Mappatura in base alla posizione</a></p>
            </li><li class="listitem">
               <p><a href="#orc-mapping-by-name">Mappatura in base al nome delle colonne</a> </p>
            </li></ul></div>
         <p>La mappatura in base al nome delle colonne è l'opzione predefinita. </p>
          
            <h3 id="orc-mapping-by-position">Mappatura in base alla posizione</h3>
            <p>Con la mappatura in base alla posizione, la prima colonna definita nella tabella esterna mappa alla prima colonna nel file di dati ORC, la seconda alla seconda e così via. Per la mappatura in base alla posizione, è necessario che l'ordine delle colonne nella tabella esterna e nel file ORC corrisponda. Diversamente, puoi mappare le colonne in base al nome. </p>
            <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Importante</h6></div><div class="awsdocs-note-text"><p>Nelle release precedenti, Redshift Spectrum utilizzava la mappatura in base alla posizione come opzione predefinita. Se devi continuare a utilizzare la mappatura in base alla posizione per le tabelle esistenti, imposta la proprietà di tabella <code class="code">orc.schema.resolution</code> su <code class="code">position</code>, come mostrato nell'esempio seguente. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.orc_example 
set table properties('orc.schema.resolution'='position'); </code></pre></div></div>
            <p>Ad esempio, la tabella <code class="code">SPECTRUM.ORC_EXAMPLE</code> è definita come segue. </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.orc_example(
int_col int,
float_col float,
nested_col struct&lt;
  "int_col" : int,
  "map_col" : map&lt;int, array&lt;float &gt;&gt;
   &gt;
) stored as orc
location 's3://example/orc/files/';</code></pre>
            <p>La struttura della tabella può essere astratta come segue. </p>
            <pre class="screen">• 'int_col' : int
• 'float_col' : float
• 'nested_col' : struct
   o 'int_col' : int
   o 'map_col' : map
      - key : int
      - value : array
         - value : float</pre>
            <p>Il file ORC sottostante presenta la seguente struttura di file.</p>
            <pre class="screen">• ORC file root(id = 0)
   o 'int_col' : int (id = 1)
   o 'float_col' : float (id = 2)
   o 'nested_col' : struct (id = 3)
      - 'int_col' : int (id = 4)
      - 'map_col' : map (id = 5)
         - key : int (id = 6)
         - value : array (id = 7)
            - value : float (id = 8)</pre>
            <p>In questo esempio, puoi mappare ciascuna colonna nella tabella esterna verso una colonna nel file di dati ORC rigorosamente in base alla posizione. Di seguito è riportata la mappatura.</p>

            <div class="table-container"><div class="table-contents"><table id="w319aac29c19c45c11c21"><thead>
                     <tr>
                        <th>Nome della colonna della tabella esterna</th>
                        <th>ID della colonna ORC</th>
                        <th>Nome della colonna ORC</th>
                     </tr>
                  </thead>
                     <tr>
                        <td tabindex="-1">int_col</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">float_col</td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">float_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col</td>
                        <td tabindex="-1">3</td>
                        <td tabindex="-1">nested_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.int_col</td>
                        <td tabindex="-1">4</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col</td>
                        <td tabindex="-1">5</td>
                        <td tabindex="-1">map_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.key</td>
                        <td tabindex="-1">6</td>
                        <td tabindex="-1">ND</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.value</td>
                        <td tabindex="-1">7</td>
                        <td tabindex="-1">ND</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.value.item</td>
                        <td tabindex="-1">8</td>
                        <td tabindex="-1">N/A</td>
                     </tr>
                  </table></div></div>
          
          
            <h3 id="orc-mapping-by-name">Mappatura in base al nome delle colonne</h3>
            <p>Tramite la mappatura dei nomi, puoi mappare le colonne in una tabella esterna verso colonne con nome nei file ORC allo stesso livello e con il medesimo nome. </p>
            <p>Supponi ad esempio di voler mappare la tabella del precedente esempio, <code class="code">SPECTRUM.ORC_EXAMPLE</code>, con un file ORC che utilizza la seguente struttura di file.</p>
            <pre class="screen">• ORC file root(id = 0)
   o 'nested_col' : struct (id = 1)
      - 'map_col' : map (id = 2)
         - key : int (id = 3)
         - value : array (id = 4)
            - value : float (id = 5)
      - 'int_col' : int (id = 6)
   o 'int_col' : int (id = 7)
   o 'float_col' : float (id = 8)</pre>

            <p>Utilizzando la mappatura basata sulla posizione, Redshift Spectrum tenta di eseguire la mappatura seguente. </p>
            <div class="table-container"><div class="table-contents"><table id="w319aac29c19c45c13c11"><thead>
                     <tr>
                        <th>Nome della colonna della tabella esterna</th>
                        <th>ID della colonna ORC</th>
                        <th>Nome della colonna ORC</th>
                     </tr>
                  </thead>
                     <tr>
                        <td tabindex="-1">int_col</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">struct</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">float_col</td>
                        <td tabindex="-1">7</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col</td>
                        <td tabindex="-1">8</td>
                        <td tabindex="-1">float_col</td>
                     </tr>
                  </table></div></div>
            <p>Quando si esegue una query su una tabella con la precedente mappatura basata sulla posizione, il comando SELECT ha esito negativo sulla convalida del tipo in quanto le strutture sono diverse. </p>
            <p>Puoi mappare la stessa tabella esterna verso entrambe le strutture di file mostrate negli esempi precedenti utilizzando la mappatura basata sui nomi. Le colonne di tabella <code class="code">int_col</code>, <code class="code">float_col</code> e <code class="code">nested_col</code> vengono mappate in base al nome verso le colonne con i medesimi nomi nel file ORC. La colonna denominata <code class="code">nested_col</code> nella tabella esterna è una colonna <code class="code">struct</code> con sottocolonne denominate <code class="code">map_col</code> e <code class="code">int_col</code>. Le sottocolonne vengono inoltre mappate correttamente alle colonne corrispondenti nel file ORC in base al nome. </p>

          
       
      <h2 id="c-spectrum-column-mapping-hudi">Creazione di tabelle esterne per i dati gestiti in Apache Hudi</h2>
      <p>Per eseguire query sui dati in formato Apache Hudi Copy On Write (CoW), è possibile utilizzare le tabelle esterne di Amazon Redshift Spectrum. Una tabella Hudi Copy On Write è una raccolta di file Apache Parquet archiviati in Amazon S3. È possibile leggere le tabelle Copy On Write (CoW) nelle versioni 0.5.2, 0.6.0, 0.7.0, 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0 e 0.11.1 di Apache Hudi create e modificate mediante operazioni di scrittura insert, delete e upsert. Le tabelle bootstrap, ad esempio, non sono supportate. Per ulteriori informazioni, consultare <a href="https://hudi.apache.org/docs/next/table_types#copy-on-write-table" rel="noopener noreferrer" target="_blank"><span>Copia sulla tabella di scrittura</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> nella documentazione open source di Apache Hudi. </p>
      <p>Quando si crea una tabella esterna che fa riferimento ai dati in formato Hudi CoW, è necessario mappare ogni colonna della tabella esterna a una colonna nei dati Hudi. La mappatura viene eseguita per colonna. </p>

      <p>Le istruzioni DDL (Data Definition Language) per tabelle Hudi partizionate e non partizionate sono simili a quelle degli altri formati di file Apache Parquet. Per le tabelle Hudi, <code class="code">INPUTFORMAT</code> può essere definito come <code class="code">org.apache.hudi.hadoop.HoodieParquetInputFormat</code>. Il parametro <code class="code">LOCATION</code> deve puntare alla cartella di base della tabella Hudi che contiene la cartella <code class="code">.hoodie</code>, necessaria per stabilire la tempistica di commit Hudi. In alcuni casi, un'operazione SELECT su una tabella Hudi potrebbe non riuscire con il messaggio <strong class="errortext"><code>Nessuna tempistica di commit Hudi valida trovata</code></strong>. In questo caso, verificare se la cartella <code class="code">.hoodie</code> si trova nella posizione corretta e se contiene una tempistica di commit Hudi valida. </p>
      <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Nota</h6></div><div class="awsdocs-note-text"><p>Il formato Apache Hudi è supportato solo quando si utilizza un AWS Glue Data Catalog. Non è supportato se si utilizza un metastore Apache Hive come catalogo esterno. </p></div></div>
      <p>Il formato DDL per definire una tabella non partizionata è il seguente. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>'</code></pre>
      <p>Il formato DDL per definire una tabella partizionata è il seguente. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
PARTITIONED BY(<em>pcolumn1</em> <em>pcolumn1-type</em>[,...])
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>'</code></pre>
      <p>Per aggiungere partizioni a una tabella Hudi partizionata, eseguire un comando ALTER TABLE ADD PARTITION in cui il parametro <code class="code">LOCATION</code> punta alla sottocartella Amazon S3 con i file che appartengono alla partizione.</p>
      <p>Il formato DDL per aggiungere le partizioni è il seguente.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>/<em>partition-path</em>'</code></pre>
    
      <h2 id="c-spectrum-column-mapping-delta">Creazione di tabelle esterne per i dati gestiti in Delta Lake</h2>
      <p>Per eseguire una query sui dati nelle tabelle Delta Lake, è possibile utilizzare le tabelle esterne di Amazon Redshift Spectrum. </p>
         <p>Per accedere a una tabella Delta Lake da Redshift Spectrum, generare un manifest prima della query. Un <em>manifest</em> Delta Lake contiene un elenco di file che costituiscono uno snapshot coerente della tabella Delta Lake. In una tabella partizionata, esiste un solo manifest per partizione. Una tabella Delta Lake è una raccolta di file Apache Parquet archiviati in Amazon S3. Per ulteriori informazioni, consultare <a href="https://delta.io" rel="noopener noreferrer" target="_blank"><span>Delta Lake</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> nella documentazione open source di Delta Lake. </p>
      <p>Quando si crea una tabella esterna che fa riferimento ai dati nelle tabelle Delta Lake, viene mappata ogni colonna della tabella a una colonna nella tabella Delta Lake. La mappatura viene eseguita per nome della colonna. </p>
      
      <p>La DDL per le tabelle Delta Lake partizionate e non partizionate è simile a quella degli altri formati di file Apache Parquet. Per le tabelle Delta Lake, è possibile definire <code class="code">INPUTFORMAT</code> come <code class="code">org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat</code> e <code class="code">OUTPUTFORMAT</code> come <code class="code">org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</code>. Il parametro <code class="code">LOCATION</code> deve puntare alla cartella del manifest nella cartella di base della tabella. Se un'operazione SELECT su una tabella Delta Lake non riesce per vari possibili motivi, consultare <a href="#c-spectrum-column-mapping-delta-limitations">Limitazioni e risoluzione dei problemi per le tabelle Delta Lake</a>. </p>
      <p>Il formato DDL per definire una tabella non partizionata è il seguente. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest'</code></pre>
      <p>Il formato DDL per definire una tabella partizionata è il seguente. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
PARTITIONED BY(<em>pcolumn1</em> <em>pcolumn1-type</em>[,...])
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION 's3://<em>s3-bucket</em>&gt;/<em>prefix</em>/_symlink_format_manifest'</code></pre>
      <p>Per aggiungere partizioni a una tabella Delta Lake partizionata, eseguire un comando ALTER TABLE ADD PARTITION in cui il parametro <code class="code">LOCATION</code> punta alla sottocartella Amazon S3 che contiene il manifest per la partizione.</p>
      <p>Il formato DDL per aggiungere le partizioni è il seguente.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION
's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest/<em>partition-path</em>'</code></pre>
      <p>Oppure eseguire la DDL che punta direttamente al file manifest di Delta Lake.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copia"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION
's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest/<em>partition-path</em>/manifest'</code></pre>
      
       
         <h3 id="c-spectrum-column-mapping-delta-limitations">Limitazioni e risoluzione dei problemi per le tabelle Delta Lake</h3>
       
      <p>Quando si eseguono query sulle tabelle Delta Lake da Redshift Spectrum, tenere presente quanto segue:</p>
      <div class="itemizedlist">
          
          
      <ul class="itemizedlist"><li class="listitem"><p>Se un manifest punta a uno snapshot o una partizione che non esiste più, le query hanno esito negativo fino a quando non viene generato un nuovo manifest valido. Ad esempio, questo potrebbe derivare da un'operazione VACUUM sulla tabella sottostante,</p></li><li class="listitem"><p>I manifest di Delta Lake forniscono coerenza solo a livello di partizione. </p></li></ul></div>
      <p>Nella tabella seguente vengono illustrati alcuni potenziali motivi per alcuni errori quando si esegue una query su una tabella Delta Lake. </p>
      <div class="table-container"><div class="table-contents"><table id="w319aac29c19c49c37"><thead>
               <tr>
                  <th>Messaggio di errore</th>
                  <th>Motivo possibile</th>
               </tr>
            </thead>
               
               
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Il manifest di Delta Lake nel bucket <em>s3-bucket-1</em> non può contenere voci nel bucket <em>s3-bucket-2</em>.</code></strong></p></td>
                  <td tabindex="-1"><p>Le voci del manifest puntano a file in un bucket Amazon S3 diverso da quello specificato. </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>I file Delta Lake dovrebbero trovarsi nella stessa cartella.</code></strong></p></td>
                  <td tabindex="-1"><p>Le voci del manifest puntano a file che hanno un prefisso Amazon S3 diverso da quello specificato.</p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Il file <em>nomefile</em> elencato nel manifest Delta Lake <em>percorso manifest</em> non è stato trovato.</code></strong></p></td>
                  <td tabindex="-1"><p>Un file elencato nel manifest non è stato trovato in Amazon S3. </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Errore durante il recupero del manifesto Delta Lake.</code></strong></p></td>
                  <td tabindex="-1"><p>Il manifest non è stato trovato in Amazon S3. </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Percorso S3 non valido.</code></strong></p></td>
                  <td tabindex="-1"><p>Una voce nel file manifest non è un percorso Amazon S3 valido o il file manifest è stato danneggiato. </p></td>
               </tr>

            </table></div></div>
      
   <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Avvertimento" /> <strong>JavaScript è disabilitato o non è disponibile nel tuo browser.</strong></p><p>Per usare la documentazione AWS, JavaScript deve essere abilitato. Consulta le pagine della guida del browser per le istruzioni.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="/general/latest/gr/docconventions.html">Convenzioni dei documenti</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./c-spectrum-external-schemas.html">Creazione di schemi esterni</div><div id="next" class="next-link" accesskey="n" href="./querying-iceberg.html">Utilizzo di tabelle Apache Iceberg</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Questa pagina ti è stata utile? - Sì</div><div class="content"><p>Grazie per averci comunicato che stiamo facendo un buon lavoro!</p><p>Se hai un momento, ti invitiamo a dirci che cosa abbiamo fatto che ti è piaciuto così possiamo offrirti altri contenuti simili.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Questa pagina ti è stata utile? - No</div><div class="content"><p>Grazie per averci comunicato che questa pagina ha bisogno di essere modificata. Siamo spiacenti di non aver soddisfatto le tue esigenze.</p><p>Se hai un momento, ti invitiamo a dirci come possiamo migliorare la documentazione.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>