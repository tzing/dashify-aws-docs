<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Step 5: Run the COPY commands - Amazon Redshift</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="tutorial-loading-run-copy" /><meta name="default_state" content="tutorial-loading-run-copy" /><link rel="icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="canonical" href="https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-run-copy.html" /><meta name="description" content="Learn basic COPY command syntax, and then run the COPY command in your SQL client with different options to learn how to load tables using different file formats." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon Redshift" /><meta name="guide" content="Database Developer Guide" /><meta name="abstract" content="Create and manage a data warehouse with Amazon Redshift, an enterprise-level, petabyte scale, fully managed data warehousing service." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-run-copy.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="de" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="en-us" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="zh-tw" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-run-copy.html" hreflang="x-default" /><meta name="feedback-item" content="Redshift" /><meta name="this_doc_product" content="Amazon Redshift" /><meta name="this_doc_guide" content="Database Developer Guide" /><script defer="" src="/assets/r/vendor4.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor3.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor1.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-common.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-doc-page.js?version=2021.12.02"></script><link href="/assets/r/vendor4.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-common.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-doc-page.css?version=2021.12.02" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'redshift'}"></script><meta id="panorama-serviceSubSection" value="Database Developer Guide" /><meta id="panorama-serviceConsolePage" value="Step 5: Run the COPY commands" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Step 5: Run the COPY commands - Amazon Redshift</title><meta name="pdf" content="/pdfs/redshift/latest/dg/redshift-dg.pdf#tutorial-loading-run-copy" /><meta name="rss" content="Dochistory.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=155" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/tutorial-loading-run-copy.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/tutorial-loading-run-copy.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/tutorial-loading-run-copy.html" /><meta name="keywords" content="Amazon Redshift,AWS Redshift,Redshift,Redshift Spectrum,cluster,data warehouse,developer,sample data,database,database developer,HLL" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon Redshift",
        "item" : "https://docs.aws.amazon.com/redshift/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Database Developer Guide",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Loading data",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/t_Loading_data.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Tutorial: Loading data from Amazon S3",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-data.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Step 5: Run the COPY commands",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-data.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="/pdfs/redshift/latest/dg/redshift-dg.pdf#tutorial-loading-run-copy" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="/index.html">Documentation</a><a href="/redshift/index.html">Amazon Redshift</a><a href="welcome.html">Database Developer Guide</a></div><div id="page-toc-src"><a href="#tutorial-loading-data-copy-syntax">COPY command syntax</a><a href="#tutorial-loading-run-copy-load-tables">Loading the SSB
                    tables</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="tutorial-loading-run-copy">Step 5: Run the COPY commands</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>You run COPY commands to load each of the tables in the SSB schema. The COPY command
            examples demonstrate loading from different file formats, using several COPY command
            options, and troubleshooting load errors.</p><div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="#tutorial-loading-data-copy-syntax">COPY command syntax</a></li><li><a href="#tutorial-loading-run-copy-load-tables">Loading the SSB
                    tables</a></li></ul></div>
            <h2 id="tutorial-loading-data-copy-syntax">COPY command syntax</h2>


            <p>The basic <a href="./r_COPY.html">COPY</a> command syntax is as
                follows. </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">COPY table_name [ column_list ] FROM data_source CREDENTIALS access_credentials [options] </code></pre>
            <p>To run a COPY command, you provide the following values. </p>
             
                <h6>Table name </h6>
                <p>The target table for the COPY command. The table must already exist in the
                    database. The table can be temporary or persistent. The COPY command appends the
                    new input data to any existing rows in the table. </p>
             
             
                <h6>Column list</h6>
                <p>By default, COPY loads fields from the source data to the table columns in
                    order. You can optionally specify a <em>column list,</em> that is a
                    comma-separated list of column names, to map data fields to specific columns.
                    You don't use column lists in this tutorial. For more information, see
                        <a href="./copy-parameters-column-mapping.html#copy-column-list">Column List</a> in the COPY command reference.</p>
             
            <p><span class="topcon">Data
                    source</span></p>
            <p>You can use the COPY command to load data from an Amazon S3 bucket, an Amazon EMR cluster, a
                remote host using an SSH connection, or an Amazon DynamoDB table. For this tutorial, you
                load from data files in an Amazon S3 bucket. When loading from Amazon S3, you must provide the
                name of the bucket and the location of the data files. To do this, provide either an
                object path for the data files or the location of a manifest file that explicitly
                lists each data file and its location. </p>
            <div class="itemizedlist">
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Key prefix </p>
                    <p>An object stored in Amazon S3 is uniquely identified by an object key, which
                        includes the bucket name, folder names, if any, and the object name. A
                            <em>key prefix </em>refers to a set of objects
                        with the same prefix. The object path is a key prefix that the COPY command
                        uses to load all objects that share the key prefix. For example, the key
                        prefix <code class="code">custdata.txt</code> can refer to a single file or to a set of
                        files, including <code class="code">custdata.txt.001</code>,
                            <code class="code">custdata.txt.002</code>, and so on. </p>
                </li><li class="listitem">
                    <p>Manifest file</p>
                    <p>In some cases, you might need to load files with different prefixes, for
                        example from multiple buckets or folders. In others, you might need to
                        exclude files that share a prefix. In these cases, you can use a manifest
                        file. A <em>manifest file</em> explicitly lists
                        each load file and its unique object key. You use a manifest file to load
                        the PART table later in this tutorial. </p>
                </li></ul></div>
             
                <h6>Credentials</h6>
                <p>To access the AWS resources that contain the data to load, you must provide
                    AWS access credentials for a user with sufficient
                    privileges. 
                    
                    
                    
                    
                    These credentials include an IAM role Amazon Resource Name (ARN). 
                    To load data from Amazon S3, the credentials must include ListBucket and GetObject
                    permissions. Additional credentials are required if your data is encrypted.
                    
                        For more information, see <a href="./copy-parameters-authorization.html">Authorization parameters</a> in the COPY command
                    reference. For more information about managing access, go to <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html">Managing access permissions to your
                        Amazon S3 resources</a>. 
                    </p>
             
            <p><span class="topcon">Options</span></p>
            <p>You can specify a number of parameters with the COPY command to specify file
                formats, manage data formats, manage errors, and control other features. In this
                tutorial, you use the following COPY command options and features: </p>
            <div class="itemizedlist">
                 
                 
                 
                 
                 
                 
                 
                 
                 
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Key prefix</p>
                    <p>For information on how to load from multiple files by specifying a key prefix, see <a href="#tutorial-loading-load-part">Load the PART table using NULL
                        AS</a>.</p>
                </li><li class="listitem">
                    <p>CSV format</p>
                    <p>For information on how to load data that is in CSV format, see <a href="#tutorial-loading-load-part">Load the PART table using NULL
                        AS</a>.</p>
                </li><li class="listitem">
                    <p>NULL AS</p>
                    <p>For information on how to load PART using the NULL AS option, see <a href="#tutorial-loading-load-part">Load the PART table using NULL
                        AS</a>.</p>
                </li><li class="listitem">
                    <p>Character-delimited format</p>
                    <p>For information on how to use the DELIMITER option, see <a href="#tutorial-loading-load-supplier">Load the SUPPLIER table using
                        REGION</a>.</p>
                </li><li class="listitem">
                    <p>REGION</p>
                    <p>For information on how to use the REGION option, see <a href="#tutorial-loading-load-supplier">Load the SUPPLIER table using
                        REGION</a>.</p>
                </li><li class="listitem">
                    <p>Fixed-format width</p>
                    <p>For information on how to load the CUSTOMER table from fixed-width data, see <a href="#tutorial-loading-load-customer">Load the CUSTOMER table using
                        MANIFEST</a>.</p>
                </li><li class="listitem">
                    <p>MAXERROR</p>
                    <p>For information on how to use the MAXERROR option, see <a href="#tutorial-loading-load-customer">Load the CUSTOMER table using
                        MANIFEST</a>.</p>
                </li><li class="listitem">
                    <p>ACCEPTINVCHARS</p>
                    <p>For information on how to use the ACCEPTINVCHARS option, see <a href="#tutorial-loading-load-customer">Load the CUSTOMER table using
                        MANIFEST</a>.</p>
                </li><li class="listitem">
                    <p>MANIFEST</p>
                    <p>For information on how to use the MANIFEST option, see <a href="#tutorial-loading-load-customer">Load the CUSTOMER table using
                        MANIFEST</a>.</p>
                </li><li class="listitem">
                    <p>DATEFORMAT</p>
                    <p>For information on how to use the DATEFORMAT option, see <a href="#tutorial-loading-load-dwdate">Load the DWDATE table using
                        DATEFORMAT</a>.</p>
                </li><li class="listitem">
                    <p>GZIP, LZOP and BZIP2</p>
                    <p>For information on how to compress your files, see <a href="#tutorial-loading-load-lineorder">Load the LINEORDER table using
                        multiple files</a>.</p>
                </li><li class="listitem">
                    <p>COMPUPDATE</p>
                    <p>For information on how to use the COMPUPDATE option, see <a href="#tutorial-loading-load-lineorder">Load the LINEORDER table using
                        multiple files</a>.</p>
                </li><li class="listitem">
                    <p>Multiple files</p>
                    <p>For information on how to load multiple files, see <a href="#tutorial-loading-load-lineorder">Load the LINEORDER table using
                        multiple files</a>.</p>
                </li></ul></div>
         
            <h2 id="tutorial-loading-run-copy-load-tables">Loading the SSB
                    tables</h2>

            <p>You use the following COPY commands to load each of the tables in the SSB schema.
                The command to each table demonstrates different COPY options and troubleshooting
                techniques.</p>
            <p>To load the SSB tables, follow these steps: </p>
            <div class="orderedlist">
                 
                 
                 
                 
                 
                 
            <ol><li>
                    <p><a href="#tutorial-loading-run-copy-replaceables">Replace the bucket name
                        and AWS credentials</a></p>

                </li><li>
                    <p><a href="#tutorial-loading-load-part">Load the PART table using NULL
                        AS</a></p>

                </li><li>
                    <p><a href="#tutorial-loading-load-supplier">Load the SUPPLIER table using
                        REGION</a></p>

                </li><li>
                    <p><a href="#tutorial-loading-load-customer">Load the CUSTOMER table using
                        MANIFEST</a></p>

                </li><li>
                    <p><a href="#tutorial-loading-load-dwdate">Load the DWDATE table using
                        DATEFORMAT</a></p>

                </li><li>
                    <p><a href="#tutorial-loading-load-lineorder">Load the LINEORDER table using
                        multiple files</a></p>

                </li></ol></div>
             
                <h3 id="tutorial-loading-run-copy-replaceables">Replace the bucket name
                        and AWS credentials</h3>

                <p>The COPY commands in this tutorial are presented in the following
                    format.</p>
                
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy table from 's3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/<em>key_prefix</em>' 
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>'
options;</code></pre>
                
                <p>For each COPY command, do the following:</p>
                <div class="orderedlist">
                     
                     
                <ol><li>
                        <p>Replace <code class="replaceable">&lt;your-bucket-name&gt;</code> with the
                            name of a bucket in the same region as your cluster. </p>
                        <p>This step assumes the bucket and the cluster are in the same region.
                            Alternatively, you can specify the region using the <a href="./copy-parameters-data-source-s3.html#copy-region">REGION</a> option with the COPY command. </p>
                    </li><li>
                        <p>Replace <code class="replaceable">&lt;aws-account-id&gt;</code> and
                            <code class="replaceable">&lt;role-name&gt;</code> with your
                            own AWS account and IAM role. The segment of the credentials
                            string that is enclosed in single quotation marks must not contain any
                            spaces or line breaks. Note that the ARN might differ slightly in format than the sample. It's best to 
                            copy the ARN for the role from the IAM console, to ensure that it's accurate, when you run the COPY commands. </p>
                        
                    </li></ol></div>
             
             
                <h3 id="tutorial-loading-load-part">Load the PART table using NULL
                        AS</h3>

                <p>In this step, you use the CSV and NULL AS options to load the PART table. </p>
                <p>The COPY command can load data from multiple files in parallel, which is much
                    faster than loading from a single file. To demonstrate this principle, the data
                    for each table in this tutorial is split into eight files, even though the files
                    are very small. In a later step, you compare the time difference between loading
                    from a single file and loading from multiple files. For more information, see
                        <a href="./c_best-practices-use-multiple-files.html">Loading data files</a>. </p>
                 
                    <h6>Key prefix</h6>
                    <p>You can load from multiple files by specifying a key prefix for the file
                        set, or by explicitly listing the files in a manifest file. In this step,
                        you use a key prefix. In a later step, you use a manifest file. The key
                        prefix <code class="code">'s3://mybucket/load/part-csv.tbl'</code> loads the following
                        set of the files in the <code class="code">load</code> folder. </p>
                 
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">part-csv.tbl-000
part-csv.tbl-001
part-csv.tbl-002
part-csv.tbl-003
part-csv.tbl-004
part-csv.tbl-005
part-csv.tbl-006
part-csv.tbl-007
</code></pre>
                 
                    <h6>CSV format</h6>
                    <p>CSV, which stands for comma separated values, is a common format used for
                        importing and exporting spreadsheet data. CSV is more flexible than
                        comma-delimited format because it enables you to include quoted strings
                        within fields. The default quotation mark character for COPY from CSV format is a
                        double quotation mark ( " ), but you can specify another quotation mark character by
                        using the QUOTE AS option. When you use the quotation mark character within the
                        field, escape the character with an additional quotation mark character.</p>
                 
                <p>The following excerpt from a CSV-formatted data file for the PART table shows
                    strings enclosed in double quotation marks (<code class="code">"LARGE ANODIZED
                    BRASS"</code>). It also shows a string enclosed in two double quotation marks
                    within a quoted string (<code class="code">"MEDIUM ""BURNISHED"" TIN"</code>).</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">15,dark sky,MFGR#3,MFGR#47,MFGR#3438,indigo,"LARGE ANODIZED BRASS",45,LG CASE
22,floral beige,MFGR#4,MFGR#44,MFGR#4421,medium,"PROMO, POLISHED BRASS",19,LG DRUM
23,bisque slate,MFGR#4,MFGR#41,MFGR#4137,firebrick,"MEDIUM ""BURNISHED"" TIN",42,JUMBO JAR</code></pre>
                <p>The data for the PART table contains characters that cause COPY to fail. In
                    this exercise, you troubleshoot the errors and correct them. </p>
                <p>To load data that is in CSV format, add <code class="code">csv</code> to your COPY command.
                    Run the following command to load the PART table. </p>
                
                
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy part from 's3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/part-csv.tbl' 
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>'
csv;</code></pre>
                
                <p>You might get an error message similar to the following.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">An error occurred when executing the SQL command:
copy part from 's3://mybucket/load/part-csv.tbl' 
credentials' ...

ERROR: Load into table 'part' failed.  Check 'stl_load_errors' system table for details. [SQL State=XX000] 

Execution time: 1.46s

1 statement(s) failed.
1 statement(s) failed.</code></pre>
                <p>To get more information about the error, query the STL_LOAD_ERRORS table. The
                    following query uses the SUBSTRING function to shorten columns for readability
                    and uses LIMIT 10 to reduce the number of rows returned. You can adjust the
                    values in <code class="code">substring(filename,22,25)</code> to allow for the length of your
                    bucket name.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select query, substring(filename,22,25) as filename,line_number as line, 
substring(colname,0,12) as column, type, position as pos, substring(raw_line,0,30) as line_text,
substring(raw_field_value,0,15) as field_text, 
substring(err_reason,0,45) as reason
from stl_load_errors 
order by query desc
limit 10;</code></pre>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""> query  |    filename      | line |  column   |    type    | pos |      
--------+-------------------------+-----------+------------+------------+-----+----
 333765 | part-csv.tbl-000 |    1 |           |            |   0 |

 line_text        | field_text |                    reason
------------------+------------+----------------------------------------------
 15,NUL next,     |            | Missing newline: Unexpected character 0x2c f</code></pre>


                 
                    <h6>NULL AS</h6>
                    <p>The <code class="code">part-csv.tbl</code> data files use the NUL terminator character
                            (<code class="code">\x000</code> or <code class="code">\x0</code>) to indicate NULL values.</p>
                 
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Despite very similar spelling, NUL and NULL are not the same. NUL is a
                        UTF-8 character with codepoint <code class="code">x000</code> that is often used to
                        indicate end of record (EOR). NULL is a SQL value that represents an absence
                        of data. </p></div></div>
                <p>By default, COPY treats a NUL terminator character as an EOR character and
                    terminates the record, which often results in unexpected results or an error.
                    There is no single standard method of indicating NULL in text data. Thus, the
                    NULL AS COPY command option enables you to specify which character to substitute
                    with NULL when loading the table. In this example, you want COPY to treat the
                    NUL terminator character as a NULL value.</p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The table column that receives the NULL value must be configured as
                            <em>nullable.</em> That is, it must not include the NOT NULL
                        constraint in the CREATE TABLE specification.</p></div></div>
                <p>To load PART using the NULL AS option, run the following COPY
                    command.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy part from 's3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/part-csv.tbl' 
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
csv
null as '\000';</code></pre>
                
                <p>To verify that COPY loaded NULL values, run the following command to
                    select only the rows that contain NULL.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select p_partkey, p_name, p_mfgr, p_category from part where p_mfgr is null;</code></pre>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""> p_partkey |  p_name  | p_mfgr | p_category
-----------+----------+--------+------------
        15 | NUL next |        | MFGR#47
        81 | NUL next |        | MFGR#23
       133 | NUL next |        | MFGR#44 
(2 rows)</code></pre>
             

             
                <h3 id="tutorial-loading-load-supplier">Load the SUPPLIER table using
                        REGION</h3>

                <p>In this step, you use the DELIMITER and REGION options to load the SUPPLIER
                    table.</p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The files for loading the SUPPLIER table are provided in an AWS sample
                        bucket. You don't need to upload files for this step.</p></div></div>
                 
                    <h6>Character-Delimited Format</h6>
                    <p>The fields in a character-delimited file are separated by a specific
                        character, such as a pipe character ( | ), a comma ( , ) or a tab ( \t ).
                        Character-delimited files can use any single ASCII character, including one
                        of the nonprinting ASCII characters, as the delimiter. You specify the
                        delimiter character by using the DELIMITER option. The default delimiter is
                        a pipe character ( | ). </p>
                 
                <p>The following excerpt from the data for the SUPPLIER table uses pipe-delimited
                    format. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">1|1|257368|465569|41365|19950218|2-HIGH|0|17|2608718|9783671|4|2504369|92072|2|19950331|TRUCK
1|2|257368|201928|8146|19950218|2-HIGH|0|36|6587676|9783671|9|5994785|109794|6|19950416|MAIL</code></pre>

                
                 
                    <h6>REGION</h6>
                    <p>Whenever possible, you should locate your load data in the same AWS region
                        as your Amazon Redshift cluster. If your data and your cluster are in the same
                        region, you reduce latency and avoid
                        cross-region data transfer costs. For more information, see <a href="./c_loading-data-best-practices.html">Amazon Redshift best practices for loading
            data</a>
                    </p>
                 
                <p>If you must load data from a different AWS region, use the REGION option to
                    specify the AWS region in which the load data is located. If you specify a
                    region, all of the load data, including manifest files, must be in the named
                    region. For more information, see <a href="./copy-parameters-data-source-s3.html#copy-region">REGION</a>. </p>
                <p>If your cluster is in the US East (N. Virginia) Region, run the following
                    command to load the SUPPLIER table from pipe-delimited data in an Amazon S3 bucket
                    located in the US West (Oregon) Region. For this example, do not change the
                    bucket name. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy supplier from 's3://awssampledbuswest2/ssbgz/supplier.tbl' 
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
delimiter '|' 
gzip
region 'us-west-2';</code></pre>
                
                <p>If your cluster is <em>not</em> in the US East (N. Virginia)
                    region, run the following command to load the SUPPLIER table from
                    pipe-delimited data in an Amazon S3 bucket located in the US East (N. Virginia)
                    region. For this example, do not change the bucket name.</p>
                
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy supplier from 's3://awssampledb/ssbgz/supplier.tbl' 
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
delimiter '|' 
gzip
region 'us-east-1';
</code></pre>
                
             

             
                <h3 id="tutorial-loading-load-customer">Load the CUSTOMER table using
                        MANIFEST</h3>

                <p>In this step, you use the FIXEDWIDTH, MAXERROR, ACCEPTINVCHARS, and MANIFEST
                    options to load the CUSTOMER table.</p>
                <p>The sample data for this exercise contains characters that cause errors when
                    COPY attempts to load them. You use the MAXERRORS option and the STL_LOAD_ERRORS
                    system table to troubleshoot the load errors and then use the ACCEPTINVCHARS and
                    MANIFEST options to eliminate the errors.</p>
                 
                    <h6>Fixed-Width Format</h6>
                    <p>Fixed-width format defines each field as a fixed number of characters,
                        rather than separating fields with a delimiter. The following excerpt from
                        the data for the CUSTOMER table uses fixed-width format.</p>
                 
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">1   Customer#000000001   IVhzIApeRb           MOROCCO  0MOROCCO  AFRICA      25-705 
2   Customer#000000002   XSTf4,NCwDVaWNe6tE   JORDAN   6JORDAN   MIDDLE EAST 23-453
3   Customer#000000003   MG9kdTD              ARGENTINA5ARGENTINAAMERICA     11-783</code></pre>

                <p>The order of the label/width pairs must match the order of the table columns
                    exactly. For more information, see <a href="./copy-parameters-data-format.html#copy-fixedwidth">FIXEDWIDTH</a>.</p>
                <p>The fixed-width specification string for the CUSTOMER table data is as
                    follows.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">fixedwidth 'c_custkey:10, c_name:25, c_address:25, c_city:10, c_nation:15, 
c_region :12, c_phone:15,c_mktsegment:10'</code></pre>
                <p>To load the CUSTOMER table from fixed-width data, run the following
                    command.</p>
                
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy customer
from 's3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl'
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
fixedwidth 'c_custkey:10, c_name:25, c_address:25, c_city:10, c_nation:15, c_region :12, c_phone:15,c_mktsegment:10';</code></pre>
                
                <p>You should get an error message, similar to the following.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">An error occurred when executing the SQL command:
copy customer
from 's3://mybucket/load/customer-fw.tbl'
credentials'...

ERROR: Load into table 'customer' failed.  Check 'stl_load_errors' system table for details. [SQL State=XX000] 

Execution time: 2.95s

1 statement(s) failed.</code></pre>
                 
                    <h6>MAXERROR</h6>
                    <p>By default, the first time COPY encounters an error, the command fails and
                        returns an error message. To save time during testing, you can use the
                        MAXERROR option to instruct COPY to skip a specified number of errors before
                        it fails. Because we expect errors the first time we test loading the
                        CUSTOMER table data, add <code class="code">maxerror 10</code> to the COPY command.
                    </p>
                 
                <p>To test using the FIXEDWIDTH and MAXERROR options, run the following
                    command.</p>
                
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy customer
from 's3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl'
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
fixedwidth 'c_custkey:10, c_name:25, c_address:25, c_city:10, c_nation:15, c_region :12, c_phone:15,c_mktsegment:10'
maxerror 10;</code></pre>
                
                <p>This time, instead of an error message, you get a warning message similar to
                    the following.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">Warnings:
Load into table 'customer' completed, 112497 record(s) loaded successfully.
Load into table 'customer' completed, 7 record(s) could not be loaded.  Check 'stl_load_errors' system table for details.</code></pre>
                <p>The warning indicates that COPY encountered seven errors. To check the errors,
                    query the STL_LOAD_ERRORS table, as shown in the following example.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select query, substring(filename,22,25) as filename,line_number as line, 
substring(colname,0,12) as column, type, position as pos, substring(raw_line,0,30) as line_text,
substring(raw_field_value,0,15) as field_text, 
substring(err_reason,0,45) as error_reason
from stl_load_errors 
order by query desc, filename 
limit 7;</code></pre>
                <p>The results of the STL_LOAD_ERRORS query should look similar to the
                    following.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""> query  |         filename          | line |  column   |    type    | pos |           line_text           | field_text |              error_reason
--------+---------------------------+------+-----------+------------+-----+-------------------------------+------------+----------------------------------------------
 334489 | customer-fw.tbl.log       |    2 | c_custkey | int4       |  -1 | customer-fw.tbl               | customer-f | Invalid digit, Value 'c', Pos 0, Type: Integ
 334489 | customer-fw.tbl.log       |    6 | c_custkey | int4       |  -1 | Complete                      | Complete   | Invalid digit, Value 'C', Pos 0, Type: Integ
 334489 | customer-fw.tbl.log       |    3 | c_custkey | int4       |  -1 | #Total rows                   | #Total row | Invalid digit, Value '#', Pos 0, Type: Integ
 334489 | customer-fw.tbl.log       |    5 | c_custkey | int4       |  -1 | #Status                       | #Status    | Invalid digit, Value '#', Pos 0, Type: Integ
 334489 | customer-fw.tbl.log       |    1 | c_custkey | int4       |  -1 | #Load file                    | #Load file | Invalid digit, Value '#', Pos 0, Type: Integ
 334489 | customer-fw.tbl000        |    1 | c_address | varchar    |  34 | 1         Customer#000000001  | .Mayag.ezR | String contains invalid or unsupported UTF8
 334489 | customer-fw.tbl000        |    1 | c_address | varchar    |  34 | 1         Customer#000000001  | .Mayag.ezR | String contains invalid or unsupported UTF8
(7 rows)</code></pre>
                <p>By examining the results, you can see that there are two messages in the
                        <code class="code">error_reasons</code> column:</p>
                <div class="itemizedlist">
                     
                     
                <ul class="itemizedlist"><li class="listitem">
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">Invalid digit, Value '#', Pos 0, Type: Integ </code></pre>
                        <p>These errors are caused by the <code class="code">customer-fw.tbl.log</code> file.
                            The problem is that it is a log file, not a data file, and should not be
                            loaded. You can use a manifest file to avoid loading the wrong file.
                        </p>
                    </li><li class="listitem">
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">String contains invalid or unsupported UTF8 </code></pre>
                        <p>The VARCHAR data type supports multibyte UTF-8 characters up to three
                            bytes. If the load data contains unsupported or invalid characters, you
                            can use the ACCEPTINVCHARS option to replace each invalid character with
                            a specified alternative character.</p>
                    </li></ul></div>
                <p>Another problem with the load is more difficult to detect—the load
                    produced unexpected results. To investigate this problem, run the following
                    command to query the CUSTOMER table.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select c_custkey, c_name, c_address        
from customer
order by c_custkey
limit 10;
</code></pre>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""> c_custkey |          c_name           |         c_address
-----------+---------------------------+---------------------------
         2 | Customer#000000002        | XSTf4,NCwDVaWNe6tE
         2 | Customer#000000002        | XSTf4,NCwDVaWNe6tE
         3 | Customer#000000003        | MG9kdTD
         3 | Customer#000000003        | MG9kdTD
         4 | Customer#000000004        | XxVSJsL
         4 | Customer#000000004        | XxVSJsL
         5 | Customer#000000005        | KvpyuHCplrB84WgAi
         5 | Customer#000000005        | KvpyuHCplrB84WgAi
         6 | Customer#000000006        | sKZz0CsnMD7mp4Xd0YrBvx
         6 | Customer#000000006        | sKZz0CsnMD7mp4Xd0YrBvx
(10 rows)</code></pre>
                <p>The rows should be unique, but there are duplicates. </p>
                <p>Another way to check for unexpected results is to verify the number of rows
                    that were loaded. In our case, 100000 rows should have been loaded, but the load
                    message reported loading 112497 records. The extra rows were loaded because the
                    COPY loaded an extraneous file, <code class="code">customer-fw.tbl0000.bak</code>. </p>
                <p>In this exercise, you use a manifest file to avoid loading the wrong files. </p>
                 
                    <h6>ACCEPTINVCHARS</h6>
                    <p>By default, when COPY encounters a character that is not supported by the
                        column's data type, it skips the row and returns an error. For information
                        about invalid UTF-8 characters, see <a href="./multi-byte-character-load-errors.html">Multibyte character load
                  errors</a>. </p>
                 
                <p>You could use the MAXERRORS option to ignore errors and continue loading, then
                    query STL_LOAD_ERRORS to locate the invalid characters, and then fix the data
                    files. However, MAXERRORS is best used for troubleshooting load problems and
                    should generally not be used in a production environment. </p>
                <p>The ACCEPTINVCHARS option is usually a better choice for managing invalid
                    characters. ACCEPTINVCHARS instructs COPY to replace each invalid character with
                    a specified valid character and continue with the load operation. You can
                    specify any valid ASCII character, except NULL, as the replacement character.
                    The default replacement character is a question mark ( ? ). COPY replaces
                    multibyte characters with a replacement string of equal length. For example, a
                    4-byte character would be replaced with <code class="code">'????'</code>. </p>
                <p>COPY returns the number of rows that contained invalid UTF-8 characters. It
                    also adds an entry to the STL_REPLACEMENTS system table for each affected row,
                    up to a maximum of 100 rows per node slice. Additional invalid UTF-8 characters
                    are also replaced, but those replacement events are not recorded. </p>
                <p>ACCEPTINVCHARS is valid only for VARCHAR columns. </p>
                <p>For this step, you add the ACCEPTINVCHARS with the replacement character
                        <code class="code">'^'</code>. </p>
                 
                    <h6>MANIFEST</h6>
                    <p>When you COPY from Amazon S3 using a key prefix, there is a risk that you might
                        load unwanted tables. For example, the <code class="code">'s3://mybucket/load/</code>
                        folder contains eight data files that share the key prefix
                            <code class="code">customer-fw.tbl</code>: <code class="code">customer-fw.tbl0000</code>,
                            <code class="code">customer-fw.tbl0001</code>, and so on. However, the same folder
                        also contains the extraneous files <code class="code">customer-fw.tbl.log</code> and
                            <code class="code">customer-fw.tbl-0001.bak</code>. </p>
                 
                <p>To ensure that you load all of the correct files, and only the correct files,
                    use a manifest file. The manifest is a text file in JSON format that explicitly
                    lists the unique object key for each source file to be loaded. The file objects
                    can be in different folders or different buckets, but they must be in the same
                    region. For more information, see <a href="./copy-parameters-data-source-s3.html#copy-manifest">MANIFEST</a>.</p>
                <p>The following shows the <code class="code">customer-fw-manifest</code> text. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight"><span>{</span>
  "entries": [
    <span>{</span>"url":"s3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl-000"},
    <span>{</span>"url":"s3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl-001"},
    <span>{</span>"url":"s3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl-002"},
    <span>{</span>"url":"s3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl-003"},
    <span>{</span>"url":"s3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl-004"},    
    <span>{</span>"url":"s3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl-005"},
    <span>{</span>"url":"s3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl-006"}, 
    <span>{</span>"url":"s3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw.tbl-007"} 
    ]
}</code></pre>
                <div class="procedure"><h6>To load the data for the CUSTOMER table using the manifest file</h6><ol><li>
                        <p>Open the file <code class="code">customer-fw-manifest</code> in a text
                            editor.</p>
                    </li><li>
                        <p>Replace <code class="replaceable">&lt;your-bucket-name&gt;</code> with the
                            name of your bucket.</p>
                    </li><li>
                        <p>Save the file.</p>
                    </li><li>
                        <p>Upload the file to the load folder on your bucket.</p>
                    </li><li>
                        <p>Run the following COPY command.</p>
                        
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy customer from 's3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/customer-fw-manifest'
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
fixedwidth 'c_custkey:10, c_name:25, c_address:25, c_city:10, c_nation:15, c_region :12, c_phone:15,c_mktsegment:10'
maxerror 10 
acceptinvchars as '^'
manifest;</code></pre>
                        
                    </li></ol></div>
             
             
                <h3 id="tutorial-loading-load-dwdate">Load the DWDATE table using
                        DATEFORMAT</h3>

                <p>In this step, you use the DELIMITER and DATEFORMAT options to load the DWDATE
                    table.</p>
                
                <p>When loading DATE and TIMESTAMP columns, COPY expects the default format,
                    which is YYYY-MM-DD for dates and YYYY-MM-DD HH:MI:SS for timestamps. If the
                    load data does not use a default format, you can use DATEFORMAT and TIMEFORMAT
                    to specify the format. </p>
                <p>The following excerpt shows date formats in the DWDATE table. Notice that the
                    date formats in column two are inconsistent.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">19920104	1992-01-04          Sunday		January	1992	199201	Jan1992	1	4	4	1...
19920112	January 12, 1992	Monday		January	1992	199201	Jan1992	2	12	12	1...
19920120	January 20, 1992	Tuesday	    January	1992	199201	Jan1992	3	20	20	1...</code></pre>
                 
                    <h6>DATEFORMAT</h6>
                    <p>You can specify only one date format. If the load data contains
                        inconsistent formats, possibly in different columns, or if the format is not
                        known at load time, you use DATEFORMAT with the <code class="code">'auto'</code>
                        argument. When <code class="code">'auto'</code> is specified, COPY recognizes any valid
                        date or time format and convert it to the default format. The
                            <code class="code">'auto'</code> option recognizes several formats that are not
                        supported when using a DATEFORMAT and TIMEFORMAT string. For more
                        information, see <a href="./automatic-recognition.html">Using automatic recognition with DATEFORMAT and
               TIMEFORMAT</a>. </p>
                 
                <p>To load the DWDATE table, run the following COPY command.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy dwdate from 's3://<code class="replaceable">&lt;your-bucket-name&gt;</code>/load/dwdate-tab.tbl'
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
delimiter '\t' 
dateformat 'auto';</code></pre>
                
             
             
                <h3 id="tutorial-loading-load-lineorder">Load the LINEORDER table using
                        multiple files</h3>

                <p>This step uses the GZIP and COMPUPDATE options to load the LINEORDER
                    table.</p>
                <p>In this exercise, you load the LINEORDER table from a single data file and
                    then load it again from multiple files. Doing this enables you to compare the
                    load times for the two methods. </p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The files for loading the LINEORDER table are provided in an AWS sample
                        bucket. You don't need to upload files for this step.</p></div></div>
                 
                    <h6>GZIP, LZOP and BZIP2</h6>
                    <p>You can compress your files using either gzip, lzop, or bzip2 compression
                        formats. When loading from compressed files, COPY uncompresses the files
                        during the load process. Compressing your files saves storage space and
                        shortens upload times. </p>
                 
                 
                    <h6>COMPUPDATE</h6>
                    <p>When COPY loads an empty table with no compression encodings, it analyzes
                        the load data to determine the optimal encodings. It then alters the table
                        to use those encodings before beginning the load. This analysis process
                        takes time, but it occurs, at most, once per table. To save time, you can
                        skip this step by turning COMPUPDATE off. To enable an accurate evaluation
                        of COPY times, you turn COMPUPDATE off for this step.</p>
                 
                 
                    <h6>Multiple Files</h6>
                    <p>The COPY command can load data very efficiently when it loads from
                        multiple files in parallel instead of from a single file. You can split your
                        data into files so that the number of files is a multiple of the number of
                        slices in your cluster. If you do, Amazon Redshift divides the workload and
                        distributes the data evenly among the slices. The number of slices per node
                        depends on the node size of the cluster. For more information about the
                        number of slices that each node size has, go to <a href="https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#rs-about-clusters-and-nodes">About clusters and nodes</a> in the
                            <em>Amazon Redshift Management Guide</em>.</p>
                 
                <p>For example, the dc2.large compute nodes used in this tutorial have two slices
                    each, so the four-node cluster has eight slices. In previous steps, the load
                    data was contained in eight files, even though the files are very small. In this
                    step, you compare the time difference between loading from a single large file
                    and loading from multiple files. </p>
                <p>The files you use for this tutorial contain about 15 million records and
                    occupy about 1.2 GB. These files are very small in Amazon Redshift scale, but
                    sufficient to demonstrate the performance advantage of loading from multiple
                    files. The files are large enough that the time required to download them and
                    then upload them to Amazon S3 is excessive for this tutorial. Thus, you load the
                    files directly from an AWS sample bucket. </p>
                <p>The following screenshot shows the data files for LINEORDER.</p>

                <div class="mediaobject">
                     
                        <img src="/images/redshift/latest/dg/images/tutorial-load-lineorder-files.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                     
                </div>
                <div class="procedure"><h6>To evaluate the performance of COPY with multiple files</h6><ol><li>
                        <p>Run the following command to COPY from a single file. Do not
                            change the bucket name.</p>
                        
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy lineorder from 's3://awssampledb/load/lo/lineorder-single.tbl' 
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
gzip
compupdate off
region 'us-east-1';</code></pre>
                        
                    </li><li>
                        <p>Your results should be similar to the following. Note the execution
                            time.</p>
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">Warnings:
Load into table 'lineorder' completed, 14996734 record(s) loaded successfully.

0 row(s) affected.
copy executed successfully

Execution time: 51.56s</code></pre>
                    </li><li>
                        <p>Run the following command to COPY from multiple files. Do not
                            change the bucket name.</p>
                        
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">copy lineorder from 's3://awssampledb/load/lo/lineorder-multi.tbl' 
credentials 'aws_iam_role=arn:aws:iam::<code class="replaceable">&lt;aws-account-id&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' 
gzip
compupdate off
region 'us-east-1';
</code></pre>
                        
                    </li><li>
                        <p>Your results should be similar to the following. Note the execution
                            time.</p>
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">Warnings:
Load into table 'lineorder' completed, 14996734 record(s) loaded successfully.

0 row(s) affected.
copy executed successfully

Execution time: 17.7s</code></pre>
                    </li><li>
                        <p>Compare execution times.</p>
                        <p>In our example, the time to load 15 million records decreased from
                            51.56 seconds to 17.7 seconds, a reduction of 65.7 percent. </p>
                        <p>These results are based on using a four-node cluster. If your cluster
                            has more nodes, the time savings is multiplied. For typical Amazon Redshift
                            clusters, with tens to hundreds of nodes, the difference is even more
                            dramatic. If you have a single node cluster, there is little difference
                            between the execution times. </p>
                    </li></ol></div>
             
             
                <h3 id="tutorial-loading-next-step6">Next step</h3>

                <p><a href="./tutorial-loading-data-vacuum.html">Step 6: Vacuum and analyze the
                database</a></p>
             
        <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./tutorial-loading-data-create-tables.html">Step 4: Create the sample tables</div><div id="next" class="next-link" accesskey="n" href="./tutorial-loading-data-vacuum.html">Step 6: Vacuum and analyze the database</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/tutorial-loading-run-copy.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/tutorial-loading-run-copy.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>