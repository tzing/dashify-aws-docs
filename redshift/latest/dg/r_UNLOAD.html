<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>UNLOAD - Amazon Redshift</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="r_UNLOAD" /><meta name="default_state" content="r_UNLOAD" /><link rel="icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="canonical" href="https://docs.aws.amazon.com/redshift/latest/dg/r_UNLOAD.html" /><meta name="description" content="Unloads the result of a query to one or more files on Amazon Simple Storage Service(Amazon S3)." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon Redshift" /><meta name="guide" content="Database Developer Guide" /><meta name="abstract" content="Create and manage a data warehouse with Amazon Redshift, an enterprise-level, petabyte scale, fully managed data warehousing service." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="https://docs.aws.amazon.com/redshift/latest/dg/r_UNLOAD.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/r_UNLOAD.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/r_UNLOAD.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/r_UNLOAD.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/r_UNLOAD.html" hreflang="de" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/r_UNLOAD.html" hreflang="en-us" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/r_UNLOAD.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/r_UNLOAD.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/r_UNLOAD.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/r_UNLOAD.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/r_UNLOAD.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/r_UNLOAD.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/r_UNLOAD.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/r_UNLOAD.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/r_UNLOAD.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/r_UNLOAD.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/r_UNLOAD.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/r_UNLOAD.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/r_UNLOAD.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_UNLOAD.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/redshift/latest/dg/r_UNLOAD.html" hreflang="zh-tw" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/r_UNLOAD.html" hreflang="x-default" /><meta name="feedback-item" content="Redshift" /><meta name="this_doc_product" content="Amazon Redshift" /><meta name="this_doc_guide" content="Database Developer Guide" /><script defer="" src="/assets/r/vendor4.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor3.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor1.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-common.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-doc-page.js?version=2021.12.02"></script><link href="/assets/r/vendor4.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-common.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-doc-page.css?version=2021.12.02" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'redshift'}"></script><meta id="panorama-serviceSubSection" value="Database Developer Guide" /><meta id="panorama-serviceConsolePage" value="UNLOAD" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>UNLOAD - Amazon Redshift</title><meta name="pdf" content="/pdfs/redshift/latest/dg/redshift-dg.pdf#r_UNLOAD" /><meta name="rss" content="Dochistory.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=155" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_UNLOAD.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_UNLOAD.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_UNLOAD.html" /><meta name="keywords" content="Amazon Redshift,AWS Redshift,Redshift,Redshift Spectrum,cluster,data warehouse,developer,sample data,database,database developer,HLL" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon Redshift",
        "item" : "https://docs.aws.amazon.com/redshift/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Database Developer Guide",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "SQL reference",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/cm_chap_SQLCommandRef.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "SQL commands",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/c_SQL_commands.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "UNLOAD",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/c_SQL_commands.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="/pdfs/redshift/latest/dg/redshift-dg.pdf#r_UNLOAD" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="/index.html">Documentation</a><a href="/redshift/index.html">Amazon Redshift</a><a href="welcome.html">Database Developer Guide</a></div><div id="page-toc-src"><a href="#r_UNLOAD-permissions">Required privileges and permissions</a><a href="#r_UNLOAD-synopsis">Syntax</a><a href="#unload-parameters">Parameters</a><a href="#unload-usage-notes">Usage notes</a><a href="#r_UNLOAD-examples">Examples</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="r_UNLOAD">UNLOAD</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Unloads the result of a query to one or more text, JSON, or Apache Parquet files on Amazon S3, using
         Amazon S3 server-side encryption (SSE-S3). You can also specify server-side encryption with an
         AWS Key Management Service key (SSE-KMS) or client-side encryption with a customer managed key.</p><p>By default, the format of the unloaded file is pipe-delimited ( <code class="code">|</code> ) text.</p><p>You can manage the size of files on Amazon S3, and by extension the number of files, by
         setting the MAXFILESIZE parameter. Ensure that the S3 IP ranges are added to your allow list. To learn more about
         the required S3 IP ranges, see <a href="https://docs.aws.amazon.com/redshift/latest/mgmt/security-network-isolation.html#network-isolation">
            Network isolation</a>.</p><p>You can unload the result of an Amazon Redshift query to your Amazon S3 data lake in Apache Parquet, an
         efficient open columnar storage format for analytics. Parquet format is up to 2x faster to
         unload and consumes up to 6x less storage in Amazon S3, compared with text formats. This enables
         you to save data transformation and enrichment you have done in Amazon S3 into your Amazon S3 data
         lake in an open format. You can then analyze your data with Redshift Spectrum and other AWS services
         such as Amazon Athena, Amazon EMR, and Amazon SageMaker. </p><p>For more information and example scenarios about using the UNLOAD command, see
         <a href="./c_unloading_data.html">Unloading data</a>.</p>
         <h2 id="r_UNLOAD-permissions">Required privileges and permissions</h2>
         <p>For the UNLOAD command to succeed, at least SELECT privilege on the data in the database is needed, along with permission to write to the Amazon S3 location. 
            The permissions needed are similar to the COPY command.
            For information about COPY command permissions, see <a href="./copy-usage_notes-access-permissions.html">Permissions to access other AWS
               Resources</a>.</p>
       
         <h2 id="r_UNLOAD-synopsis">Syntax</h2>
         
         
         
         
         
         
         
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">UNLOAD ('<em>select-statement</em>')
TO '<em>s3://object-path/name-prefix</em>'
<em>authorization</em>
[ <em>option</em>, ...] 

where <em>authorization</em> is
IAM_ROLE <span>{</span> default | 'arn:aws:iam::<code class="replaceable">&lt;AWS account-id-1&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>[,arn:aws:iam::<code class="replaceable">&lt;AWS account-id-2&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>][,...]' }
            
where <em>option</em> is
| [ FORMAT [ AS ] ] CSV | PARQUET | JSON
| PARTITION BY ( <em>column_name</em> [, ... ] ) [ INCLUDE ]
| MANIFEST [ VERBOSE ]
| HEADER
| DELIMITER [ AS ] '<em>delimiter-char</em>'
| FIXEDWIDTH [ AS ] '<em>fixedwidth-spec</em>'
| ENCRYPTED [ AUTO ]
| BZIP2
| GZIP
| ZSTD
| ADDQUOTES
| NULL [ AS ] '<em>null-string</em>'
| ESCAPE
| ALLOWOVERWRITE
| CLEANPATH
| PARALLEL [ <span>{</span> ON | TRUE } | <span>{</span> OFF | FALSE } ]
| MAXFILESIZE [AS] <em>max-size</em> [ MB | GB ]
| ROWGROUPSIZE [AS] <em>size</em> [ MB | GB ]
| REGION [AS] '<em>aws-region</em>' }
| EXTENSION '<em>extension-name</em>'

</code></pre>
       
         <h2 id="unload-parameters">Parameters</h2>
         <div class="variablelist">
             
             
             
             
            
            
             
            
            
            
             
             
             
             
             
             
             
             
             
             
             
             
             
             
             
             
             
            
             
             
             
            
             
         <dl>
               <dt><span class="term">('<em>select-statement</em>') </span></dt>
               <dd>
                  <p>A SELECT query. The results of the query are unloaded. In most cases, it is
                     worthwhile to unload data in sorted order by specifying an ORDER BY clause in
                     the query. This approach saves the time required to sort the data when it is
                     reloaded.
                     </p>
                  <p>The query must be enclosed in single quotation marks as shown following: </p>
                  <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">('select * from venue order by venueid')</code></pre>
                  <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>If your query contains quotation marks (for example to enclose literal
                        values), put the literal between two sets of single quotation
                        marks—you must also enclose the query between single quotation marks: </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">('select * from venue where venuestate=''NV''')</code></pre></div></div>
               </dd>
             
               <dt><span class="term">TO 's3://<em>object-path/name-prefix</em>' </span></dt>
               <dd>
                  <p>The full path, including bucket name, to the location on Amazon S3 where Amazon Redshift
                     writes the output file objects, including the manifest file if MANIFEST is
                     specified. The object names are prefixed with <em>name-prefix</em>.
                     If you use <code class="code">PARTITION BY</code>, a forward slash (/) is automatically
                     added to the end of the <em>name-prefix</em> value if needed. For
                     added security, UNLOAD connects to Amazon S3 using an HTTPS connection. By default,
                     UNLOAD writes one or more files per slice. UNLOAD appends a slice number and
                     part number to the specified name prefix as follows:</p>
                  <p><code class="code"><code class="replaceable">&lt;object-path&gt;</code>/<code class="replaceable">&lt;name-prefix&gt;</code><code class="replaceable">&lt;slice-number&gt;</code>_part_<code class="replaceable">&lt;part-number&gt;</code></code>. </p>
                  <p>If MANIFEST is specified, the manifest file is written as follows:</p>
                  <p><code class="code"><code class="replaceable">&lt;object_path&gt;</code>/<code class="replaceable">&lt;name_prefix&gt;</code>manifest</code>. </p>
                  <p>If PARALLEL is specified OFF, the data files are written as follows:</p>
                  <p><code class="code"><code class="replaceable">&lt;object_path&gt;</code>/<code class="replaceable">&lt;name_prefix&gt;</code><code class="replaceable">&lt;part-number&gt;</code></code>. </p>
                  <p>UNLOAD automatically creates encrypted files using Amazon S3 server-side
                     encryption (SSE), including the manifest file if MANIFEST is used. The COPY
                     command automatically reads server-side encrypted files during the load
                     operation. You can transparently download server-side encrypted files from your
                     bucket using either the Amazon S3 console or API. For more information, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html">Protecting Data Using
                        Server-Side Encryption</a>. </p>
                  <p>To use Amazon S3 client-side encryption, specify the ENCRYPTED option.</p>
                  <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>REGION is required when the Amazon S3 bucket isn't in the same AWS Region
                        as the Amazon Redshift database. </p></div></div>
               </dd>
             
               <dt><span class="term"><em>authorization</em></span></dt>
               <dd>
                  <p>The UNLOAD command needs authorization to write data to Amazon S3. The
                     UNLOAD command uses the same parameters the COPY command uses for
                     authorization. For more information, see <a href="./copy-parameters-authorization.html">Authorization parameters</a> in the COPY command syntax
                     reference.</p>
               </dd>
             
               <dt id="unload-iam"><span class="term">IAM_ROLE <span>{</span> default | 'arn:aws:iam::<code class="replaceable">&lt;AWS account-id-1&gt;</code>:role/<code class="replaceable">&lt;role-name&gt;</code>' </span></dt>
               <dd>
                  <p>Use the default keyword to have Amazon Redshift use the IAM role that is
                     set as default and associated with the cluster when the UNLOAD command
                     runs.</p>
                  <p>Use the Amazon Resource Name (ARN) for an IAM role that your cluster uses
                     for authentication and authorization. If you specify IAM_ROLE, you can't
                     use ACCESS_KEY_ID and SECRET_ACCESS_KEY, SESSION_TOKEN, or CREDENTIALS.
                     The IAM_ROLE can be chained. For more information, see
                     <a href="https://docs.aws.amazon.com/redshift/latest/mgmt/authorizing-redshift-service.html#authorizing-redshift-service-chaining-roles">Chaining IAM roles</a> in the <em>Amazon Redshift Management Guide</em>.</p>
               </dd>
             
               <dt id="unload-csv"><span class="term">[ FORMAT [AS] ] CSV | PARQUET | JSON</span></dt>
               <dd>
                  <p>Keywords to specify the unload format to override the default format. </p>
                  <p>When CSV, unloads to a text file in CSV format using a comma ( , ) character
                     as the default delimiter. If a field contains delimiters, double quotation
                     marks, newline characters, or carriage returns, then the field in the unloaded
                     file is enclosed in double quotation marks. A double quotation mark within a
                     data field is escaped by an additional double quotation mark.
                     When zero rows are unloaded, Amazon Redshift might write empty Amazon S3 objects.</p>
                  <p>When PARQUET, unloads to a file in Apache Parquet version 1.0 format. By
                     default, each row group is compressed using SNAPPY compression. For more
                     information about Apache Parquet format, see <a href="https://parquet.apache.org/" rel="noopener noreferrer" target="_blank"><span>Parquet</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. </p>
                  <p>When JSON, unloads to a JSON file with each line containing a JSON object, representing a full record in the query result.
                     Amazon Redshift supports writing nested JSON when the query result contains SUPER columns. To create a valid JSON object, the name of each column in the query must be unique.
                     In the JSON file, boolean values are unloaded as <code class="code">t</code> or <code class="code">f</code>, and NULL values are unloaded as <code class="code">null</code>.
                     When zero rows are unloaded, Amazon Redshift does not write Amazon S3 objects.</p>
                  <p>The FORMAT and AS keywords are optional. You can't use CSV with
                     FIXEDWIDTH or ADDQUOTES. 
                     You can't use PARQUET with DELIMITER, FIXEDWIDTH, ADDQUOTES, ESCAPE, NULL
                     AS, HEADER, GZIP, BZIP2, or ZSTD. PARQUET with ENCRYPTED is only supported with
                     server-side encryption with an AWS Key Management Service key (SSE-KMS). You can't use JSON with DELIMITER, HEADER, FIXEDWIDTH, ADDQUOTES, ESCAPE, or NULL AS.</p>
               </dd>
             
               <dt id="unload-partitionby"><span class="term">PARTITION BY ( <em>column_name</em> [, ... ] ) [INCLUDE]</span></dt>
               <dd>
                  <p>Specifies the partition keys for the unload operation. UNLOAD automatically
                     partitions output files into partition folders based on the partition key
                     values, following the Apache Hive convention. For example, a Parquet file that
                     belongs to the partition year 2019 and the month September has the following
                     prefix:
                        <code>s3://my_bucket_name/my_prefix/year=2019/month=September/000.parquet</code>. </p>
                  <p>The value for <em>column_name</em> must be a column in the query
                     results being unloaded. </p>
                  <p>If you specify PARTITION BY with the INCLUDE option, partition columns
                     aren't removed from the unloaded files. </p>

                  <p>Amazon Redshift doesn't support string literals in PARTITION BY clauses.</p>


               </dd>
             
               <dt><span class="term">MANIFEST [ VERBOSE ]</span></dt>
               <dd>
                  <p>Creates a manifest file that explicitly lists details for the data files
                     that are created by the UNLOAD process. The manifest is a text file in JSON
                     format that lists the URL of each file that was written to Amazon S3. </p>
                  <p>If MANIFEST is specified with the VERBOSE option, the manifest includes the
                     following details: </p>
                  <div class="itemizedlist">
                      
                      
                      
                      
                  <ul class="itemizedlist"><li class="listitem">
                        <p>The column names and data types, and for CHAR, VARCHAR, or NUMERIC
                           data types, dimensions for each column. For CHAR and VARCHAR data types,
                           the dimension is the length. For a DECIMAL or NUMERIC data type, the
                           dimensions are precision and scale. </p>
                     </li><li class="listitem">
                        <p>The row count unloaded to each file. If the HEADER option is
                           specified, the row count includes the header line. </p>
                     </li><li class="listitem">
                        <p>The total file size of all files unloaded and the total row count
                           unloaded to all files. If the HEADER option is specified, the row count
                           includes the header lines. </p>
                     </li><li class="listitem">
                        <p>The author. Author is always "Amazon Redshift".</p>
                     </li></ul></div>
                  <p>You can specify VERBOSE only following MANIFEST. </p>
                  <p>The manifest file is written to the same Amazon S3 path prefix as the unload
                     files in the format <code class="code">&lt;object_path_prefix&gt;manifest</code>. For
                     example, if UNLOAD specifies the Amazon S3 path prefix
                        '<code class="code">s3://mybucket/venue_</code>', the manifest file location is
                        '<code class="code">s3://mybucket/venue_manifest</code>'.</p>
               </dd>
             
               <dt><span class="term">HEADER</span></dt>
               <dd>
                  <p>Adds a header line containing column names at the top of each output file.
                     Text transformation options, such as CSV, DELIMITER, ADDQUOTES, and ESCAPE,
                     also apply to the header line. You can't use HEADER with
                     FIXEDWIDTH.</p>
               </dd>
             
               <dt><span class="term">DELIMITER AS '<em>delimiter_character</em>' </span></dt>
               <dd>
                  <p>Specifies a single ASCII character that is used to separate fields in the
                     output file, such as a pipe character ( | ), a comma ( , ), or a tab ( \t ).
                     The default delimiter for text files is a pipe character.
                      The default
                     delimiter for CSV files is a comma character. The AS keyword is optional. You
                     can't use DELIMITER with FIXEDWIDTH. If the data contains the delimiter
                     character, you need to specify the ESCAPE option to escape the delimiter, or
                     use ADDQUOTES to enclose the data in double quotation marks. Alternatively,
                     specify a delimiter that isn't contained in the data.</p>
               </dd>
             
               <dt><span class="term">FIXEDWIDTH '<em>fixedwidth_spec</em>' </span></dt>
               <dd>
                  <p>Unloads the data to a file where each column width is a fixed length, rather
                     than separated by a delimiter. The <em>fixedwidth_spec</em> is a
                     string that specifies the number of columns and the width of the columns. The
                     AS keyword is optional. Because FIXEDWIDTH doesn't truncate data, the
                     specification for each column in the UNLOAD statement needs to be at least as
                     long as the length of the longest entry for that column. The format for
                        <em>fixedwidth_spec</em> is shown below: </p>
                  <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">'<em>colID1:colWidth1,colID2:colWidth2, ...</em>'</code></pre>
                  <p>You can't use FIXEDWIDTH with DELIMITER or HEADER.</p>
               </dd>
             
               <dt id="unload-parameters-encrypted"><span class="term">ENCRYPTED [AUTO]</span></dt>
               <dd>
                  <p>Specifies that the output files on Amazon S3 are encrypted using Amazon S3 server-side
                     encryption or client-side encryption. If MANIFEST is specified, the manifest
                     file is also encrypted. For more information, see <a href="./t_unloading_encrypted_files.html">Unloading encrypted data files</a>. If you don't specify the
                     ENCRYPTED parameter, UNLOAD automatically creates encrypted files using Amazon S3
                     server-side encryption with AWS-managed encryption keys (SSE-S3). </p>
                  <p>For ENCRYPTED, you might want to unload to Amazon S3 using server-side encryption
                     with an AWS KMS key (SSE-KMS). If so, use the <a href="#unload-parameters-kms-key-id">KMS_KEY_ID</a> parameter to provide the key ID.
                     You can't use the <a href="./copy-parameters-authorization.html#copy-credentials">CREDENTIALS</a> parameter with the
                     KMS_KEY_ID parameter. If you run an UNLOAD command for data using KMS_KEY_ID,
                     you can then do a COPY operation for the same data without specifying a key. </p>
                  <p>To unload to Amazon S3 using client-side encryption with a customer-supplied
                     symmetric key, provide the key in one of two ways. To provide the
                     key, use the <a href="#unload-parameters-master-symmetric-key">MASTER_SYMMETRIC_KEY</a> parameter
                     or the <code class="code">master_symmetric_key</code> portion of a <a href="./copy-parameters-authorization.html#copy-credentials">CREDENTIALS</a> credential string. If you unload data using a
                     root symmetric key, make sure that you supply the same key when you perform a
                     COPY operation for the encrypted data. </p>
                  <p>UNLOAD doesn't support Amazon S3 server-side encryption with a
                     customer-supplied key (SSE-C). </p>
                  <p>If ENCRYPTED AUTO is used, the UNLOAD command fetches the default AWS KMS
                     encryption key on the target Amazon S3 bucket property and encrypts the files written to
                     Amazon S3 with the AWS KMS key. If the bucket doesn't have the default AWS KMS
                     encryption key, UNLOAD automatically creates encrypted files using Amazon Redshift
                     server-side encryption with AWS-managed encryption keys (SSE-S3). You

                     can't use this option with KMS_KEY_ID, MASTER_SYMMETRIC_KEY, or
                     CREDENTIALS that contains master_symmetric_key. </p>
               </dd>
             
               <dt id="unload-parameters-kms-key-id"><span class="term">KMS_KEY_ID '<em>key-id</em>'</span></dt>
               <dd>
                  <p>Specifies the key ID for an AWS Key Management Service (AWS KMS) key to be used to encrypt data
                     files on Amazon S3. For more information, see <a href="https://docs.aws.amazon.com/kms/latest/developerguide/overview.html">What is AWS Key Management Service?</a>
                     If you specify KMS_KEY_ID, you must specify the <a href="#unload-parameters-encrypted">ENCRYPTED</a> parameter also. If you specify
                     KMS_KEY_ID, you can't authenticate using the CREDENTIALS parameter.
                     Instead, use either <a href="./copy-parameters-authorization.html#copy-iam-role">IAM_ROLE</a> or <a href="./copy-parameters-authorization.html#copy-access-key-id">ACCESS_KEY_ID and SECRET_ACCESS_KEY</a>. </p>

               </dd>
             
               <dt id="unload-parameters-master-symmetric-key"><span class="term">MASTER_SYMMETRIC_KEY '<em>root_key</em>'</span></dt>
               <dd>
                  <p>Specifies the root symmetric key to be used to encrypt data files on Amazon S3.
                     If you specify MASTER_SYMMETRIC_KEY, you must specify the <a href="#unload-parameters-encrypted">ENCRYPTED</a> parameter also. You can't use
                     MASTER_SYMMETRIC_KEY with the CREDENTIALS parameter. For more information, see
                        <a href="./c_loading-encrypted-files.html">Loading encrypted data files from
                     Amazon S3</a>. </p>
               </dd>
             
               <dt><span class="term">BZIP2 </span></dt>
               <dd>
                  <p>Unloads data to one or more bzip2-compressed files per slice. Each resulting
                     file is appended with a <code class="code">.bz2</code> extension. </p>
               </dd>
             
               <dt><span class="term">GZIP </span></dt>
               <dd>
                  <p>Unloads data to one or more gzip-compressed files per slice. Each resulting
                     file is appended with a <code class="code">.gz</code> extension. </p>
               </dd>
             
               <dt><span class="term">ZSTD </span></dt>
               <dd>
                  <p>Unloads data to one or more Zstandard-compressed files per slice. Each
                     resulting file is appended with a <code class="code">.zst</code> extension. </p>
               </dd>
             
               <dt><span class="term">ADDQUOTES </span></dt>
               <dd>
                  <p>Places quotation marks around each unloaded data field, so that Amazon Redshift can
                     unload data values that contain the delimiter itself. For example, if the
                     delimiter is a comma, you could unload and reload the following data
                     successfully: </p>
                  <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""> "1","Hello, World" </code></pre>
                  <p>Without the added quotation marks, the string <code class="code">Hello, World</code>
                     would be parsed as two separate fields.</p>
                  <p>Some output formats do not support ADDQUOTES.</p>
                  <p>If you use ADDQUOTES, you must specify REMOVEQUOTES in the COPY if you
                     reload the data.</p>
               </dd>
             
               <dt><span class="term">NULL AS '<em>null-string</em>' </span></dt>
               <dd>
                  <p>Specifies a string that represents a null value in unload files. If this
                     option is used, all output files contain the specified string in place of any
                     null values found in the selected data. If this option isn't specified,
                     null values are unloaded as: </p>
                  <div class="itemizedlist">
                      
                      
                  <ul class="itemizedlist"><li class="listitem">
                        <p>Zero-length strings for delimited output </p>
                     </li><li class="listitem">
                        <p>Whitespace strings for fixed-width output</p>
                     </li></ul></div>
                  <p>If a null string is specified for a fixed-width unload and the width of an
                     output column is less than the width of the null string, the following behavior
                     occurs: </p>
                  <div class="itemizedlist">
                      
                      
                  <ul class="itemizedlist"><li class="listitem">
                        <p>An empty field is output for non-character columns </p>
                     </li><li class="listitem">
                        <p>An error is reported for character columns </p>
                     </li></ul></div>
                  <p>Unlike other data types where a user-defined string represents a null value, Amazon Redshift exports the SUPER data columns using the JSON format and represents it as null as determined by the JSON format. As a result, SUPER data columns ignore the NULL [AS] option used in UNLOAD commands.</p>
               </dd>
             
               <dt><span class="term">ESCAPE </span></dt>
               <dd>
                  <p>For CHAR and VARCHAR columns in delimited unload files, an escape character
                        (<code class="code">\</code>) is placed before every occurrence of the following
                     characters:</p>
                  <div class="itemizedlist">
                      
                      
                      
                      
                      
                  <ul class="itemizedlist"><li class="listitem">
                        <p>Linefeed: <code class="code">\n</code></p>
                     </li><li class="listitem">
                        <p>Carriage return: <code class="code">\r</code></p>
                     </li><li class="listitem">
                        <p>The delimiter character specified for the unloaded data. </p>
                     </li><li class="listitem">
                        <p>The escape character: <code class="code">\</code></p>
                     </li><li class="listitem">
                        <p>A quotation mark character: <code class="code">"</code> or <code class="code">'</code> (if both
                           ESCAPE and ADDQUOTES are specified in the UNLOAD command).</p>
                     </li></ul></div>
                  <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>If you loaded your data using a COPY with the ESCAPE option, you must
                        also specify the ESCAPE option with your UNLOAD command to generate the
                        reciprocal output file. Similarly, if you UNLOAD using the ESCAPE option,
                        you need to use ESCAPE when you COPY the same data.</p></div></div>
               </dd>
             
               <dt id="allowoverwrite"><span class="term">ALLOWOVERWRITE </span></dt>
               <dd>
                  <p>By default, UNLOAD fails if it finds files that it would possibly overwrite.
                     If ALLOWOVERWRITE is specified, UNLOAD overwrites existing files, including the
                     manifest file. </p>
               </dd>
             
               <dt id="cleanpath"><span class="term">CLEANPATH</span></dt>
               <dd>
                  <p>The CLEANPATH option removes existing files located in the Amazon S3 path specified in the TO clause before unloading files to the specified location.  </p>
                  <p>If you include the PARTITION BY clause, existing files are removed only from the partition folders to receive new files generated by the UNLOAD operation.</p>
                  <p>You must have the <code class="code">s3:DeleteObject</code> permission on the Amazon S3 bucket. For information, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-policy-language-overview.html">Policies and Permissions in Amazon S3</a> in the <em>Amazon Simple Storage Service User Guide</em>. Files that you remove by using the CLEANPATH option are permanently deleted and can't be recovered.</p>
                  <p>You can't specify the CLEANPATH option if you specify the ALLOWOVERWRITE option.</p>
               </dd>
             
               <dt id="unload-parallel"><span class="term">PARALLEL </span></dt>
               <dd>
                  <p>By default, UNLOAD writes data in parallel to multiple files, according to
                     the number of slices in the cluster. The default option is ON or TRUE. If
                     PARALLEL is OFF or FALSE, UNLOAD writes to one or more data files serially,
                     sorted absolutely according to the ORDER BY clause, if one is used. The maximum
                     size for a data file is 6.2 GB. So, for example, if you unload 13.4 GB of data,
                     UNLOAD creates the following three files.</p>
                  <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">s3://mybucket/key000    6.2 GB
s3://mybucket/key001    6.2 GB
s3://mybucket/key002    1.0 GB</code></pre>
                  <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The UNLOAD command is designed to use parallel processing. We recommend
                        leaving PARALLEL enabled for most cases, especially if the files are used to
                        load tables using a COPY command.</p></div></div>
               </dd>
             
               <dt id="unload-maxfilesize"><span class="term">MAXFILESIZE [AS] max-size [ MB | GB ] </span></dt>
               <dd>
                  <p>Specifies the maximum size of files that UNLOAD creates in Amazon S3.
                     Specify a decimal value between 5 MB and 6.2 GB. The AS keyword is optional.
                     The default unit is MB. If MAXFILESIZE isn't specified, the default
                     maximum file size is 6.2 GB. The size of the manifest file, if one is used,
                     isn't affected by MAXFILESIZE.</p>
               </dd>
             
               <dt id="unload-rowgroupsize"><span class="term">ROWGROUPSIZE [AS] size [ MB | GB ] </span></dt>
               <dd>
                  <p>Specifies the size of row groups. Choosing a larger size can reduce the number of row groups, reducing
                     the amount of network communication.
                     Specify an integer value between 32 MB and 128 MB. The AS keyword is optional.
                     The default unit is MB.</p>
                  <p>If ROWGROUPSIZE isn't specified, the default
                     size is 32 MB. To use this parameter, the storage format must be Parquet and the node type must be ra3.4xlarge, ra3.16xlarge, ds2.8xlarge, or dc2.8xlarge.</p>
               </dd>
             
               <dt id="unload-region"><span class="term">REGION [AS] '<em>aws-region</em>'</span></dt>
               <dd>
                  <p>Specifies the AWS Region where the target Amazon S3 bucket is located. REGION is
                     required for UNLOAD to an Amazon S3 bucket that isn't in the same AWS Region as
                     the Amazon Redshift database. </p>
                  <p>The value for <em>aws_region</em> must match an AWS Region
                     listed in the <a href="https://docs.aws.amazon.com/general/latest/gr/rande.html#redshift_region">Amazon Redshift
                        regions and endpoints</a> table in the <em>AWS General Reference</em>.</p>
                  <p>By default, UNLOAD assumes that the target Amazon S3 bucket is located in the
                     same AWS Region as the Amazon Redshift database.</p>
               </dd>
             
               <dt id="unload-extension"><span class="term">EXTENSION '<em>extension-name</em>'</span></dt>
               <dd>
                  <p>Specifies the file extension to append to the names of the unloaded files. Amazon Redshift doesn't run any validation, so you must
                     verify that the specified file extension is correct. If you're using a compression method such as GZIP, you still
                     have to specify <code class="code">.gz</code> in the extension parameter. If you don't provide any extension,
                  Amazon Redshift doesn't add anything to the filename. If you specify a compression method without providing
                  an extension, Amazon Redshift only adds the compression method's extension to the filename.</p>
               </dd>
            </dl></div>
       
         <h2 id="unload-usage-notes">Usage notes</h2>
          
            <h3 id="unload-usage-escape">Using ESCAPE for all delimited text UNLOAD
                  operations</h3>
            <p>When you UNLOAD using a delimiter, your data can include that delimiter or any of
               the characters listed in the ESCAPE option description. In this case, you must use
               the ESCAPE option with the UNLOAD statement. If you don't use the ESCAPE option
               with the UNLOAD, subsequent COPY operations using the unloaded data might
               fail.</p>
            <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>We strongly recommend that you always use ESCAPE with both UNLOAD and COPY
                  statements. The exception is if you are certain that your data doesn't
                  contain any delimiters or other characters that might need to be escaped. </p></div></div>
          
          
            <h3 id="unload-usage-floating-point-precision">Loss of floating-point
                  precision</h3>
            <p>You might encounter loss of precision for floating-point data that is successively
               unloaded and reloaded. </p>
          
          
            <h3 id="unload-usage-limit-clause">Limit clause</h3>
            <p>The SELECT query can't use a LIMIT clause in the outer SELECT. For example,
               the following UNLOAD statement fails.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">unload ('select * from venue limit 10')
to 's3://mybucket/venue_pipe_' iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'; </code></pre>
            <p>Instead, use a nested LIMIT clause, as in the following example.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">unload ('select * from venue where venueid in
(select venueid from venue order by venueid desc limit 10)')
to 's3://mybucket/venue_pipe_' iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole';</code></pre>
            <p>You can also populate a table using SELECT…INTO or CREATE TABLE AS using a LIMIT
               clause, then unload from that table.</p>
          
          
            <h3 id="unload-usage-geometry">Unloading a column of the GEOMETRY data
                  type</h3>
            <p>You can only unload GEOMETRY columns to text or CSV format. You can't unload
               GEOMETRY data with the <code class="code">FIXEDWIDTH</code> option. The data is unloaded in the
               hexadecimal form of the extended well-known binary (EWKB) format. If the size of the
               EWKB data is more than 4 MB, then a warning occurs because the data can't later
               be loaded into a table. </p>
          


          
            <h3 id="unload-usage-hll">Unloading the HLLSKETCH data type</h3>

            <p>You can only unload HLLSKETCH columns to text or CSV format. You can't unload
               HLLSKETCH data with the <code class="code">FIXEDWIDTH</code> option. The data is unloaded in the
               Base64 format for dense HyperLogLog sketches or in the JSON format for sparse
               HyperLogLog sketches. For more information, see <a href="./hyperloglog-functions.html">HyperLogLog functions</a>.</p>
            <p>The following example exports a table containing HLLSKETCH columns into a
               file.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE TABLE a_table(an_int INT, b_int INT);
INSERT INTO a_table VALUES (1,1), (2,1), (3,1), (4,1), (1,2), (2,2), (3,2), (4,2), (5,2), (6,2);

CREATE TABLE hll_table (sketch HLLSKETCH);
INSERT INTO hll_table select hll_create_sketch(an_int) from a_table group by b_int;

UNLOAD ('select * from hll_table') TO 's3://mybucket/unload/'
IAM_ROLE 'arn:aws:iam::0123456789012:role/MyRedshiftRole' NULL AS 'null' ALLOWOVERWRITE CSV;</code></pre>
          

          
            
            <h3 id="unload-usage-varbyte">Unloading a column of the VARBYTE data
                  type</h3>
            <p>You can only unload VARBYTE columns to text or CSV format.
               The data is unloaded in the hexadecimal form.
               You can't unload VARBYTE data with the <code class="code">FIXEDWIDTH</code> option.
               The <code class="code">ADDQUOTES</code> option of UNLOAD to a CSV is not supported.
               A VARBYTE column can't be a PARTITIONED BY column.
                </p>
          


          
            <h3 id="unload-parquet-usage">FORMAT AS PARQUET clause</h3>
            <p>Be aware of these considerations when using FORMAT AS PARQUET:</p>
            <div class="itemizedlist">
                
                
                
                
            <ul class="itemizedlist"><li class="listitem">
                  <p>Unload to Parquet doesn't use file level compression. Each row group is
                     compressed with SNAPPY.</p>
               </li><li class="listitem">
                  <p>If MAXFILESIZE isn't specified, the default maximum file size is 6.2
                     GB. You can use MAXFILESIZE to specify a file size of 5 MB–6.2 GB. The
                     actual file size is approximated when the file is being written, so it might
                     not be exactly equal to the number you specify.</p>
                  <p>To maximize scan performance, Amazon Redshift tries to create Parquet files that
                     contain equally sized 32-MB row groups. The MAXFILESIZE value that you specify
                     is automatically rounded down to the nearest multiple of 32 MB. For example, if
                     you specify MAXFILESIZE 200 MB, then each Parquet file unloaded is
                     approximately 192 MB (32 MB row group x 6 = 192 MB).</p>
               </li><li class="listitem">
                  <p>If a column uses TIMESTAMPTZ data format, only the timestamp values are
                     unloaded. The time zone information isn't unloaded.</p>
               </li><li class="listitem">
                  <p>Don't specify file name prefixes that begin with underscore (_) or
                     period (.) characters. Redshift Spectrum treats files that begin with these characters as
                     hidden files and ignores them.</p>
               </li></ul></div>
          
          
            <h3 id="unload-partitionby-usage">PARTITION BY clause</h3>
            <p>Be aware of these considerations when using PARTITION BY:</p>
            <div class="itemizedlist">

                
                
                
                
                
                

            <ul class="itemizedlist"><li class="listitem">
                  <p>Partition columns aren't included in the output file.</p>
               </li><li class="listitem">
                  <p>Make sure to include partition columns in the SELECT query used in the
                     UNLOAD statement. You can specify any number of partition columns in the UNLOAD
                     command. However, there is a limitation that there should be at least one
                     nonpartition column to be part of the file.</p>
               </li><li class="listitem">
                  <p>If the partition key value is null, Amazon Redshift automatically unloads that data
                     into a default partition called
                        <code class="code">partition_column=__HIVE_DEFAULT_PARTITION__</code>. </p>
               </li><li class="listitem">
                  <p>The UNLOAD command doesn't make any calls to an external catalog. To
                     register your new partitions to be part of your existing external table, use a
                     separate ALTER TABLE ... ADD PARTITION ... command. Or you can run a CREATE
                     EXTERNAL TABLE command to register the unloaded data as a new external table.
                     You can also use an AWS Glue crawler to populate your Data Catalog. For more
                     information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html">Defining Crawlers</a> in the
                        <em>AWS Glue Developer Guide</em>. </p>
               </li><li class="listitem">
                  <p>If you use the MANIFEST option, Amazon Redshift generates only one manifest file in the
                     root Amazon S3 folder.</p>
               </li><li class="listitem">
                  <p>The column data types that you can use as the partition key are SMALLINT,
                     INTEGER, BIGINT, DECIMAL, REAL, BOOLEAN, CHAR, VARCHAR, DATE, and TIMESTAMP.
                  </p>
               </li></ul></div>
          
         

         


         

          
            <h3 id="unload-assumerole-privilege-usage">Using the ASSUMEROLE privilege to
                  grant access to an IAM role for UNLOAD operations</h3>

            <p>To provide access for specific users and groups to an IAM role for UNLOAD operations, a superuser can grant the
               ASSUMEROLE privilege on an IAM role to users and groups. For information, see <a href="./r_GRANT.html">GRANT</a>. </p>

          

          
            <h3 id="unload-usage-s3-access-point-alias">UNLOAD doesn't support Amazon S3 access point aliases</h3>

            <p>You can't use Amazon S3 access point aliases with the UNLOAD command. </p>
          
         
       
            <h2 id="r_UNLOAD-examples">Examples</h2>
            <p>For examples that show how to use the UNLOAD command, see <a href="./r_UNLOAD_command_examples.html">UNLOAD examples</a>.</p>
         <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./r_TRUNCATE.html">TRUNCATE</div><div id="next" class="next-link" accesskey="n" href="./r_UNLOAD_command_examples.html">UNLOAD examples</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_UNLOAD.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_UNLOAD.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>