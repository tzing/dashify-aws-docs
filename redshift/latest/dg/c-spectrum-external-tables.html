<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Creating external tables for Redshift Spectrum - Amazon Redshift</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="c-spectrum-external-tables" /><meta name="default_state" content="c-spectrum-external-tables" /><link rel="icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="canonical" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="description" content="You create an external table in an external schema. To create external tables, you must be the owner of the external schema or a superuser. To transfer ownership of an external schema, use to change the owner. The following example changes the owner of the" /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon Redshift" /><meta name="guide" content="Database Developer Guide" /><meta name="abstract" content="Create and manage a data warehouse with Amazon Redshift, an enterprise-level, petabyte scale, fully managed data warehousing service." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="de" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="en-us" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="zh-tw" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html" hreflang="x-default" /><meta name="feedback-item" content="Redshift" /><meta name="this_doc_product" content="Amazon Redshift" /><meta name="this_doc_guide" content="Database Developer Guide" /><script defer="" src="/assets/r/vendor4.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor3.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor1.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-common.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-doc-page.js?version=2021.12.02"></script><link href="/assets/r/vendor4.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-common.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-doc-page.css?version=2021.12.02" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'redshift'}"></script><meta id="panorama-serviceSubSection" value="Database Developer Guide" /><meta id="panorama-serviceConsolePage" value="Creating external tables for Redshift Spectrum" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Creating external tables for Redshift Spectrum - Amazon Redshift</title><meta name="pdf" content="/pdfs/redshift/latest/dg/redshift-dg.pdf#c-spectrum-external-tables" /><meta name="rss" content="Dochistory.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=155" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/c-spectrum-external-tables.html" /><meta name="keywords" content="Amazon Redshift,AWS Redshift,Redshift,Redshift Spectrum,cluster,data warehouse,developer,sample data,database,database developer,HLL" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon Redshift",
        "item" : "https://docs.aws.amazon.com/redshift/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Database Developer Guide",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Querying external data using Amazon Redshift Spectrum",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Creating external tables for Redshift Spectrum",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="/pdfs/redshift/latest/dg/redshift-dg.pdf#c-spectrum-external-tables" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="/index.html">Documentation</a><a href="/redshift/index.html">Amazon Redshift</a><a href="welcome.html">Database Developer Guide</a></div><div id="page-toc-src"><a href="#c-spectrum-external-tables-pseudocolumns">Pseudocolumns</a><a href="#c-spectrum-external-tables-partitioning">Partitioning Redshift Spectrum external
               tables</a><a href="#c-spectrum-column-mapping-orc">Mapping to ORC
               columns</a><a href="#c-spectrum-column-mapping-hudi">Creating external tables for
               Hudi-managed data</a><a href="#c-spectrum-column-mapping-delta">Creating external tables for
               Delta Lake data</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="c-spectrum-external-tables">Creating external tables for Redshift Spectrum</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p></p><p>You create an external table in an external schema. To create external tables, you must
         be the owner of the external schema or a superuser. To transfer ownership of an external
         schema, use <a href="./r_ALTER_SCHEMA.html">ALTER SCHEMA</a> to change the
         owner. The following example changes the owner of the <code class="code">spectrum_schema</code> schema
         to <code class="code">newowner</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter schema spectrum_schema owner to newowner;</code></pre><p>To run a Redshift Spectrum query, you need the following permissions:</p><div class="itemizedlist">
          
          
      <ul class="itemizedlist"><li class="listitem">
            <p>Usage permission on the schema </p>
         </li><li class="listitem">
            <p>Permission to create temporary tables in the current database </p>
         </li></ul></div><p>The following example grants usage permission on the schema <code class="code">spectrum_schema</code>
         to the <code class="code">spectrumusers</code> user group.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">grant usage on schema spectrum_schema to group spectrumusers;</code></pre><p>The following example grants temporary permission on the database
            <code class="code">spectrumdb</code> to the <code class="code">spectrumusers</code> user group. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">grant temp on database spectrumdb to group spectrumusers;</code></pre><p>You can create an external table in Amazon Redshift, AWS Glue, Amazon Athena, or an Apache Hive metastore.
         For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/getting-started.html">Getting Started
            Using AWS Glue</a> in the <em>AWS Glue Developer Guide</em>, <a href="https://docs.aws.amazon.com/athena/latest/ug/getting-started.html">Getting Started</a> in the <em>Amazon Athena User Guide</em>, or <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html">Apache Hive</a> in the
            <em>Amazon EMR Developer Guide</em>. </p><p>If your external table is defined in AWS Glue, Athena, or a Hive metastore, you first create
         an external schema that references the external database. Then you can reference the
         external table in your SELECT statement by prefixing the table name with the schema name,
         without needing to create the table in Amazon Redshift. For more information, see <a href="./c-spectrum-external-schemas.html">Creating external schemas for Amazon Redshift
            Spectrum</a>. </p><p>To allow Amazon Redshift to view tables in the AWS Glue Data Catalog, add <code class="code">glue:GetTable</code> to the
         Amazon Redshift IAM role. Otherwise you might get an error similar to the following.</p><pre class="programlisting"><div class="code-btn-container"></div><code class="nohighlight">RedshiftIamRoleSession is not authorized to perform: glue:GetTable on resource: *;</code></pre><p>For example, suppose that you have an external table named <code class="code">lineitem_athena</code>
         defined in an Athena external catalog. In this case, you can define an external schema named
            <code class="code">athena_schema</code>, then query the table using the following SELECT
         statement.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select count(*) from athena_schema.lineitem_athena;</code></pre><p>To define an external table in Amazon Redshift, use the <a href="./r_CREATE_EXTERNAL_TABLE.html">CREATE EXTERNAL TABLE</a> command. The external table statement defines
         the table columns, the format of your data files, and the location of your data in Amazon S3.
         Redshift Spectrum scans the files in the specified folder and any subfolders. Redshift
         Spectrum ignores hidden files and files that begin with a period, underscore, or hash mark
         ( . , _, or #) or end with a tilde (~). </p><p>The following example creates a table named SALES in the Amazon Redshift external schema named
            <code class="code">spectrum</code>. The data is in tab-delimited text files.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
row format delimited
fields terminated by '\t'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/sales/'
table properties ('numRows'='172000');</code></pre><p>To view external tables, query the <a href="./r_SVV_EXTERNAL_TABLES.html">SVV_EXTERNAL_TABLES</a> system view. </p>
         <h2 id="c-spectrum-external-tables-pseudocolumns">Pseudocolumns</h2>

         
         <p>By default, Amazon Redshift creates external tables with the pseudocolumns <code class="code">$path</code>,
               <code class="code">$size</code>, and <code class="code">$spectrum_oid</code>. Select the <code class="code">$path</code>
            column to view the path to the data files on
            Amazon S3,
            and select the <code class="code">$size</code> column to view the size of the data files for each row
            returned by a query. The <code class="code">$spectrum_oid</code> column provides the ability to
            perform correlated queries with Redshift Spectrum. For an example, see <a href="./c_performing-correlated-subqueries-spectrum.html">Example: Performing correlated subqueries in Redshift Spectrum</a>. You must delimit the <code class="code">$path</code>,
               <code class="code">$size</code>, and <code class="code">$spectrum_oid</code> column names with double quotation
            marks. A SELECT * clause doesn't return the pseudocolumns. You must explicitly
            include the <code class="code">$path</code>, <code class="code">$size</code>, and <code class="code">$spectrum_oid</code>
            column names in your query, as the following example shows.</p>
         
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="SQL ">select "$path", "$size", "$spectrum_oid"
from spectrum.sales_part where saledate = '2008-12-01';</code></pre>
         
         <p>You can disable
            the
            creation of pseudocolumns for a session by setting the
            <code class="code">spectrum_enable_pseudo_columns</code> configuration parameter to <code class="code">false</code>. For
            more information, see <a href="./r_spectrum_enable_pseudo_columns.html">spectrum_enable_pseudo_columns</a>. You can also disable only the
               <code class="code">$spectrum_oid</code> pseudocolumn by setting the
               <code class="code">enable_spectrum_oid</code> to <code class="code">false</code>.
            For more information, see <a href="./r_spectrum_enable_spectrum_oid.html">enable_spectrum_oid</a>. However, disabling the
               <code class="code">$spectrum_oid</code> pseudocolumn also disables support for correlated queries with Redshift Spectrum.</p>
         <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>Selecting <code class="code">$size</code>, <code class="code">$path</code>, or <code class="code">$spectrum_oid</code> incurs charges because Redshift Spectrum scans the
               data files on Amazon S3 to determine the size of the result set. For
               more information, see <a href="https://aws.amazon.com/redshift/pricing/" rel="noopener noreferrer" target="_blank"><span>Amazon Redshift
                  Pricing</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p></div></div>
          
            <h3 id="c-spectrum-external-tables-pseudocolumns-example">Pseudocolumns
                  example</h3>

            <p>The following example returns the total size of related data files for an external
               table.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select distinct "$path", "$size"
from spectrum.sales_part;

 $path                                                                    | $size
--------------------------------------------------------------------------+-------
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/ |  1616
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-02/ |  1444
s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/ |  1644</code></pre>
          
       
         <h2 id="c-spectrum-external-tables-partitioning">Partitioning Redshift Spectrum external
               tables</h2>

         <p>When you partition your data, you can restrict the amount of data that Redshift
            Spectrum scans by filtering on the partition key. You can partition your data by any
            key. </p>
         <p>A common practice is to partition the data based on time. For example, you might
            choose to partition by year, month, date, and hour. If you have data coming from
            multiple sources, you might partition by a data source identifier and date. </p>
         <p>The following procedure describes how to partition your data.</p>
         <div class="procedure"><h6>To partition your data</h6><ol><li>
               <p>Store your data in folders in Amazon S3 according to your partition key. </p>
               <p>Create one folder for each partition value and name the folder with the
                  partition key and value. For example, if you partition by date, you might have
                  folders named <code class="code">saledate=2017-04-01</code>, <code class="code">saledate=2017-04-02</code>,
                  and so on. Redshift Spectrum scans the files in the partition folder and any
                  subfolders. Redshift Spectrum ignores hidden files and files that begin with a
                  period, underscore, or hash mark ( . , _, or #) or end with a tilde (~). </p>

            </li><li>
               <p>Create an external table and specify the partition key in the PARTITIONED BY
                  clause. </p>
               <p>The partition key can't be the name of a table column. The data type can
                  be SMALLINT, INTEGER, BIGINT, DECIMAL, REAL, DOUBLE PRECISION, BOOLEAN, CHAR, VARCHAR, DATE, or TIMESTAMP data type. </p>
            </li><li>
               <p>Add the partitions. </p>
               <p>Using <a href="./r_ALTER_TABLE.html">ALTER TABLE</a> … ADD
                  PARTITION, add each partition, specifying the partition column and key value, and
                  the location of the partition folder in Amazon S3. You can add multiple partitions in a
                  single ALTER TABLE … ADD statement. The following example adds partitions for
                     <code class="code">'2008-01'</code> and <code class="code">'2008-03'</code>.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_part add
partition(saledate='2008-01-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/'
partition(saledate='2008-03-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/';</code></pre>
               <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>If you use the AWS Glue catalog, you can add up to 100 partitions using a
                     single ALTER TABLE statement.</p></div></div>
            </li></ol></div>

          
            <h3 id="c-spectrum-external-tables-partitioning-example">Partitioning data
                  examples</h3>


            <p>In this example, you create an external table that is partitioned by a single
               partition key and an external table that is partitioned by two partition keys.</p>

            <p>The sample data for this example is located in an Amazon S3 bucket that gives read
               access to all authenticated AWS users. Your cluster and your external data files must
               be in the same AWS Region. The sample data bucket is in the US East (N. Virginia) Region
               (us-east-1). To access the data using Redshift Spectrum, your cluster must also be in
               us-east-1. To list the folders in Amazon S3, run the following command.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">aws s3 ls s3://redshift-downloads/tickit/spectrum/sales_partition/</code></pre>
            <pre class="screen">PRE saledate=2008-01/
PRE saledate=2008-03/
PRE saledate=2008-04/
PRE saledate=2008-05/
PRE saledate=2008-06/
PRE saledate=2008-12/</pre>
            <p>If you don't already have an external schema, run the following command.
               Substitute the Amazon Resource Name (ARN) for your AWS Identity and Access Management (IAM) role.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external schema spectrum
from data catalog
database 'spectrumdb'
iam_role 'arn:aws:iam::123456789012:role/myspectrumrole'
create external database if not exists;</code></pre>
             
               <h4 id="c-spectrum-external-tables-single-partition-example">Example 1:
                     Partitioning with a single partition key</h4>
               <p>In the following example, you create an external table that is partitioned by
                  month.</p>
               <p>To create an external table partitioned by month, run the following
                  command.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales_part(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
partitioned by (saledate char(10))
row format delimited
fields terminated by '|'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/sales_partition/'
table properties ('numRows'='172000');</code></pre>
               <p>To add the partitions, run the following ALTER TABLE command.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_part add
partition(saledate='2008-01') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01/'

partition(saledate='2008-03') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03/'

partition(saledate='2008-04') 
location 's3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-04/';</code></pre>
               <p>To select data from the partitioned table, run the following query.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select top 5 spectrum.sales_part.eventid, sum(spectrum.sales_part.pricepaid) 
from spectrum.sales_part, event
where spectrum.sales_part.eventid = event.eventid
  and spectrum.sales_part.pricepaid &gt; 30
  and saledate = '2008-01'
group by spectrum.sales_part.eventid
order by 2 desc;</code></pre>

               <pre class="screen">eventid | sum     
--------+---------
   4124 | 21179.00
   1924 | 20569.00
   2294 | 18830.00
   2260 | 17669.00
   6032 | 17265.00</pre>
               <p>To view external table partitions, query the <a href="./r_SVV_EXTERNAL_PARTITIONS.html">SVV_EXTERNAL_PARTITIONS</a>
                  system view.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select schemaname, tablename, values, location from svv_external_partitions
where tablename = 'sales_part';</code></pre>

               <pre class="screen">schemaname | tablename  | values      | location                                                                
-----------+------------+-------------+-------------------------------------------------------------------------
spectrum   | sales_part | ["2008-01"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-01
spectrum   | sales_part | ["2008-03"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-03
spectrum   | sales_part | ["2008-04"] | s3://redshift-downloads/tickit/spectrum/sales_partition/saledate=2008-04</pre>
             
             
               <h4 id="c-spectrum-external-tables-multi-partition-example">Example 2:
                     Partitioning with a multiple partition key</h4>

               <p>To create an external table partitioned by <code class="code">date</code> and
                     <code class="code">eventid</code>, run the following command.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.sales_event(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
partitioned by (salesmonth char(10), event integer)
row format delimited
fields terminated by '|'
stored as textfile
location 's3://redshift-downloads/tickit/spectrum/salesevent/'
table properties ('numRows'='172000');</code></pre>
               <p>To add the partitions, run the following ALTER TABLE command.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.sales_event add
partition(salesmonth='2008-01', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=101/'

partition(salesmonth='2008-01', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=102/'

partition(salesmonth='2008-01', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-01/event=103/'

partition(salesmonth='2008-02', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=101/'

partition(salesmonth='2008-02', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=102/'

partition(salesmonth='2008-02', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-02/event=103/'

partition(salesmonth='2008-03', event='101') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=101/'

partition(salesmonth='2008-03', event='102') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=102/'

partition(salesmonth='2008-03', event='103') 
location 's3://redshift-downloads/tickit/spectrum/salesevent/salesmonth=2008-03/event=103/';</code></pre>
               <p>Run the following query to select data from the partitioned table.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select spectrum.sales_event.salesmonth, event.eventname, sum(spectrum.sales_event.pricepaid) 
from spectrum.sales_event, event
where spectrum.sales_event.eventid = event.eventid
  and salesmonth = '2008-02'
	and (event = '101'
	or event = '102'
	or event = '103')
group by event.eventname, spectrum.sales_event.salesmonth
order by 3 desc;</code></pre>
               <pre class="screen">salesmonth | eventname       | sum    
-----------+-----------------+--------
2008-02    | The Magic Flute | 5062.00
2008-02    | La Sonnambula   | 3498.00
2008-02    | Die Walkure     |  534.00</pre>
             
          
       
         <h2 id="c-spectrum-column-mapping-orc">Mapping external table columns to ORC
               columns</h2>
         <p>You use Amazon Redshift Spectrum external tables to query data from files in ORC format.
            Optimized row columnar (ORC) format is a columnar storage file format that supports
            nested data structures. For more information about querying nested data, see <a href="./tutorial-query-nested-data.html#tutorial-nested-data-overview">Querying Nested Data with Amazon Redshift
               Spectrum</a>. </p>
         <p>When you create an external table that references data in an ORC file, you map each
            column in the external table to a column in the ORC data. To do so, you use one of the
            following methods:</p>
         <div class="itemizedlist">
             
             
         <ul class="itemizedlist"><li class="listitem">
               <p><a href="#orc-mapping-by-position">Mapping by position</a></p>
            </li><li class="listitem">
               <p><a href="#orc-mapping-by-name">Mapping by column name</a>
               </p>
            </li></ul></div>
         <p>Mapping by column name is the default. </p>
          
            <h3 id="orc-mapping-by-position">Mapping by position</h3>
            <p>With position mapping, the first column defined in the external table maps to the
               first column in the ORC data file, the second to the second, and so on. Mapping by
               position requires that the order of columns in the external table and in the ORC file
               match. If the order of the columns doesn't match, then you can map the columns by
               name. </p>
            <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>In earlier releases, Redshift Spectrum used position mapping by default. If you
                  need to continue using position mapping for existing tables, set the table
                  property <code class="code">orc.schema.resolution</code> to <code class="code">position</code>, as the
                  following example shows. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">alter table spectrum.orc_example 
set table properties('orc.schema.resolution'='position'); </code></pre></div></div>
            <p>For example, the table <code class="code">SPECTRUM.ORC_EXAMPLE</code> is defined as follows. </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create external table spectrum.orc_example(
int_col int,
float_col float,
nested_col struct&lt;
  "int_col" : int,
  "map_col" : map&lt;int, array&lt;float &gt;&gt;
   &gt;
) stored as orc
location 's3://example/orc/files/';</code></pre>
            <p>The table structure can be abstracted as follows. </p>
            <pre class="screen">• 'int_col' : int
• 'float_col' : float
• 'nested_col' : struct
   o 'int_col' : int
   o 'map_col' : map
      - key : int
      - value : array
         - value : float</pre>
            <p>The underlying ORC file has the following file structure.</p>
            <pre class="screen">• ORC file root(id = 0)
   o 'int_col' : int (id = 1)
   o 'float_col' : float (id = 2)
   o 'nested_col' : struct (id = 3)
      - 'int_col' : int (id = 4)
      - 'map_col' : map (id = 5)
         - key : int (id = 6)
         - value : array (id = 7)
            - value : float (id = 8)</pre>
            <p>In this example, you can map each column in the external table to a column in ORC
               file strictly by position. The following shows the mapping.</p>

            <div class="table-container"><div class="table-contents"><table id="w323aac48c21c49c11c21"><thead>
                     <tr>
                        <th>External table column name</th>
                        <th>ORC column ID</th>
                        <th>ORC column name</th>
                     </tr>
                  </thead>
                     <tr>
                        <td tabindex="-1">int_col</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">float_col</td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">float_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col</td>
                        <td tabindex="-1">3</td>
                        <td tabindex="-1">nested_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.int_col</td>
                        <td tabindex="-1">4</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col</td>
                        <td tabindex="-1">5</td>
                        <td tabindex="-1">map_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.key</td>
                        <td tabindex="-1">6</td>
                        <td tabindex="-1">NA</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.value</td>
                        <td tabindex="-1">7</td>
                        <td tabindex="-1">NA</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col.map_col.value.item</td>
                        <td tabindex="-1">8</td>
                        <td tabindex="-1">NA</td>
                     </tr>
                  </table></div></div>
          
          
            <h3 id="orc-mapping-by-name">Mapping by column name</h3>
            <p>Using name mapping, you map columns in an external table to named columns in ORC
               files on the same level, with the same name. </p>
            <p>For example, suppose that you want to map the table from the previous example,
                  <code class="code">SPECTRUM.ORC_EXAMPLE</code>, with an ORC file that uses the following file
               structure.</p>
            <pre class="screen">• ORC file root(id = 0)
   o 'nested_col' : struct (id = 1)
      - 'map_col' : map (id = 2)
         - key : int (id = 3)
         - value : array (id = 4)
            - value : float (id = 5)
      - 'int_col' : int (id = 6)
   o 'int_col' : int (id = 7)
   o 'float_col' : float (id = 8)</pre>

            <p>Using position mapping, Redshift Spectrum attempts the following mapping. </p>
            <div class="table-container"><div class="table-contents"><table id="w323aac48c21c49c13c11"><thead>
                     <tr>
                        <th>External table column name</th>
                        <th>ORC column ID</th>
                        <th>ORC column name</th>
                     </tr>
                  </thead>
                     <tr>
                        <td tabindex="-1">int_col</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">struct</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">float_col</td>
                        <td tabindex="-1">7</td>
                        <td tabindex="-1">int_col</td>
                     </tr>
                     <tr>
                        <td tabindex="-1">nested_col</td>
                        <td tabindex="-1">8</td>
                        <td tabindex="-1">float_col</td>
                     </tr>
                  </table></div></div>
            <p>When you query a table with the preceding position mapping, the SELECT command
               fails on type validation because the structures are different. </p>
            <p>You can map the same external table to both file structures shown in the previous
               examples by using column name mapping. The table columns <code class="code">int_col</code>,
                  <code class="code">float_col</code>, and <code class="code">nested_col</code> map by column name to columns
               with the same names in the ORC file. The column named <code class="code">nested_col</code> in the
               external table is a <code class="code">struct</code> column with subcolumns named
                  <code class="code">map_col</code> and <code class="code">int_col</code>. The subcolumns also map correctly
               to the corresponding columns in the ORC file by column name. </p>

          
       
      <h2 id="c-spectrum-column-mapping-hudi">Creating external tables for data managed in
               Apache Hudi</h2>
      <p>To query data in Apache Hudi Copy On Write (CoW) format, you can use Amazon Redshift Spectrum external
            tables. A Hudi Copy On Write table is a collection of Apache Parquet files stored in
            Amazon S3. 
            
         You can read Copy On Write (CoW) tables in Apache Hudi versions 0.5.2, 0.6.0, 0.7.0, 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, and 0.11.1
            that are created and modified with insert, delete, and upsert write operations.
            For example, bootstrap tables are not supported.     
            For more information, see 
         <a href="https://hudi.apache.org/docs/next/table_types#copy-on-write-table" rel="noopener noreferrer" target="_blank"><span>Copy On Write
            Table</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> 
            
         in the open source Apache Hudi documentation. </p>
      <p>When you create an external table that references data in Hudi CoW format, you map each
         column in the external table to a column in the Hudi data. Mapping is done by column. </p>

      <p>The data definition language (DDL) statements for partitioned and unpartitioned Hudi
            tables are similar to those for other Apache Parquet file formats. For Hudi tables, you
            define <code class="code">INPUTFORMAT</code> as
               <code class="code">org.apache.hudi.hadoop.HoodieParquetInputFormat</code>. The
               <code class="code">LOCATION</code> parameter must point to the Hudi table base folder that
            contains the <code class="code">.hoodie</code> folder, which is required to establish the Hudi commit
            timeline. In some cases, a SELECT operation on a Hudi table might fail with the message
               <strong class="errortext"><code>No valid Hudi commit timeline found</code></strong>. If so, check if the
               <code class="code">.hoodie</code> folder is in the correct location and contains a valid Hudi
            commit timeline. </p>
      <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Apache Hudi format is only supported when you use an AWS Glue Data Catalog. It's not supported when you
               use an Apache Hive metastore as the external catalog. </p></div></div>
      <p>The DDL to define an unpartitioned table has the following format. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>'</code></pre>
      <p>The DDL to define a partitioned table has the following format. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
PARTITIONED BY(<em>pcolumn1</em> <em>pcolumn1-type</em>[,...])
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>'</code></pre>
      <p>To add partitions to a partitioned Hudi table, run an ALTER TABLE ADD PARTITION command
            where the <code class="code">LOCATION</code> parameter points to the Amazon S3 subfolder with the files
            that belong to the partition.</p>
      <p>The DDL to add partitions has the following format.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>/<em>partition-path</em>'</code></pre>
    
      <h2 id="c-spectrum-column-mapping-delta">Creating external tables for data managed in
               Delta Lake</h2>
      <p>To query data in Delta Lake tables, you can use Amazon Redshift Spectrum external tables. </p>
         <p>To access a Delta Lake table from Redshift Spectrum, generate a manifest before the query. A
            Delta Lake <em>manifest</em> contains a listing of files that
            make up a consistent snapshot of the Delta Lake table. In a partitioned table, there is
            one manifest per partition. A Delta Lake table is a collection of Apache
            Parquet files stored in Amazon S3. 
            
            For more information, see <a href="https://delta.io" rel="noopener noreferrer" target="_blank"><span>Delta Lake</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> in the
            open source Delta Lake documentation. </p>
      <p>When you create an external table that references data in Delta Lake tables, you map
            each column in the external table to a column in the Delta Lake table. Mapping is done
            by column name. </p>
      
      <p>The DDL for partitioned and unpartitioned Delta Lake tables is similar to that for other
            Apache Parquet file formats. For Delta Lake tables, you define <code class="code">INPUTFORMAT</code>
            as <code class="code">org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat</code> and
               <code class="code">OUTPUTFORMAT</code> as
               <code class="code">org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</code>. The
               <code class="code">LOCATION</code> parameter must point to the manifest folder in the table base
            folder. If a SELECT operation on a Delta Lake table fails, for possible reasons see
               <a href="#c-spectrum-column-mapping-delta-limitations">Limitations and
                  troubleshooting for Delta Lake tables</a>. </p>
      <p>The DDL to define an unpartitioned table has the following format. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION 's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest'</code></pre>
      <p>The DDL to define a partitioned table has the following format. </p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE EXTERNAL TABLE <em>tbl_name</em> (<em>columns</em>)
PARTITIONED BY(<em>pcolumn1</em> <em>pcolumn1-type</em>[,...])
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION 's3://<em>s3-bucket</em>&gt;/<em>prefix</em>/_symlink_format_manifest'</code></pre>
      <p>To add partitions to a partitioned Delta Lake table, run an ALTER TABLE ADD PARTITION
            command where the <code class="code">LOCATION</code> parameter points to the Amazon S3 subfolder that
            contains the manifest for the partition.</p>
      <p>The DDL to add partitions has the following format.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION
's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest/<em>partition-path</em>'</code></pre>
      <p>Or run DDL that points directly to the Delta Lake manifest file.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE <em>tbl_name</em>
ADD IF NOT EXISTS PARTITION(<em>pcolumn1</em>=<em>pvalue1</em>[,...])
LOCATION
's3://<em>s3-bucket</em>/<em>prefix</em>/_symlink_format_manifest/<em>partition-path</em>/manifest'</code></pre>
      
       
         <h3 id="c-spectrum-column-mapping-delta-limitations">Limitations and
                  troubleshooting for Delta Lake tables</h3>
       
      <p>Consider the following when querying Delta Lake tables from Redshift Spectrum:</p>
      <div class="itemizedlist">
          
          
      <ul class="itemizedlist"><li class="listitem"><p>If a manifest points to a snapshot or partition that no longer exists, queries fail until a
                  new valid manifest has been generated. For example, this might result from a
                  VACUUM operation on the underlying table,</p></li><li class="listitem"><p>Delta Lake manifests only provide partition-level consistency. </p></li></ul></div>
      <p>The following table explains some potential reasons for certain errors when you query a
            Delta Lake table. </p>
      <div class="table-container"><div class="table-contents"><table id="w323aac48c21c59c37"><thead>
               <tr>
                  <th>Error message</th>
                  <th>Possible reason</th>
               </tr>
            </thead>
               
               
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Delta Lake manifest in bucket <em>s3-bucket-1</em> 
                     cannot contain entries in bucket <em>s3-bucket-2</em>.</code></strong></p></td>
                  <td tabindex="-1"><p>The manifest entries point to files in a different Amazon S3 bucket than the specified one. 
                  </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Delta Lake files are expected to be in the same folder.</code></strong></p></td>
                  <td tabindex="-1"><p>The manifest entries point to files that have a different Amazon S3 prefix than the specified
                           one.</p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>File <em>filename</em> listed in Delta Lake manifest <em>manifest-path</em> was not found.</code></strong></p></td>
                  <td tabindex="-1"><p>A file listed in the manifest wasn't found in Amazon S3. </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Error fetching Delta Lake manifest.</code></strong></p></td>
                  <td tabindex="-1"><p>The manifest wasn't found in Amazon S3. </p></td>
               </tr>
               <tr>
                  <td tabindex="-1"><p><strong class="errortext"><code>Invalid S3 Path.</code></strong></p></td>
                  <td tabindex="-1"><p>An entry in the manifest file isn't a valid Amazon S3 path, or the manifest file has been
                           corrupted. </p></td>
               </tr>

            </table></div></div>
      
   <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./c-spectrum-external-schemas.html">Creating external
            schemas</div><div id="next" class="next-link" accesskey="n" href="./querying-iceberg.html">Using Apache Iceberg tables</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/c-spectrum-external-tables.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/c-spectrum-external-tables.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>