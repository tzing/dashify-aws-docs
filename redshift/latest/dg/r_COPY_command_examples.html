<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>COPY examples - Amazon Redshift</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="r_COPY_command_examples" /><meta name="default_state" content="r_COPY_command_examples" /><link rel="icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="canonical" href="https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html" /><meta name="description" content="Provides examples of how to use the COPY to load data from a variety of sources." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon Redshift" /><meta name="guide" content="Database Developer Guide" /><meta name="abstract" content="Create and manage a data warehouse with Amazon Redshift, an enterprise-level, petabyte scale, fully managed data warehousing service." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/r_COPY_command_examples.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/redshift/latest/dg/r_COPY_command_examples.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/r_COPY_command_examples.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/redshift/latest/dg/r_COPY_command_examples.html" hreflang="de" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html" hreflang="en-us" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/r_COPY_command_examples.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/redshift/latest/dg/r_COPY_command_examples.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/r_COPY_command_examples.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/redshift/latest/dg/r_COPY_command_examples.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/r_COPY_command_examples.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/redshift/latest/dg/r_COPY_command_examples.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/r_COPY_command_examples.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/r_COPY_command_examples.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/r_COPY_command_examples.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/r_COPY_command_examples.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/r_COPY_command_examples.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/redshift/latest/dg/r_COPY_command_examples.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_COPY_command_examples.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/redshift/latest/dg/r_COPY_command_examples.html" hreflang="zh-tw" /><link rel="alternative" href="https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html" hreflang="x-default" /><meta name="feedback-item" content="Redshift" /><meta name="this_doc_product" content="Amazon Redshift" /><meta name="this_doc_guide" content="Database Developer Guide" /><script defer="" src="/assets/r/vendor4.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor3.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor1.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-common.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-doc-page.js?version=2021.12.02"></script><link href="/assets/r/vendor4.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-common.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-doc-page.css?version=2021.12.02" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'redshift'}"></script><meta id="panorama-serviceSubSection" value="Database Developer Guide" /><meta id="panorama-serviceConsolePage" value="COPY examples" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>COPY examples - Amazon Redshift</title><meta name="pdf" content="/pdfs/redshift/latest/dg/redshift-dg.pdf#r_COPY_command_examples" /><meta name="rss" content="Dochistory.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=155" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_COPY_command_examples.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_COPY_command_examples.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_COPY_command_examples.html" /><meta name="keywords" content="Amazon Redshift,AWS Redshift,Redshift,Redshift Spectrum,cluster,data warehouse,developer,sample data,database,database developer,HLL" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon Redshift",
        "item" : "https://docs.aws.amazon.com/redshift/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Database Developer Guide",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "SQL reference",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/cm_chap_SQLCommandRef.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "SQL commands",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/c_SQL_commands.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "COPY",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "COPY examples",
        "item" : "https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="/pdfs/redshift/latest/dg/redshift-dg.pdf#r_COPY_command_examples" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="/index.html">Documentation</a><a href="/redshift/index.html">Amazon Redshift</a><a href="welcome.html">Database Developer Guide</a></div><div id="page-toc-src"><a href="#r_COPY_command_examples-load-favoritemovies-from-an-amazon-dynamodb-table">Load FAVORITEMOVIES from an DynamoDB table</a><a href="#r_COPY_command_examples-load-listing-from-an-amazon-s3-bucket">Load LISTING from an Amazon S3 Bucket</a><a href="#copy-command-examples-emr">Load LISTING from an Amazon EMR cluster</a><a href="#copy-command-examples-manifest">Using a manifest to specify data
               files</a><a href="#r_COPY_command_examples-load-listing-from-a-pipe-delimited-file-default-delimiter">Load LISTING from a pipe-delimited file (default delimiter)</a><a href="#r_COPY_command_examples-load-listing-from-parquet">Load LISTING using columnar data in Parquet format</a><a href="#r_COPY_command_examples-load-listing-from-orc">Load LISTING using columnar data in ORC format</a><a href="#r_COPY_command_examples-load-event-with-options">Load EVENT with options</a><a href="#r_COPY_command_examples-load-venue-from-a-fixed-width-data-file">Load VENUE from a fixed-width data file</a><a href="#load-from-csv">Load CATEGORY from a CSV file</a><a href="#r_COPY_command_examples-load-venue-with-explicit-values-for-an-identity-column">Load VENUE with explicit values for an IDENTITY column</a><a href="#r_COPY_command_examples-load-time-from-a-pipe-delimited-gzip-file">Load TIME from a pipe-delimited GZIP file</a><a href="#r_COPY_command_examples-load-a-time-datestamp">Load a timestamp or datestamp</a><a href="#r_COPY_command_examples-load-data-from-a-file-with-default-values">Load data from a file with default values</a><a href="#r_COPY_command_examples-copy-data-with-the-escape-option">COPY data with the ESCAPE option</a><a href="#r_COPY_command_examples-copy-from-json">Copy from JSON examples</a><a href="#r_COPY_command_examples-copy-from-avro">Copy from Avro examples</a><a href="#r_COPY_preparing_data">Preparing files for COPY with the ESCAPE option</a><a href="#copy-example-spatial-copy-shapefile">Loading a shapefile</a><a href="#r_COPY_command_examples-load-noload-option">COPY command with the NOLOAD option</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="r_COPY_command_examples">COPY examples</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>These examples contain line breaks for readability. Do not include line breaks or
            spaces in your <em>credentials-args</em> string.</p></div></div><div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="#r_COPY_command_examples-load-favoritemovies-from-an-amazon-dynamodb-table">Load FAVORITEMOVIES from an DynamoDB table</a></li><li><a href="#r_COPY_command_examples-load-listing-from-an-amazon-s3-bucket">Load
               LISTING from an Amazon S3 bucket</a></li><li><a href="#copy-command-examples-emr">Load LISTING from an Amazon EMR cluster</a></li><li><a href="#copy-command-examples-manifest">Using a manifest to specify data
               files</a></li><li><a href="#r_COPY_command_examples-load-listing-from-a-pipe-delimited-file-default-delimiter">Load LISTING from a pipe-delimited file (default delimiter)</a></li><li><a href="#r_COPY_command_examples-load-listing-from-parquet">Load LISTING using
               columnar data in Parquet format</a></li><li><a href="#r_COPY_command_examples-load-listing-from-orc">Load LISTING using
               columnar data in ORC format</a></li><li><a href="#r_COPY_command_examples-load-event-with-options">Load EVENT with
               options</a></li><li><a href="#r_COPY_command_examples-load-venue-from-a-fixed-width-data-file">Load
               VENUE from a fixed-width data file</a></li><li><a href="#load-from-csv">Load CATEGORY from a CSV file</a></li><li><a href="#r_COPY_command_examples-load-venue-with-explicit-values-for-an-identity-column">Load VENUE with explicit values for an IDENTITY column</a></li><li><a href="#r_COPY_command_examples-load-time-from-a-pipe-delimited-gzip-file">Load
               TIME from a pipe-delimited GZIP file</a></li><li><a href="#r_COPY_command_examples-load-a-time-datestamp">Load a timestamp or
               datestamp</a></li><li><a href="#r_COPY_command_examples-load-data-from-a-file-with-default-values">Load
               data from a file with default values</a></li><li><a href="#r_COPY_command_examples-copy-data-with-the-escape-option">COPY data
               with the ESCAPE option</a></li><li><a href="#r_COPY_command_examples-copy-from-json">Copy from JSON examples</a></li><li><a href="#r_COPY_command_examples-copy-from-avro">Copy from Avro examples</a></li><li><a href="#r_COPY_preparing_data">Preparing files for COPY with the ESCAPE
               option</a></li><li><a href="#copy-example-spatial-copy-shapefile">Loading a shapefile into Amazon Redshift</a></li><li><a href="#r_COPY_command_examples-load-noload-option">COPY command with the NOLOAD option</a></li></ul></div>
         <h2 id="r_COPY_command_examples-load-favoritemovies-from-an-amazon-dynamodb-table">Load FAVORITEMOVIES from an DynamoDB table</h2>


         <p>The AWS SDKs include a simple example of creating a DynamoDB table called
               <em>Movies</em>. (For this example, see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.html">Getting Started with DynamoDB</a>.) The
            following example loads the Amazon Redshift MOVIES table with data from the DynamoDB table. The
            Amazon Redshift table must already exist in the database.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy favoritemovies from 'dynamodb://Movies'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
readratio 50;</code></pre>
       
         <h2 id="r_COPY_command_examples-load-listing-from-an-amazon-s3-bucket">Load
               LISTING from an Amazon S3 bucket</h2>


         <p>The following example loads LISTING from an Amazon S3 bucket. The COPY command loads all
            of the files in the <code class="code">/data/listing/</code> folder.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy listing
from 's3://mybucket/data/listing/' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole';</code></pre>
       
         <h2 id="copy-command-examples-emr">Load LISTING from an Amazon EMR cluster</h2>

         <p>The following example loads the SALES table with tab-delimited data from
            lzop-compressed files in an Amazon EMR cluster. COPY loads every file in the
               <code class="code">myoutput/</code> folder that begins with <code class="code">part-</code>.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy sales
from 'emr://j-SAMPLE2B500FC/myoutput/part-*' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
delimiter '\t' lzop;</code></pre>
         <p>The following example loads the SALES table with JSON formatted data in an Amazon EMR
            cluster. COPY loads every file in the <code class="code">myoutput/json/</code> folder.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy sales
from 'emr://j-SAMPLE2B500FC/myoutput/json/' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
JSON 's3://mybucket/jsonpaths.txt';</code></pre>
       
         <h2 id="copy-command-examples-manifest">Using a manifest to specify data
               files</h2>

         <p>You can use a manifest to ensure that your COPY command loads all of the required
            files, and only the required files, from Amazon S3. You can also use a manifest when you need
            to load multiple files from different buckets or files that don't share the same
            prefix. </p>
         <p>For example, suppose that you need to load the following three files:
               <code class="code">custdata1.txt</code>, <code class="code">custdata2.txt</code>, and
               <code class="code">custdata3.txt</code>. You could use the following command to load all of the
            files in <code class="code">mybucket</code> that begin with <code class="code">custdata</code> by specifying a
            prefix: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/custdata' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole';</code></pre>
         <p>If only two of the files exist because of an error, COPY loads only those two files
            and finishes successfully, resulting in an incomplete data load. If the bucket also
            contains an unwanted file that happens to use the same prefix, such as a file named
               <code class="code">custdata.backup</code> for example, COPY loads that file as well, resulting in
            unwanted data being loaded.</p>
         <p>To ensure that all of the required files are loaded and to prevent unwanted files
            from being loaded, you can use a manifest file. The manifest is a JSON-formatted text
            file that lists the files to be processed by the COPY command. For example, the
            following manifest loads the three files in the previous example.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>  
   "entries":[  
      <span>{</span>  
         "url":"s3://mybucket/custdata.1",
         "mandatory":true
      },
      <span>{</span>  
         "url":"s3://mybucket/custdata.2",
         "mandatory":true
      },
      <span>{</span>  
         "url":"s3://mybucket/custdata.3",
         "mandatory":true
      }
   ]
}</code></pre>
         <p>The optional <code class="code">mandatory</code> flag indicates whether COPY should terminate if
            the file doesn't exist. The default is <code class="code">false</code>. Regardless of any mandatory
            settings, COPY terminates if no files are found. In this example, COPY returns an error
            if any of the files isn't found. Unwanted files that might have been picked up if you
            specified only a key prefix, such as <code class="code">custdata.backup</code>, are ignored, because
            they aren't on the manifest. </p>
         <p>When loading from data files in ORC or Parquet format, a <code class="code">meta</code> field is
            required, as shown in the following example.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>  
   "entries":[  
      <span>{</span>  
         "url":"s3://mybucket-alpha/orc/2013-10-04-custdata",
         "mandatory":true,
         "meta":<span>{</span>  
            "content_length":99
         }
      },
      <span>{</span>  
         "url":"s3://mybucket-beta/orc/2013-10-05-custdata",
         "mandatory":true,
         "meta":<span>{</span>  
            "content_length":99
         }
      }
   ]
}</code></pre>
         <p>The following example uses a manifest named
               <code class="code">cust.manifest</code>. </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy customer
from 's3://mybucket/cust.manifest' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
format as orc
manifest;</code></pre>
         <p>You can use a manifest to load files from different buckets or files that don't
            share the same prefix. The following example shows the JSON to load data with files
            whose names begin with a date stamp.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
  "entries": [
    <span>{</span>"url":"s3://mybucket/2013-10-04-custdata.txt","mandatory":true},
    <span>{</span>"url":"s3://mybucket/2013-10-05-custdata.txt","mandatory":true},
    <span>{</span>"url":"s3://mybucket/2013-10-06-custdata.txt","mandatory":true},
    <span>{</span>"url":"s3://mybucket/2013-10-07-custdata.txt","mandatory":true}
  ]
}</code></pre>
         <p>The manifest can list files that are in different buckets, as long as the buckets are
            in the same AWS Region as the cluster. </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
  "entries": [
    <span>{</span>"url":"s3://mybucket-alpha/custdata1.txt","mandatory":false},
    <span>{</span>"url":"s3://mybucket-beta/custdata1.txt","mandatory":false},
    <span>{</span>"url":"s3://mybucket-beta/custdata2.txt","mandatory":false}
  ]
}</code></pre>
       
         <h2 id="r_COPY_command_examples-load-listing-from-a-pipe-delimited-file-default-delimiter">Load LISTING from a pipe-delimited file (default delimiter)</h2>


         <p>The following example is a very simple case in which no options are specified and the
            input file contains the default delimiter, a pipe character ('|'). </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy listing 
from 's3://mybucket/data/listings_pipe.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole';</code></pre>
       
         <h2 id="r_COPY_command_examples-load-listing-from-parquet">Load LISTING using
               columnar data in Parquet format</h2>
         <p>The following example loads data from a folder on Amazon S3 named parquet. </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy listing 
from 's3://mybucket/data/listings/parquet/' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
format as parquet;</code></pre>
       
         <h2 id="r_COPY_command_examples-load-listing-from-orc">Load LISTING using
               columnar data in ORC format</h2>
         <p>The following example loads data from a folder on Amazon S3 named <code class="code">orc</code>. </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy listing 
from 's3://mybucket/data/listings/orc/' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
format as orc;</code></pre>
       
         <h2 id="r_COPY_command_examples-load-event-with-options">Load EVENT with
               options</h2>


         <p>The following example loads pipe-delimited data into the EVENT table and applies the
            following rules: </p>
         <div class="itemizedlist">
             
             
             
             
         <ul class="itemizedlist"><li class="listitem">
               <p>If pairs of quotation marks are used to surround any character strings, they
                  are removed.</p>
            </li><li class="listitem">
               <p>Both empty strings and strings that contain blanks are loaded as NULL
                  values.</p>
            </li><li class="listitem">
               <p>The load fails if more than 5 errors are returned.</p>
            </li><li class="listitem">
               <p>Timestamp values must comply with the specified format; for example, a valid
                  timestamp is <code class="code">2008-09-26 05:43:12</code>.</p>
            </li></ul></div>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy event
from 's3://mybucket/data/allevents_pipe.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
removequotes
emptyasnull
blanksasnull
maxerror 5
delimiter '|'
timeformat 'YYYY-MM-DD HH:MI:SS';</code></pre>
       
         <h2 id="r_COPY_command_examples-load-venue-from-a-fixed-width-data-file">Load
               VENUE from a fixed-width data file</h2>


         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy venue
from 's3://mybucket/data/venue_fw.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
fixedwidth 'venueid:3,venuename:25,venuecity:12,venuestate:2,venueseats:6';</code></pre>
         <p>The preceding example assumes a data file formatted in the same way as the sample
            data shown. In the sample following, spaces act as placeholders so that all of the
            columns are the same width as noted in the specification: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">1  Toyota Park              Bridgeview  IL0
2  Columbus Crew Stadium    Columbus    OH0
3  RFK Stadium              Washington  DC0
4  CommunityAmerica BallparkKansas City KS0
5  Gillette Stadium         Foxborough  MA68756</code></pre>
       
         <h2 id="load-from-csv">Load CATEGORY from a CSV file</h2>

         <p>Suppose you want to load the CATEGORY with the values shown in the following
            table.</p>
         <div class="table-container"><div class="table-contents"><table id="w323aac67c10c95c37c29b5"><thead>
                  <tr>
                     <th>catid</th>
                     <th>catgroup</th>
                     <th>catname</th>
                     <th>catdesc </th>
                  </tr>
               </thead>
                  <tr>
                     <td tabindex="-1">12</td>
                     <td tabindex="-1">Shows </td>
                     <td tabindex="-1">Musicals</td>
                     <td tabindex="-1">Musical theatre</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">13</td>
                     <td tabindex="-1">Shows</td>
                     <td tabindex="-1">Plays</td>
                     <td tabindex="-1">All "non-musical" theatre</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">14</td>
                     <td tabindex="-1">Shows</td>
                     <td tabindex="-1">Opera</td>
                     <td tabindex="-1">All opera, light, and "rock" opera</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">15</td>
                     <td tabindex="-1">Concerts</td>
                     <td tabindex="-1">Classical </td>
                     <td tabindex="-1">All symphony, concerto, and choir concerts</td>
                  </tr>

               </table></div></div>
         <p>The following example shows the contents of a text file with the field values
            separated by commas.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">12,Shows,Musicals,Musical theatre
13,Shows,Plays,All "non-musical" theatre  
14,Shows,Opera,All opera, light, and "rock" opera
15,Concerts,Classical,All symphony, concerto, and choir concerts</code></pre>
         <p>If you load the file using the DELIMITER parameter to specify comma-delimited input,
            the COPY command fails because some input fields contain commas. You can avoid that
            problem by using the CSV parameter and enclosing the fields that contain commas in quotation mark characters. If the quotation mark character appears within a quoted string, you need to escape it
            by doubling the quotation mark character. The default quotation mark character is a double quotation mark,
            so you need to escape each double quotation mark with an additional double quotation
            mark. Your new input file looks something like this. </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">12,Shows,Musicals,Musical theatre
13,Shows,Plays,"All ""non-musical"" theatre"
14,Shows,Opera,"All opera, light, and ""rock"" opera"
15,Concerts,Classical,"All symphony, concerto, and choir concerts"</code></pre>
         <p>Assuming the file name is <code class="code">category_csv.txt</code>, you can load the file by
            using the following COPY command:</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/data/category_csv.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
csv;</code></pre>
         <p>Alternatively, to avoid the need to escape the double quotation marks in your input,
            you can specify a different quotation mark character by using the QUOTE AS parameter. For
            example, the following version of <code class="code">category_csv.txt</code> uses '<code class="code">%</code>' as
            the quotation mark character.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">12,Shows,Musicals,Musical theatre
13,Shows,Plays,%All "non-musical" theatre%
14,Shows,Opera,%All opera, light, and "rock" opera%
15,Concerts,Classical,%All symphony, concerto, and choir concerts%</code></pre>
         <p>The following COPY command uses QUOTE AS to load
            <code class="code">category_csv.txt</code>:</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/data/category_csv.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
csv quote as '%';</code></pre>
       
         <h2 id="r_COPY_command_examples-load-venue-with-explicit-values-for-an-identity-column">Load VENUE with explicit values for an IDENTITY column</h2>


         <p>The following example assumes that when the VENUE table was created that at least one
            column (such as the <code class="code">venueid</code> column) was specified to be an IDENTITY column.
            This command overrides the default IDENTITY behavior of autogenerating values for an
            IDENTITY column and instead loads the explicit values from the venue.txt file. 
            Amazon Redshift does not check if duplicate IDENTITY values are loaded into the table when using the EXLICIT_IDS option.  </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy venue
from 's3://mybucket/data/venue.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
explicit_ids;</code></pre>
       
         <h2 id="r_COPY_command_examples-load-time-from-a-pipe-delimited-gzip-file">Load
               TIME from a pipe-delimited GZIP file</h2>


         <p>The following example loads the TIME table from a pipe-delimited GZIP file:</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy time
from 's3://mybucket/data/timerows.gz' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
gzip
delimiter '|';</code></pre>
       
         <h2 id="r_COPY_command_examples-load-a-time-datestamp">Load a timestamp or
               datestamp</h2>


         <p>The following example loads data with a formatted timestamp.</p>
         <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The TIMEFORMAT of <code class="code">HH:MI:SS</code> can also support fractional seconds beyond
               the <code class="code">SS</code> to a microsecond level of detail. The file <code class="code">time.txt</code>
               used in this example contains one row, <code class="code">2009-01-12
               14:15:57.119568</code>.</p></div></div>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy timestamp1 
from 's3://mybucket/data/time.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
timeformat 'YYYY-MM-DD HH:MI:SS';</code></pre>
         <p>The result of this copy is as follows: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select * from timestamp1;
c1
----------------------------
2009-01-12 14:15:57.119568
(1 row)</code></pre>
       
         <h2 id="r_COPY_command_examples-load-data-from-a-file-with-default-values">Load
               data from a file with default values</h2>


         <p>The following example uses a variation of the VENUE table in the TICKIT database.
            Consider a VENUE_NEW table defined with the following statement: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create table venue_new(
venueid smallint not null,
venuename varchar(100) not null,
venuecity varchar(30),
venuestate char(2),
venueseats integer not null default '1000');</code></pre>
         <p>Consider a venue_noseats.txt data file that contains no values for the VENUESEATS
            column, as shown in the following example: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">1|Toyota Park|Bridgeview|IL|
2|Columbus Crew Stadium|Columbus|OH|
3|RFK Stadium|Washington|DC|
4|CommunityAmerica Ballpark|Kansas City|KS|
5|Gillette Stadium|Foxborough|MA|
6|New York Giants Stadium|East Rutherford|NJ|
7|BMO Field|Toronto|ON|
8|The Home Depot Center|Carson|CA|
9|Dick's Sporting Goods Park|Commerce City|CO|
10|Pizza Hut Park|Frisco|TX|</code></pre>
         <p>The following COPY statement will successfully load the table from the file and apply
            the DEFAULT value ('1000') to the omitted column: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy venue_new(venueid, venuename, venuecity, venuestate) 
from 's3://mybucket/data/venue_noseats.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
delimiter '|';</code></pre>
         <p>Now view the loaded table: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">select * from venue_new order by venueid;
venueid |         venuename          |    venuecity    | venuestate | venueseats
---------+----------------------------+-----------------+------------+------------
1 | Toyota Park                | Bridgeview      | IL         |       1000
2 | Columbus Crew Stadium      | Columbus        | OH         |       1000
3 | RFK Stadium                | Washington      | DC         |       1000
4 | CommunityAmerica Ballpark  | Kansas City     | KS         |       1000
5 | Gillette Stadium           | Foxborough      | MA         |       1000
6 | New York Giants Stadium    | East Rutherford | NJ         |       1000
7 | BMO Field                  | Toronto         | ON         |       1000
8 | The Home Depot Center      | Carson          | CA         |       1000
9 | Dick's Sporting Goods Park | Commerce City   | CO         |       1000
10 | Pizza Hut Park             | Frisco          | TX         |       1000
(10 rows)</code></pre>
         <p>For the following example, in addition to assuming that no VENUESEATS data is
            included in the file, also assume that no VENUENAME data is included: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">1||Bridgeview|IL|
2||Columbus|OH|
3||Washington|DC|
4||Kansas City|KS|
5||Foxborough|MA|
6||East Rutherford|NJ|
7||Toronto|ON|
8||Carson|CA|
9||Commerce City|CO|
10||Frisco|TX|</code></pre>
         <p> Using the same table definition, the following COPY statement fails because no
            DEFAULT value was specified for VENUENAME, and VENUENAME is a NOT NULL column: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy venue(venueid, venuecity, venuestate) 
from 's3://mybucket/data/venue_pipe.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
delimiter '|';</code></pre>
         <p>Now consider a variation of the VENUE table that uses an IDENTITY column: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">create table venue_identity(
venueid int identity(1,1),
venuename varchar(100) not null,
venuecity varchar(30),
venuestate char(2),
venueseats integer not null default '1000');</code></pre>
         <p>As with the previous example, assume that the VENUESEATS column has no corresponding
            values in the source file. The following COPY statement successfully loads the table,
            including the predefined IDENTITY data values instead of autogenerating those values: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy venue(venueid, venuename, venuecity, venuestate) 
from 's3://mybucket/data/venue_pipe.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
delimiter '|' explicit_ids;</code></pre>
         <p>This statement fails because it doesn't include the IDENTITY column (VENUEID is
            missing from the column list) yet includes an EXPLICIT_IDS parameter: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy venue(venuename, venuecity, venuestate) 
from 's3://mybucket/data/venue_pipe.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
delimiter '|' explicit_ids;</code></pre>
         <p>This statement fails because it doesn't include an EXPLICIT_IDS parameter: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy venue(venueid, venuename, venuecity, venuestate)
from 's3://mybucket/data/venue_pipe.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
delimiter '|';</code></pre>
       
         <h2 id="r_COPY_command_examples-copy-data-with-the-escape-option">COPY data
               with the ESCAPE option</h2>


         <p>The following example shows how to load characters that match the delimiter character
            (in this case, the pipe character). In the input file, make sure that all of the pipe
            characters (|) that you want to load are escaped with the backslash character (\). Then
            load the file with the ESCAPE parameter. </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">$ more redshiftinfo.txt
1|public\|event\|dwuser
2|public\|sales\|dwuser

create table redshiftinfo(infoid int,tableinfo varchar(50));

copy redshiftinfo from 's3://mybucket/data/redshiftinfo.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
delimiter '|' escape;

select * from redshiftinfo order by 1;
infoid |       tableinfo
-------+--------------------
1      | public|event|dwuser
2      | public|sales|dwuser
(2 rows)</code></pre>
         <p>Without the ESCAPE parameter, this COPY command fails with an <code class="code">Extra column(s)
               found</code> error.</p>
         <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>If you load your data using a COPY with the ESCAPE parameter, you must also
               specify the ESCAPE parameter with your UNLOAD command to generate the reciprocal
               output file. Similarly, if you UNLOAD using the ESCAPE parameter, you need to use
               ESCAPE when you COPY the same data.</p></div></div>
       
         <h2 id="r_COPY_command_examples-copy-from-json">Copy from JSON examples</h2>

         <p>In the following examples, you load the CATEGORY table with the following data. </p>
         <div class="table-container"><div class="table-contents"><table id="w323aac67c10c95c37c43b5"><thead>
                  <tr>
                     <th>CATID</th>
                     <th>CATGROUP</th>
                     <th>CATNAME</th>
                     <th>CATDESC</th>
                  </tr>
               </thead>
                  <tr>
                     <td tabindex="-1">1</td>
                     <td tabindex="-1">Sports</td>
                     <td tabindex="-1">MLB</td>
                     <td tabindex="-1"> Major League Baseball</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">2</td>
                     <td tabindex="-1">Sports</td>
                     <td tabindex="-1">NHL</td>
                     <td tabindex="-1">National Hockey League</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">3</td>
                     <td tabindex="-1">Sports</td>
                     <td tabindex="-1">NFL</td>
                     <td tabindex="-1">National Football League</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">4</td>
                     <td tabindex="-1">Sports</td>
                     <td tabindex="-1">NBA</td>
                     <td tabindex="-1">National Basketball Association</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">5</td>
                     <td tabindex="-1">Concerts</td>
                     <td tabindex="-1">Classical</td>
                     <td tabindex="-1">All symphony, concerto, and choir concerts</td>
                  </tr>
               </table></div></div>
         <div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="#copy-from-json-examples-using-auto">Load from JSON data using the
                  'auto' option</a></li><li><a href="#copy-from-json-examples-using-auto-ignorecase">Load from JSON data using the
                  'auto ignorecase' option</a></li><li><a href="#copy-from-json-examples-using-jsonpaths">Load from JSON data using a
                  JSONPaths file</a></li><li><a href="#copy-from-json-examples-using-jsonpaths-arrays">Load from JSON
                  arrays using a JSONPaths file</a></li></ul></div>

          
            <h3 id="copy-from-json-examples-using-auto">Load from JSON data using the
                  'auto' option</h3>

            <p>To load from JSON data using the <code class="code">'auto'</code> option, the JSON data must
               consist of a set of objects. The key names must match the column names, but the order
               doesn't matter. The following shows the contents of a file named
                  <code class="code">category_object_auto.json</code>.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "catdesc": "Major League Baseball",
    "catid": 1,
    "catgroup": "Sports",
    "catname": "MLB"
}
<span>{</span>
    "catgroup": "Sports",
    "catid": 2,
    "catname": "NHL",
    "catdesc": "National Hockey League"
}<span>{</span>
    "catid": 3,
    "catname": "NFL",
    "catgroup": "Sports",
    "catdesc": "National Football League"
}
<span>{</span>
    "bogus": "Bogus Sports LLC",
    "catid": 4,
    "catgroup": "Sports",
    "catname": "NBA",
    "catdesc": "National Basketball Association"
}
<span>{</span>
    "catid": 5,
    "catgroup": "Shows",
    "catname": "Musicals",
    "catdesc": "All symphony, concerto, and choir concerts"
}</code></pre>
            <p>To load from the JSON data file in the previous example, run the following COPY
               command.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/category_object_auto.json'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
json 'auto';</code></pre>
          
         
          
            <h3 id="copy-from-json-examples-using-auto-ignorecase">Load from JSON data using the
                  'auto ignorecase' option</h3>
            
            <p>To load from JSON data using the <code class="code">'auto ignorecase'</code> option, the JSON
               data must consist of a set of objects. The case of the key names doesn't have to
               match the column names and the order doesn't matter. The following shows the
               contents of a file named <code class="code">category_object_auto-ignorecase.json</code>.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "CatDesc": "Major League Baseball",
    "CatID": 1,
    "CatGroup": "Sports",
    "CatName": "MLB"
}
<span>{</span>
    "CatGroup": "Sports",
    "CatID": 2,
    "CatName": "NHL",
    "CatDesc": "National Hockey League"
}<span>{</span>
    "CatID": 3,
    "CatName": "NFL",
    "CatGroup": "Sports",
    "CatDesc": "National Football League"
}
<span>{</span>
    "bogus": "Bogus Sports LLC",
    "CatID": 4,
    "CatGroup": "Sports",
    "CatName": "NBA",
    "CatDesc": "National Basketball Association"
}
<span>{</span>
    "CatID": 5,
    "CatGroup": "Shows",
    "CatName": "Musicals",
    "CatDesc": "All symphony, concerto, and choir concerts"
}</code></pre>
            <p>To load from the JSON data file in the previous example, run the following COPY
               command.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/category_object_auto ignorecase.json'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
json 'auto ignorecase';</code></pre>
          
          
            <h3 id="copy-from-json-examples-using-jsonpaths">Load from JSON data using a
                  JSONPaths file</h3>
            
            <p>If the JSON data objects don't correspond directly to column names, you can use a
               JSONPaths file to map the JSON elements to columns. The order doesn't matter
               in the JSON source data, but the order of the JSONPaths file expressions must match
               the column order. Suppose that you have the following data file, named
               <code class="code">category_object_paths.json</code>.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "one": 1,
    "two": "Sports",
    "three": "MLB",
    "four": "Major League Baseball"
}
<span>{</span>
    "three": "NHL",
    "four": "National Hockey League",
    "one": 2,
    "two": "Sports"
}
<span>{</span>
    "two": "Sports",
    "three": "NFL",
    "one": 3,
    "four": "National Football League"
}
<span>{</span>
    "one": 4,
    "two": "Sports",
    "three": "NBA",
    "four": "National Basketball Association"
}
<span>{</span>
    "one": 6,
    "two": "Shows",
    "three": "Musicals",
    "four": "All symphony, concerto, and choir concerts"
}</code></pre>
            <p>The following JSONPaths file, named <code class="code">category_jsonpath.json</code>, maps the
               source data to the table columns.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "jsonpaths": [
        "$['one']",
        "$['two']",
        "$['three']",
        "$['four']"
    ]
}</code></pre>
            <p>To load from the JSON data file in the previous example, run the following COPY
               command.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/category_object_paths.json'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
json 's3://mybucket/category_jsonpath.json';</code></pre>
          
         
         
          
            <h3 id="copy-from-json-examples-using-jsonpaths-arrays">Load from JSON
                  arrays using a JSONPaths file</h3>

            <p>To load from JSON data that consists of a set of arrays, you must use a JSONPaths
               file to map the array elements to columns. Suppose that you have the following data
               file, named <code class="code">category_array_data.json</code>.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">[1,"Sports","MLB","Major League Baseball"]
[2,"Sports","NHL","National Hockey League"]
[3,"Sports","NFL","National Football League"]
[4,"Sports","NBA","National Basketball Association"]
[5,"Concerts","Classical","All symphony, concerto, and choir concerts"]</code></pre>
            <p>The following JSONPaths file, named <code class="code">category_array_jsonpath.json</code>,
               maps the source data to the table columns.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>
    "jsonpaths": [
        "$[0]",
        "$[1]",
        "$[2]",
        "$[3]"
    ]
}</code></pre>
            <p>To load from the JSON data file in the previous example, run the following COPY
               command.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/category_array_data.json'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
json 's3://mybucket/category_array_jsonpath.json';</code></pre>
          
             
         <h2 id="r_COPY_command_examples-copy-from-avro">Copy from Avro examples</h2>

         <p>In the following examples, you load the CATEGORY table with the following data. </p>
         <div class="table-container"><div class="table-contents"><table id="w323aac67c10c95c37c49b5"><thead>
                  <tr>
                     <th>CATID</th>
                     <th>CATGROUP</th>
                     <th>CATNAME</th>
                     <th>CATDESC</th>
                  </tr>
               </thead>
                  <tr>
                     <td tabindex="-1">1</td>
                     <td tabindex="-1">Sports</td>
                     <td tabindex="-1">MLB</td>
                     <td tabindex="-1"> Major League Baseball</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">2</td>
                     <td tabindex="-1">Sports</td>
                     <td tabindex="-1">NHL</td>
                     <td tabindex="-1">National Hockey League</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">3</td>
                     <td tabindex="-1">Sports</td>
                     <td tabindex="-1">NFL</td>
                     <td tabindex="-1">National Football League</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">4</td>
                     <td tabindex="-1">Sports</td>
                     <td tabindex="-1">NBA</td>
                     <td tabindex="-1">National Basketball Association</td>
                  </tr>
                  <tr>
                     <td tabindex="-1">5</td>
                     <td tabindex="-1">Concerts</td>
                     <td tabindex="-1">Classical</td>
                     <td tabindex="-1">All symphony, concerto, and choir concerts</td>
                  </tr>
               </table></div></div>
         <div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="#copy-from-avro-examples-using-auto">Load from Avro data using the
                  'auto' option</a></li><li><a href="#copy-from-avro-examples-using-auto-ignorecase">Load from Avro data using the
                  'auto ignorecase' option</a></li><li><a href="#copy-from-avro-examples-using-avropaths">Load from Avro data using a
                  JSONPaths file</a></li></ul></div>
          
            <h3 id="copy-from-avro-examples-using-auto">Load from Avro data using the
                  'auto' option</h3>

            <p>To load from Avro data using the <code class="code">'auto'</code> argument, field names in the
               Avro schema must match the column names. When using the <code class="code">'auto'</code>
               argument, order doesn't matter. The following shows the schema for a file named
                  <code class="code">category_auto.avro</code>.</p>
            <pre class="screen"><span>{</span>
    "name": "category",
    "type": "record",
    "fields": [
        <span>{</span>"name": "catid", "type": "int"},
        <span>{</span>"name": "catdesc", "type": "string"},
        <span>{</span>"name": "catname", "type": "string"},
        <span>{</span>"name": "catgroup", "type": "string"},
}</pre>
            <p>The data in an Avro file is in binary format, so it isn't human-readable. The
               following shows a JSON representation of the data in the
                  <code class="code">category_auto.avro</code> file. </p>
            <pre class="screen"><span>{</span>
   "catid": 1,
   "catdesc": "Major League Baseball",
   "catname": "MLB",
   "catgroup": "Sports"
}
<span>{</span>
   "catid": 2,
   "catdesc": "National Hockey League",
   "catname": "NHL",
   "catgroup": "Sports"
}
<span>{</span>
   "catid": 3,
   "catdesc": "National Basketball Association",
   "catname": "NBA",
   "catgroup": "Sports"
}
<span>{</span>
   "catid": 4,
   "catdesc": "All symphony, concerto, and choir concerts",
   "catname": "Classical",
   "catgroup": "Concerts"
}</pre>
            <p>To load from the Avro data file in the previous example, run the following COPY
               command.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/category_auto.avro'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
format as avro 'auto';</code></pre>
          
         
          
            <h3 id="copy-from-avro-examples-using-auto-ignorecase">Load from Avro data using the
                  'auto ignorecase' option</h3>
            
            <p>To load from Avro data using the <code class="code">'auto ignorecase'</code> argument, the case of the field names in the
               Avro schema does not have to match the case of column names. When using the <code class="code">'auto ignorecase'</code>
               argument, order doesn't matter. The following shows the schema for a file named
               <code class="code">category_auto-ignorecase.avro</code>.</p>
            <pre class="screen"><span>{</span>
    "name": "category",
    "type": "record",
    "fields": [
        <span>{</span>"name": "CatID", "type": "int"},
        <span>{</span>"name": "CatDesc", "type": "string"},
        <span>{</span>"name": "CatName", "type": "string"},
        <span>{</span>"name": "CatGroup", "type": "string"},
}</pre>
            <p>The data in an Avro file is in binary format, so it isn't human-readable. The
               following shows a JSON representation of the data in the
               <code class="code">category_auto-ignorecase.avro</code> file. </p>
            <pre class="screen"><span>{</span>
   "CatID": 1,
   "CatDesc": "Major League Baseball",
   "CatName": "MLB",
   "CatGroup": "Sports"
}
<span>{</span>
   "CatID": 2,
   "CatDesc": "National Hockey League",
   "CatName": "NHL",
   "CatGroup": "Sports"
}
<span>{</span>
   "CatID": 3,
   "CatDesc": "National Basketball Association",
   "CatName": "NBA",
   "CatGroup": "Sports"
}
<span>{</span>
   "CatID": 4,
   "CatDesc": "All symphony, concerto, and choir concerts",
   "CatName": "Classical",
   "CatGroup": "Concerts"
}</pre>
            <p>To load from the Avro data file in the previous example, run the following COPY
               command.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/category_auto-ignorecase.avro'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'
format as avro 'auto ignorecase';</code></pre>
          
         
          
            <h3 id="copy-from-avro-examples-using-avropaths">Load from Avro data using a
                  JSONPaths file</h3>

            <p>If the field names in the Avro schema don't correspond directly to column names,
               you can use a JSONPaths file to map the schema elements to columns. The order of the
               JSONPaths file expressions must match the column order. </p>
            <p>Suppose that you have a data file named <code class="code">category_paths.avro</code> that
               contains the same data as in the previous example, but with the following
               schema.</p>
            <pre class="screen"><span>{</span>
    "name": "category",
    "type": "record",
    "fields": [
        <span>{</span>"name": "id", "type": "int"},
        <span>{</span>"name": "desc", "type": "string"},
        <span>{</span>"name": "name", "type": "string"},
        <span>{</span>"name": "group", "type": "string"},
        <span>{</span>"name": "region", "type": "string"} 
     ]
}</pre>
            <p>The following JSONPaths file, named <code class="code">category_path.avropath</code>, maps the
               source data to the table columns.</p>
            <pre class="screen"><span>{</span>
    "jsonpaths": [
        "$['id']",
        "$['group']",
        "$['name']",
        "$['desc']"
    ]
}</pre>
            <p>To load from the Avro data file in the previous example, run the following COPY
               command.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy category
from 's3://mybucket/category_object_paths.avro'
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole' 
format avro 's3://mybucket/category_path.avropath ';</code></pre>
          

       
         <h2 id="r_COPY_preparing_data">Preparing files for COPY with the ESCAPE
               option</h2>


         <p>The following example describes how you might prepare data to "escape" newline
            characters before importing the data into an Amazon Redshift table using the COPY command with
            the ESCAPE parameter. Without preparing the data to delimit the newline characters,
            Amazon Redshift returns load errors when you run the COPY command, because the newline
            character is normally used as a record separator. </p>
         <p>For example, consider a file or a column in an external table that you want to copy
            into an Amazon Redshift table. If the file or column contains XML-formatted content or similar
            data, you need to make sure that all of the newline characters (\n) that are part of the
            content are escaped with the backslash character (\). </p>
         <p>A file or table containing embedded newlines characters 
            provides a relatively easy pattern to match. Each embedded newline character most likely
            always follows a <code class="code">&gt;</code> character with potentially some white space
            characters (<code class="code">' '</code> or tab) in between, as you can see in the following example
            of a text file named <code>nlTest1.txt</code>. </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">$ cat nlTest1.txt
&lt;xml start&gt;
&lt;newline characters provide&gt;
&lt;line breaks at the end of each&gt;
&lt;line in content&gt;
&lt;/xml&gt;|1000
&lt;xml&gt;
&lt;/xml&gt;|2000</code></pre>
         <p>With the following example, you can run a text-processing utility to pre-process the
            source file and insert escape characters where needed. (The <code class="code">|</code> character is
            intended to be used as delimiter to separate column data when copied into an Amazon Redshift
            table.) </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">$ sed -e ':a;N;$!ba;s/&gt;[[:space:]]*\n/&gt;\\\n/g' nlTest1.txt &gt; nlTest2.txt</code></pre>
         <p>Similarly, you can use Perl to perform a similar operation: </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">cat nlTest1.txt | perl -p -e 's/&gt;\s*\n/&gt;\\\n/g' &gt; nlTest2.txt</code></pre>
         <p>To accommodate loading the data from the <code>nlTest2.txt</code> file into
            Amazon Redshift, we created a two-column table in Amazon Redshift. The first column c1, is a character
            column that holds XML-formatted content from the <code>nlTest2.txt</code> file.
            The second column c2 holds integer values loaded from the same file. </p>
         <p>After running the <code class="code">sed</code> command, you can correctly load data from the
               <code>nlTest2.txt</code> file into an Amazon Redshift table using the ESCAPE
            parameter. </p>
         <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>When you include the ESCAPE parameter with the COPY command, it escapes a number
               of special characters that include the backslash character (including newline).
            </p></div></div>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">copy t2 from 's3://mybucket/data/nlTest2.txt' 
iam_role 'arn:aws:iam::0123456789012:role/MyRedshiftRole'  
escape
delimiter as '|';

select * from t2 order by 2;

c1           |  c2
-------------+------
&lt;xml start&gt;
&lt;newline characters provide&gt;
&lt;line breaks at the end of each&gt;
&lt;line in content&gt;
&lt;/xml&gt;
| 1000
&lt;xml&gt;
&lt;/xml&gt;       | 2000
(2 rows)</code></pre>
         <p>You can prepare data files exported from external databases in a similar way. For
            example, with an Oracle database, you can use the REPLACE function on each affected
            column in a table that you want to copy into Amazon Redshift. </p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">SELECT c1, REPLACE(c2, \n',\\n' ) as c2 from my_table_with_xml</code></pre>
         <p>In addition, many database export and extract, transform, load (ETL) tools that
            routinely process large amounts of data provide options to specify escape and delimiter
            characters. </p>
       
         
         
         <h2 id="copy-example-spatial-copy-shapefile">Loading a shapefile into Amazon Redshift</h2>
         
         <p>The following examples demonstrate how to load an Esri shapefile using COPY. For more
            information about loading shapefiles, see <a href="./spatial-copy-shapefile.html">Loading a shapefile into Amazon Redshift</a>. </p>        

         
         
          
            <h3 id="copy-example-spatial-copy-shapefile-loading-copy">Loading a shapefile</h3>
            
            
            <p>The following steps show how to ingest OpenStreetMap data from Amazon S3 using the COPY
               command. This example assumes that the Norway shapefile archive from <a href="https://download.geofabrik.de/europe.html" rel="noopener noreferrer" target="_blank"><span>the download site of
                  Geofabrik</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> has been uploaded to a private Amazon S3 bucket in your AWS Region.
               The <code>.shp</code>, <code>.shx</code>, and
                  <code>.dbf</code> files must share the same Amazon S3 prefix and file
               name.</p>
            
             
               <h4 id="spatial-copy-shapefile-loading-copy-fits">Ingesting data without
                     simplification</h4>
               <p>The following commands create tables and ingest data that can fit in the
                  maximum geometry size without any simplification. Open the
                     <code>gis_osm_natural_free_1.shp</code> in your preferred GIS software
                  and inspect the columns in this layer.
                  
                  By default, either IDENTITY or GEOMETRY columns are first. When a GEOMETRY column
                  is first, you can create the table as shown following.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE TABLE norway_natural (
   wkb_geometry GEOMETRY,
   osm_id BIGINT,
   code INT,
   fclass VARCHAR,
   name VARCHAR);            
</code></pre>
               
               <p>Or, when an IDENTITY column is first, you can create the table as shown
                  following.</p>
               
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE TABLE norway_natural_with_id (
   fid INT IDENTITY(1,1),
   wkb_geometry GEOMETRY,
   osm_id BIGINT,
   code INT,
   fclass VARCHAR,
   name VARCHAR);            
</code></pre>
               
               <p>Now you can ingest the data using COPY.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">COPY norway_natural FROM 's3://<code class="replaceable">bucket_name</code>/shapefiles/norway/gis_osm_natural_free_1.shp'
FORMAT SHAPEFILE
CREDENTIALS 'aws_iam_role=arn:aws:iam::123456789012:role/MyRoleName';
INFO: Load into table 'norway_natural' completed, 83891 record(s) loaded successfully
</code></pre>
               
               <p>Or you can ingest the data as shown following. </p>
               
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">COPY norway_natural_with_id FROM 's3://<code class="replaceable">bucket_name</code>/shapefiles/norway/gis_osm_natural_free_1.shp'
FORMAT SHAPEFILE
CREDENTIALS 'aws_iam_role=arn:aws:iam::123456789012:role/MyRoleName';
INFO: Load into table 'norway_natural_with_id' completed, 83891 record(s) loaded successfully.
</code></pre>         
             
            
             
               <h4 id="spatial-copy-shapefile-loading-copy-no-fit">Ingesting data with
                     simplification</h4>
               <p>The following commands create a table and try to ingest data that can't fit in
                  the maximum geometry size without any simplification. Inspect the
                     <code>gis_osm_water_a_free_1.shp</code> shapefile and create the
                  appropriate table as shown following.</p>             
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE TABLE norway_water (
   wkb_geometry GEOMETRY,
   osm_id BIGINT,
   code INT,
   fclass VARCHAR,
   name VARCHAR);
</code></pre>
               
               <p>When the COPY command runs, it results in an error.</p>
               
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">COPY norway_water FROM 's3://<code class="replaceable">bucket_name</code>/shapefiles/norway/gis_osm_water_a_free_1.shp'
FORMAT SHAPEFILE
CREDENTIALS 'aws_iam_role=arn:aws:iam::123456789012:role/MyRoleName';
ERROR:  Load into table 'norway_water' failed.  Check 'stl_load_errors' system table for details.              
</code></pre>
               
               <p>Querying <code class="code">STL_LOAD_ERRORS</code> shows that the geometry is too large. </p>
               
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">SELECT line_number, btrim(colname), btrim(err_reason) FROM stl_load_errors WHERE query = pg_last_copy_id();
 line_number |    btrim     |                                 btrim
-------------+--------------+-----------------------------------------------------------------------
     1184705 | wkb_geometry | Geometry size: 1513736 is larger than maximum supported size: 1048447              
</code></pre>
               
               <p>To overcome this, the <code class="code">SIMPLIFY AUTO</code> parameter is added to the COPY
                  command to simplify geometries.</p>
               
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">COPY norway_water FROM 's3://<code class="replaceable">bucket_name</code>/shapefiles/norway/gis_osm_water_a_free_1.shp'
FORMAT SHAPEFILE
SIMPLIFY AUTO
CREDENTIALS 'aws_iam_role=arn:aws:iam::123456789012:role/MyRoleName';

INFO:  Load into table 'norway_water' completed, 1989196 record(s) loaded successfully.              
</code></pre>
               
               <p>To view the rows and geometries that were simplified, query
                     <code class="code">SVL_SPATIAL_SIMPLIFY</code>.</p>
               
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">SELECT * FROM svl_spatial_simplify WHERE query = pg_last_copy_id();
 query | line_number | maximum_tolerance | initial_size | simplified | final_size |   final_tolerance
-------+-------------+-------------------+--------------+------------+------------+----------------------
    20 |     1184704 |                -1 |      1513736 | t          |    1008808 |   1.276386653895e-05
    20 |     1664115 |                -1 |      1233456 | t          |    1023584 | 6.11707814796635e-06               
</code></pre>
               
               <p>Using SIMPLIFY AUTO <em>max_tolerance</em> with the tolerance lower
                  than the automatically calculated ones probably results in an ingestion error. In
                  this case, use MAXERROR to ignore errors.</p>
               
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">COPY norway_water FROM 's3://<code class="replaceable">bucket_name</code>/shapefiles/norway/gis_osm_water_a_free_1.shp'
FORMAT SHAPEFILE
SIMPLIFY AUTO 1.1E-05
MAXERROR 2
CREDENTIALS 'aws_iam_role=arn:aws:iam::123456789012:role/MyRoleName';

INFO:  Load into table 'norway_water' completed, 1989195 record(s) loaded successfully.
INFO:  Load into table 'norway_water' completed, 1 record(s) could not be loaded.  Check 'stl_load_errors' system table for details.               
</code></pre>
               
               <p>Query <code class="code">SVL_SPATIAL_SIMPLIFY</code> again to identify the record that COPY
                  didn't manage to load.</p>
               <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">SELECT * FROM svl_spatial_simplify WHERE query = pg_last_copy_id();
 query | line_number | maximum_tolerance | initial_size | simplified | final_size | final_tolerance
-------+-------------+-------------------+--------------+------------+------------+-----------------
    29 |     1184704 |           1.1e-05 |      1513736 | f          |          0 |               0
    29 |     1664115 |           1.1e-05 |      1233456 | t          |     794432 |         1.1e-05             
</code></pre>
               
               <p>In this example, the first record didnt manage to fit, so the
                     <code class="code">simplified</code> column is showing false. The second record was loaded
                  within the given tolerance. However, the final size is larger than using the
                  automatically calculated tolerance without specifying the maximum tolerance. </p>             
                       
             
                       
          
         
          
            <h3 id="copy-example-spatial-copy-shapefile-compressed">Loading from a compressed shapefile</h3>
            <p>Amazon Redshift COPY supports ingesting data from a compressed shapefile. All shapefile
               components must have the same Amazon S3 prefix and the same compression suffix. As an
               example, suppose that you want to load the data from the previous example. In this
               case, the files <code>gis_osm_water_a_free_1.shp.gz</code>,
                  <code>gis_osm_water_a_free_1.dbf.gz</code>, and
                  <code>gis_osm_water_a_free_1.shx.gz</code> must share the same Amazon S3
               directory. The COPY command requires the GZIP option, and the FROM clause must
               specify the correct compressed file, as shown following.</p>
            
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">COPY norway_natural FROM 's3://<code class="replaceable">bucket_name</code>/shapefiles/norway/compressed/gis_osm_natural_free_1.shp.gz'
FORMAT SHAPEFILE
GZIP
CREDENTIALS 'aws_iam_role=arn:aws:iam::123456789012:role/MyRoleName';
INFO:  Load into table 'norway_natural' completed, 83891 record(s) loaded successfully.          
</code></pre>
          
         
          
            <h3 id="copy-example-spatial-copy-shapefile-column-order">Loading data into
                  a table with a different column order</h3>
            <p>If you have a table that doesn't have <code class="code">GEOMETRY</code> as the first column,
               you can use column mapping to map columns to the target table. For example, create a
               table with <code class="code">osm_id</code> specified as a first column.</p>
            
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">CREATE TABLE norway_natural_order (
   osm_id BIGINT,
   wkb_geometry GEOMETRY,
   code INT,
   fclass VARCHAR,
   name VARCHAR);         
</code></pre>
            <p>Then ingest a shapefile using column mapping.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">COPY norway_natural_order(wkb_geometry, osm_id, code, fclass, name) 
FROM 's3://<code class="replaceable">bucket_name</code>/shapefiles/norway/gis_osm_natural_free_1.shp'
FORMAT SHAPEFILE
CREDENTIALS 'aws_iam_role=arn:aws:iam::123456789012:role/MyRoleName';
INFO:  Load into table 'norway_natural_order' completed, 83891 record(s) loaded successfully.         
</code></pre>
            
          
         
          
            
            <h3 id="copy-example-spatial-copy-shapefile-geography">Loading data into
                  a table with a geography column</h3>
            <p>If you have a table that has a <code class="code">GEOGRAPHY</code> column,
               you first ingest into a <code class="code">GEOMETRY</code> column and then cast the objects to <code class="code">GEOGRAPHY</code> objects. 
               For example, after you copy your shapefile into a <code class="code">GEOMETRY</code> column, alter the table to add a column of the <code class="code">GEOGRAPHY</code> data type.</p>           
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE norway_natural ADD COLUMN wkb_geography GEOGRAPHY;</code></pre>
            
            <p>Then convert geometries to geographies.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">UPDATE norway_natural SET wkb_geography = wkb_geometry::geography;</code></pre>
            
            <p>Optionally, you can drop the <code class="code">GEOMETRY</code> column.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">ALTER TABLE norway_natural DROP COLUMN wkb_geometry;</code></pre>
            
          
         
       
         
         <h2 id="r_COPY_command_examples-load-noload-option">COPY command with the NOLOAD option</h2>
              
         <p>To validate data files before you actually load the data, use the NOLOAD option with the COPY command. 
            Amazon Redshift parses the input file and displays any errors that occur.
            The following example uses the NOLOAD option and no rows are actually loaded into the table.</p>
         <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql "><code class="userinput">COPY public.zipcode1
FROM 's3://mybucket/mydata/zipcode.csv' 
DELIMITER ';' 
IGNOREHEADER 1 REGION 'us-east-1'
NOLOAD
CREDENTIALS 'aws_iam_role=arn:aws:iam::123456789012:role/myRedshiftRole'</code>;
<code class="computeroutput" copy="false">
Warnings:
Load into table 'zipcode1' completed, 0 record(s) loaded successfully.  
</code>       
         
         </code></pre>
      <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./automatic-recognition.html">Using automatic recognition with DATEFORMAT and
               TIMEFORMAT</div><div id="next" class="next-link" accesskey="n" href="./r_CREATE_DATABASE.html">CREATE DATABASE</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_COPY_command_examples.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Redshift&amp;topic_url=https://docs.aws.amazon.com/en_us/redshift/latest/dg/r_COPY_command_examples.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>